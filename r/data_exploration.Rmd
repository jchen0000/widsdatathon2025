---
title: "Data exploration"
author: "LYU JING"
date: "2025-02-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(pheatmap)
library(igraph)
```

```{r}
# Load necessary libraries
library(readxl)  # For reading Excel files
library(readr)   # For reading CSV files
setwd("/Users/jinglv/Desktop/RA/widsdatathon2025")

path <- "data/train"  # Update this with your actual path
path2<-"/Users/jinglv/Downloads"


# Read the Excel files
train_categorical_metadata <- read_excel(file.path(path, "TRAIN_CATEGORICAL_METADATA.xlsx"))
train_functional_connectome <- read_csv(file.path(path2, "TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv"))
train_quantitative_metadata <- read_excel(file.path(path, "TRAIN_QUANTITATIVE_METADATA.xlsx"))
training_solutions <- read_excel(file.path(path, "TRAINING_SOLUTIONS.xlsx"))

# Display the first few rows of each dataset
head(train_categorical_metadata)
head(train_functional_connectome)
head(train_quantitative_metadata)
head(training_solutions)


summary(train_functional_connectome$`110throw_153thcolumn`)
```

# MRI preprocessing
```{r}
name = colnames(train_functional_connectome)
name[19700:19901]
```
0-199
1+2+3...+199
200*200/2 - (200/2); no diagonal
19900
```{r}
data = train_functional_connectome
participant_ids <- data$participant_id
conn_data <- data[ , -which(names(data) == "participant_id")]


# -------------------------------
# 2. Define a Function to Reconstruct the Full Matrix
# -------------------------------
# This function takes a vector 'v' (of length 19,900) and returns a 200x200 symmetric matrix
reconstruct_matrix <- function(v, n = 200) {
  m <- matrix(0, n, n)         # create an empty matrix
  m[upper.tri(m)] <- v         # fill in the upper triangle (diagonal remains 0)
  m[lower.tri(m)] <- t(m)[lower.tri(m)]  # mirror the upper triangle to the lower triangle
  return(m)
}

# -------------------------------
# 3. Reconstruct and Visualize a Single Subject's Connectivity Matrix
# -------------------------------
# For example, reconstruct the matrix for the first participant
first_vector <- as.numeric(conn_data[100, ])
first_matrix <- reconstruct_matrix(first_vector, n = 200)

# Visualize this matrix as a heatmap
pheatmap(first_matrix,
         main = paste("Connectivity Matrix for Participant", participant_ids[1]),
         cluster_rows = TRUE,
         cluster_cols = TRUE)

```


```{r}

# -------------------------------
# 4. Compute an Average Connectivity Matrix Across All Subjects
# -------------------------------
# Initialize a matrix to accumulate connectivity values
nSubjects <- nrow(conn_data)
nNodes <- 200
avg_matrix <- matrix(0, nNodes, nNodes)

# Loop over subjects and accumulate matrices
for (i in 1:nSubjects) {
  vec <- as.numeric(conn_data[i, ])
  m <- reconstruct_matrix(vec, n = nNodes)
  avg_matrix <- avg_matrix + m
}
avg_matrix <- avg_matrix / nSubjects  # compute the average

# Visualize the average connectivity matrix
pheatmap(avg_matrix,
         main = "Average Connectivity Matrix Across Subjects",
         cluster_rows = TRUE,
         cluster_cols = TRUE)

```

https://pmc.ncbi.nlm.nih.gov/articles/PMC5008686/#S3


https://rdrr.io/github/EBlini/FCnet/f/README.md
```{r}
library("FCnet")
```

```{r}
data("MeanFC") #the object MeanFC is now available

set.seed(1)

N_subs= 50 #number of participants/matrices
subjs_variability= 0.2 #variability (sd) between matrices

#this function creates several matrices by adding gaussian noise
#with sd "variability" to a reference matrix
m_start= simulateMat(mat = MeanFC, 
                     Nmat = N_subs, 
                     mat_variability = subjs_variability)
```

Feature reduction
A-NPE software; time-series; not suitable for us

FCnet: PCA & elestic net

LDA;

spatial;

# Model training

```{r}

# Load the dataset
df <- train_functional_connectome

df_clean <- df[complete.cases(df), ]


# Function to calculate Z-scores for each column
z_score <- function(x) {
  return((x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE))
}

# Apply Z-score function to all numeric columns (exclude patient ID)
z_scores <- as.data.frame(lapply(df_clean[,-1], z_score))  # Compute Z-scores

# Identify rows where any feature has a Z-score above 3 (outlier)
outlier_rows <- apply(z_scores, 1, function(row) any(abs(row) > 3))

# Remove outliers
df_clean <- df_clean[!outlier_rows, ]

# Print how many outliers were removed
cat("Removed", sum(outlier_rows), "outliers.\n")

summary(training_solutions)
```


fit a ML model like this procedure:
PCA select variable; then used the selected variables train RF/XGB/LDA/elastic net; I want 5-fold cv; and comparision between model fitting

training variables:
train_categorical_metadata <- read_excel(file.path(path, "TRAIN_CATEGORICAL_METADATA.xlsx"))
train_functional_connectome <- read_csv(file.path(path2, "TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv"))
train_quantitative_metadata <- read_excel(file.path(path, "TRAIN_QUANTITATIVE_METADATA.xlsx"))

training outcomes:include 2 columns(sex and ADHD)
training_solutions <- read_excel(file.path(path, "TRAINING_SOLUTIONS.xlsx"))


UMAP;

```{r}
# Install LightGBM if not installed
if (!requireNamespace("lightgbm", quietly = TRUE)) {
    install.packages("lightgbm", repos = "https://cran.r-project.org")
}

# Load necessary libraries
library(lightgbm)
library(caret)  # For model training

```


```{r}
# Load required libraries
library(tidyverse)       # Data wrangling
library(readxl)          # Read Excel files
library(caret)           # ML framework & cross-validation
library(glmnet)          # Elastic Net
library(randomForest)    # Random Forest
library(xgboost)         # XGBoost
library(MASS)            # LDA
library(factoextra)      # PCA visualization

# Check structure
summary(train_categorical_metadata)
summary(train_functional_connectome)
summary(train_quantitative_metadata)
glimpse(training_solutions)

```

```{r}
# Ensure all datasets have a common key (e.g., "participant_id")
merged_data <- train_categorical_metadata %>%
  inner_join(train_quantitative_metadata, by = "participant_id") %>%
  inner_join(train_functional_connectome, by = "participant_id") %>%
  inner_join(training_solutions, by = "participant_id")

# Drop participant_id column (not needed for ML)
merged_data <- merged_data %>% dplyr::select(-participant_id)

# Convert categorical variables (sex, ADHD) to factors
merged_data$sex <- as.factor(merged_data$sex)
merged_data$ADHD <- as.factor(merged_data$ADHD)

```

checked no missing; outlier might matter

```{r}
# Identify functional connectome columns based on pattern
connectome_columns <- grep("^[0-9]+throw_[0-9]+thcolumn$", names(merged_data), value = TRUE)

# Extract functional connectome data
connectome_data <- merged_data %>% dplyr::select(all_of(connectome_columns))

# Extract non-connectome metadata & outcomes
metadata <- merged_data %>% dplyr::select(-all_of(connectome_columns))
colnames(metadata)
```

```{r}
# Perform PCA on functional connectome data
pca_result <- prcomp(connectome_data, center = TRUE, scale. = FALSE)  # No scaling

# Determine number of components explaining 95% variance
explained_variance <- cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2)
num_pcs <- which(explained_variance >= 0.95)[1]

# Select PCA components for training
pca_data <- as.data.frame(pca_result$x[, 1:num_pcs])
pca_data$sex <- metadata$Sex_F
pca_data$ADHD <- metadata$ADHD_Outcome

# Check PCA variance plot
fviz_eig(pca_result)

```

```{r}
# Define cross-validation method (5-fold CV)
control <- trainControl(method = "cv", number = 5)

# Define features (X) and labels (Y)
X <- pca_data %>% dplyr::select(-sex, -ADHD)
Y_sex <- pca_data$sex
Y_ADHD <- pca_data$ADHD


Y_sex <- factor(Y_sex)
Y_ADHD <- factor(Y_ADHD)
```

```{r}
set.seed(123)
rf_model_sex <- train(X, Y_sex, method = "rf", trControl = control, tuneLength = 5)
rf_model_ADHD <- train(X, Y_ADHD, method = "rf", trControl = control, tuneLength = 5)

saveRDS(rf_model_sex, "rf_model_sex.rds")
saveRDS(rf_model_ADHD, "rf_model_ADHD.rds")

```

```{r}
lgb_train_sex <- lgb.Dataset(as.matrix(X), label = as.numeric(Y_sex) - 1)
lgb_train_ADHD <- lgb.Dataset(as.matrix(X), label = as.numeric(Y_ADHD) - 1)

# **(B) LightGBM Tuning**
lgb_params <- list(
    objective = "binary",
    metric = "auc",
    boosting = "gbdt",
    num_leaves = 31,
    learning_rate = 0.05,
    feature_fraction = 0.8,
    lambda_l1 = 0.1,   # L1 regularization (Lasso)
    lambda_l2 = 0.1    # L2 regularization (Ridge)
)

# Train LightGBM for Sex classification
set.seed(123)
lightgbm_model_sex <- lgb.train(params = lgb_params, data = lgb_train_sex, nrounds = 100)

# Train LightGBM for ADHD classification
set.seed(123)
lightgbm_model_ADHD <- lgb.train(params = lgb_params, data = lgb_train_ADHD, nrounds = 100)


saveRDS(lightgbm_model_sex, "lightgbm_model_sex.rds")
saveRDS(lightgbm_model_ADHD, "lightgbm_model_ADHD.rds")

```

```{r}
# Define 5-fold cross-validation

# Define XGBoost parameters
xgb_grid <- expand.grid(
    nrounds = c(100, 200),          # Number of boosting rounds
    max_depth = c(3, 6, 9),         # Depth of trees
    eta = c(0.01, 0.05, 0.1),       # Learning rate
    gamma = c(0, 1),                # Minimum loss reduction
    colsample_bytree = c(0.7, 1),   # Subsampling for columns
    min_child_weight = c(1, 3),     # Minimum sum of instance weight
    subsample = c(0.7, 1)           # Fraction of samples used per tree
)

# Train XGBoost model for Sex classification
set.seed(123)
xgb_model_sex <- train(
    X, Y_sex,
    method = "xgbTree",
    trControl = control,
    tuneGrid = xgb_grid
)

# Train XGBoost model for ADHD classification
set.seed(123)
xgb_model_ADHD <- train(
    X, Y_ADHD,
    method = "xgbTree",
    trControl = control,
    tuneGrid = xgb_grid
)


saveRDS(xgb_model_sex, "xgb_model_sex.rds")
saveRDS(xgb_model_ADHD, "xgb_model_ADHD.rds")

```


```{r}
set.seed(123)
# Convert outcomes to factors (binary classification)


lda_model_sex <- train(X, Y_sex, method = "lda", trControl = control)
lda_model_ADHD <- train(X, Y_ADHD, method = "lda", trControl = control)

saveRDS(lda_model_sex, "lda_model_sex.rds")
saveRDS(lda_model_ADHD, "lda_model_ADHD.rds")

```

```{r}
# Train LDA with Regularization
set.seed(123)
lda_model_ADHD_reg <- train(X, Y_ADHD, method = "sda", trControl = control)  # "sda" = Shrinkage Discriminant Analysis
lda_model_sex_reg <- train(X, Y_sex, method = "sda", trControl = control)


saveRDS(lda_model_sex_reg, "lda_model_sex_reg.rds")
saveRDS(lda_model_ADHD_reg, "lda_model_ADHD_reg.rds")
```


```{r}
# **(D) Elastic Net Tuning**
elastic_grid <- expand.grid(alpha = seq(0, 1, by = 0.1), lambda = 10^seq(-3, 3, length = 10))
set.seed(123)
elastic_net_model_sex <- train(X, Y_sex, method = "glmnet", trControl = control, tuneGrid = elastic_grid)
elastic_net_model_ADHD <- train(X, Y_ADHD, method = "glmnet", trControl = control, tuneGrid = elastic_grid)

saveRDS(elastic_net_model_sex, "elastic_net_model_sex.rds")
saveRDS(elastic_net_model_ADHD, "elastic_net_model_ADHD.rds")

```


```{r}
# Compare model performance
results_sex <- resamples(list(#RF = rf_model_sex, 
                              LightGBM = lightgbm_model_sex, 
                              LDA = lda_model_sex, 
                              LDA_reg = lda_model_sex_reg,
                              ElasticNet = elastic_net_model_sex))
results_ADHD <- resamples(list(#RF = rf_model_ADHD, 
                               LightGBM = lightgbm_model_ADHD, 
                               LDA = lda_model_ADHD, 
                               LDA_reg = lda_model_ADHD_reg,
                               ElasticNet = elastic_net_model_ADHD))

# Print model performance summary
summary(results_sex)
summary(results_ADHD)



```

```{r}
rf_model_ADHD
lightgbm_model_ADHD
lda_model_ADHD
elastic_net_model_ADHD

```

```{r}
# Boxplot for model performance comparison
plot(results_sex)
bwplot(results_ADHD)
bwplot(results_sex)  # Change to "ROC" if available


# Save trained models
saveRDS(rf_model_sex, "rf_model_sex.rds")
saveRDS(lightgbm_model_sex, "lightgbm_model_sex.rds")
saveRDS(lda_model_sex, "lda_model_sex.rds")
saveRDS(elastic_net_model_sex, "elastic_net_model_sex.rds")

saveRDS(rf_model_ADHD, "rf_model_ADHD.rds")
saveRDS(lightgbm_model_ADHD, "lightgbm_model_ADHD.rds")
saveRDS(lda_model_ADHD, "lda_model_ADHD.rds")
saveRDS(elastic_net_model_ADHD, "elastic_net_model_ADHD.rds")
```

