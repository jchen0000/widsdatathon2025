{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLZUMM1eQEtZ0xk99FODve",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen0000/widsdatathon2025/blob/main/python/Lasso_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Import"
      ],
      "metadata": {
        "id": "mY3xblER-9qb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OgAF8gI-xyc"
      },
      "outputs": [],
      "source": [
        "# prompt: Access data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Import solution w outcome data (1213, 3)\n",
        "train_sol = pd.read_excel(\"drive/My Drive/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
        "\n",
        "# Import train MRI data (1213, 19901)\n",
        "train_mri_filepath = \"drive/My Drive/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\"\n",
        "train_mri = pd.read_csv(train_mri_filepath)\n",
        "\n",
        "# Remove first line, convert csv file to a functional connectome matrix\n",
        "train_matrix_data = train_mri.iloc[:, 1:].to_numpy(dtype=float)  # (1213, 19900)\n",
        "\n",
        "# Import Train Data\n",
        "!wget \"https://github.com/jchen0000/widsdatathon2025/blob/main/data/train/TRAIN_CATEGORICAL_METADATA_imputed_Jing.xlsx?raw=true\" -O train_cat2.xlsx\n",
        "train_cat2 = pd.read_excel(\"train_cat2.xlsx\")      # (1213, 10)\n",
        "\n",
        "!wget \"https://github.com/jchen0000/widsdatathon2025/blob/main/data/train/TRAIN_QUANTITATIVE_METADATA_imputed_Jing.xlsx?raw=true\" -O train_quant2.xlsx\n",
        "train_quant2 = pd.read_excel(\"train_quant2.xlsx\")  # (1213, 19)\n",
        "\n",
        "# Merge train datasets on the participant ID\n",
        "combined_train_data2 = pd.merge(train_cat2, train_quant2, on='participant_id')\n",
        "train_with_outcome2 = pd.merge(combined_train_data2, train_sol, on='participant_id')  # (1213, 30)\n",
        "\n",
        "# Combine metadata and fMRI into one feature matrix\n",
        "features2 = np.hstack([combined_train_data2, train_matrix_data])\n",
        "\n",
        "# Remove patient ID\n",
        "combined_metadata_imputed = features2[:, 1:]\n",
        "combined_metadata_imputed = combined_metadata_imputed.astype(float)  # (1213, 19927)\n",
        "\n",
        "\n",
        "\n",
        "# Import test MRI data\n",
        "test_mri_filepath = \"drive/My Drive/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\"\n",
        "test_mri = pd.read_csv(test_mri_filepath)\n",
        "\n",
        "# Remove first line, convert csv file to a functional connectome matrix\n",
        "test_matrix_data = test_mri.iloc[:, 1:].to_numpy(dtype=float)  # (304, 19900)\n",
        "\n",
        "# Import test Data\n",
        "!wget \"https://github.com/jchen0000/widsdatathon2025/blob/main/data/train/TEST_CATEGORICAL_METADATA_imputed_Jing_new.xlsx?raw=true\" -O test_cat2.xlsx\n",
        "test_cat2 = pd.read_excel(\"test_cat2.xlsx\")      # (304, 28)\n",
        "\n",
        "!wget \"https://github.com/jchen0000/widsdatathon2025/blob/main/data/train/TEST_QUANTITATIVE_METADATA_imputed_Jing_new.xlsx?raw=true\" -O test_quant2.xlsx\n",
        "test_quant2 = pd.read_excel(\"test_quant2.xlsx\")  # (304, 28)\n",
        "\n",
        "# Merge test datasets on the participant ID\n",
        "combined_test_data2 = pd.merge(test_cat2, test_quant2, on='participant_id')\n",
        "test_no_id2 = combined_test_data2.drop(columns=['participant_id'])\n",
        "\n",
        "test_patient_ids = combined_test_data2['participant_id'].values  # Extract patient IDs using column name\n",
        "\n",
        "# Combine metadata and fMRI into one feature matrix\n",
        "test_features2 = np.hstack([combined_test_data2, test_matrix_data])\n",
        "\n",
        "\n",
        "# Remove patient ID\n",
        "combined_test_metadata_imputed = test_features2[:, 1:]\n",
        "combined_test_metadata_imputed = combined_test_metadata_imputed.astype(float)  # (304, 19927)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "-9qQWFKh-6or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Define the function to compute weighted F1 score ---\n",
        "def compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex):\n",
        "    \"\"\"\n",
        "    Compute the final weighted F1 score for the competition.\n",
        "    Female ADHD cases (where ADHD_Outcome==1 and Sex_F==1) are given 2x weight.\n",
        "    The final score is the average of the weighted F1 for ADHD_Outcome and the F1 for Sex_F.\n",
        "    \"\"\"\n",
        "    # Create sample weights for ADHD_Outcome: weight=2 for female ADHD cases, else 1.\n",
        "    weights = np.ones_like(y_true_adhd, dtype=float)\n",
        "    weights[(y_true_adhd == 1) & (y_true_sex == 1)] = 2.0\n",
        "\n",
        "    # Calculate weighted F1 for ADHD_Outcome\n",
        "    f1_adhd = f1_score(y_true_adhd, y_pred_adhd, sample_weight=weights)\n",
        "    # Calculate standard F1 for Sex_F\n",
        "    f1_sex = f1_score(y_true_sex, y_pred_sex)\n",
        "\n",
        "    # Final leaderboard score: average of the two F1 scores\n",
        "    final_f1 = (f1_adhd + f1_sex) / 2.0\n",
        "    return final_f1, f1_adhd, f1_sex\n",
        "\n",
        "# --- Prepare the data ---\n",
        "# Use combined_metadata_imputed as input features.\n",
        "X = combined_metadata_imputed  # (1213, 19927)\n",
        "# Extract targets from train_sol:\n",
        "y_adhd = train_sol['ADHD_Outcome'].values  # Binary labels (0 or 1)\n",
        "y_sex  = train_sol['Sex_F'].values         # Binary labels (0 or 1)\n",
        "\n",
        "# Standardize features.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and validation sets.\n",
        "# Note: We split the labels separately but the splits will be aligned because we use the same X_scaled.\n",
        "X_train_split, X_val_split, y_train_adhd_split, y_val_adhd_split = train_test_split(\n",
        "    X_scaled, y_adhd, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_train_sex_split, y_val_sex_split = train_test_split(\n",
        "    X_scaled, y_sex, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- Build the multi-output neural network model ---\n",
        "input_layer = Input(shape=(X_train_split.shape[1],))\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "# Two separate output layers:\n",
        "output_adhd = Dense(1, activation='sigmoid', name='adhd_output')(x)\n",
        "output_sex  = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[output_adhd, output_sex])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics={'adhd_output': 'accuracy', 'sex_output': 'accuracy'})\n",
        "\n",
        "\n",
        "# Set up early stopping.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# --- Train the model ---\n",
        "history = model.fit(\n",
        "    X_train_split,\n",
        "    {'adhd_output': y_train_adhd_split, 'sex_output': y_train_sex_split},\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_split, {'adhd_output': y_val_adhd_split, 'sex_output': y_val_sex_split}),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# --- Evaluate the model ---\n",
        "results = model.evaluate(X_val_split, {'adhd_output': y_val_adhd_split, 'sex_output': y_val_sex_split})\n",
        "print(\"Evaluation Results:\", results)\n",
        "\n",
        "# --- Make predictions on the validation set ---\n",
        "predictions = model.predict(X_val_split)\n",
        "# predictions is a list: predictions[0] for ADHD_Outcome, predictions[1] for Sex_F.\n",
        "y_val_pred_adhd = (predictions[0] > 0.5).astype(int).flatten()\n",
        "y_val_pred_sex  = (predictions[1] > 0.5).astype(int).flatten()\n",
        "\n",
        "# --- Compute the weighted F1 score ---\n",
        "final_f1, f1_adhd, f1_sex = compute_weighted_f1(y_val_adhd_split, y_val_pred_adhd, y_val_sex_split, y_val_pred_sex)\n",
        "\n",
        "print(f\"ADHD F1 Score (weighted): {f1_adhd:.4f}\")\n",
        "print(f\"Sex_F F1 Score: {f1_sex:.4f}\")\n",
        "print(f\"Final Weighted F1 Score: {final_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aJiAMMR9-2E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold Tuning"
      ],
      "metadata": {
        "id": "rqyP44sK_Axz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For ADHD:\n",
        "#    y_val_adhd_prob: predicted probabilities from the model for ADHD_Outcome (shape: (n_samples,))\n",
        "#    y_val_adhd: true ADHD_Outcome labels (0 or 1)\n",
        "# For Sex_F:\n",
        "#    y_val_sex_prob: predicted probabilities from the model for Sex_F (shape: (n_samples,))\n",
        "#    y_val_sex: true Sex_F labels (0 or 1)\n",
        "\n",
        "y_val_adhd_prob = predictions[0].flatten()\n",
        "y_val_sex_prob  = predictions[1].flatten()\n",
        "\n",
        "# --- Define the function to compute weighted F1 score ---\n",
        "def compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex):\n",
        "    \"\"\"\n",
        "    Compute the final weighted F1 score.\n",
        "    Female ADHD cases (where ADHD_Outcome==1 and Sex_F==1) are given 2x weight.\n",
        "    Returns:\n",
        "       final_f1: the average of the weighted ADHD F1 and the Sex_F F1.\n",
        "       f1_adhd: F1 score for ADHD_Outcome using sample weights.\n",
        "       f1_sex:  F1 score for Sex_F (unweighted).\n",
        "    \"\"\"\n",
        "    weights = np.ones_like(y_true_adhd, dtype=float)\n",
        "    weights[(y_true_adhd == 1) & (y_true_sex == 1)] = 2.0\n",
        "    f1_adhd = f1_score(y_true_adhd, y_pred_adhd, sample_weight=weights)\n",
        "    f1_sex = f1_score(y_true_sex, y_pred_sex)\n",
        "    final_f1 = (f1_adhd + f1_sex) / 2.0\n",
        "    return final_f1, f1_adhd, f1_sex\n",
        "\n",
        "# --- Define a range of thresholds to test ---\n",
        "#thresholds = np.linspace(0, 1, 101)  # from 0.00 to 1.00 in steps of 0.01\n",
        "thresholds = np.linspace(0.2, 0.99, 98)\n",
        "\n",
        "best_final_f1 = 0.0\n",
        "best_thr_adhd = 0.0\n",
        "best_thr_sex  = 0.0\n",
        "best_f1_adhd = 0.0\n",
        "best_f1_sex  = 0.0\n",
        "\n",
        "# --- Perform a 2D threshold sweep ---\n",
        "for thr_a in thresholds:\n",
        "    for thr_s in thresholds:\n",
        "        y_pred_adhd = (y_val_adhd_prob > thr_a).astype(int)\n",
        "        y_pred_sex  = (y_val_sex_prob > thr_s).astype(int)\n",
        "        final_f1, f1_adhd, f1_sex = compute_weighted_f1(y_val_adhd_split, y_pred_adhd, y_val_sex_split, y_pred_sex)\n",
        "        if final_f1 > best_final_f1:\n",
        "            best_final_f1 = final_f1\n",
        "            best_thr_adhd = thr_a\n",
        "            best_thr_sex  = thr_s\n",
        "            best_f1_adhd = f1_adhd\n",
        "            best_f1_sex  = f1_sex\n",
        "\n",
        "print(f\"Best ADHD Threshold: {best_thr_adhd:.2f} with F1: {best_f1_adhd:.4f}\")\n",
        "print(f\"Best Sex_F Threshold: {best_thr_sex:.2f} with F1: {best_f1_sex:.4f}\")\n",
        "print(f\"Best Final Weighted F1: {best_final_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4StHMFS5_BM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold Tuning Graph"
      ],
      "metadata": {
        "id": "k9vBUnn6_ICy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a threshold tuning graph for ADHD and Sex_F\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_val_adhd_prob, y_val_sex_prob, y_val_adhd_split, and y_val_sex_split are defined as in your code.\n",
        "\n",
        "# Function to compute the weighted F1 score (same as before)\n",
        "def compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex):\n",
        "    weights = np.ones_like(y_true_adhd, dtype=float)\n",
        "    weights[(y_true_adhd == 1) & (y_true_sex == 1)] = 2.0\n",
        "    f1_adhd = f1_score(y_true_adhd, y_pred_adhd, sample_weight=weights)\n",
        "    f1_sex = f1_score(y_true_sex, y_pred_sex)\n",
        "    final_f1 = (f1_adhd + f1_sex) / 2.0\n",
        "    return final_f1, f1_adhd, f1_sex\n",
        "\n",
        "\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "f1_scores_adhd = []\n",
        "f1_scores_sex = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_adhd = (y_val_adhd_prob > threshold).astype(int)\n",
        "    y_pred_sex = (y_val_sex_prob > threshold).astype(int)\n",
        "    _, f1_adhd, f1_sex = compute_weighted_f1(y_val_adhd_split, y_pred_adhd, y_val_sex_split, y_pred_sex)\n",
        "    f1_scores_adhd.append(f1_adhd)\n",
        "    f1_scores_sex.append(f1_sex)\n",
        "\n",
        "# Plotting the threshold tuning graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, f1_scores_adhd, label='ADHD F1 Score')\n",
        "plt.plot(thresholds, f1_scores_sex, label='Sex_F F1 Score')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Threshold Tuning Graph for ADHD and Sex_F')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uANRbZqC_KHQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}