{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen0000/widsdatathon2025/blob/main/python/CNN_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f-urbtYjabWr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zcNRu2naL_x"
      },
      "source": [
        "# Neural Networks\n",
        "\n",
        "This page includes neural network models:\n",
        "- NN\n",
        "- CNN: 1D & 2D\n",
        "- GCN: GCN, GAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azsx2ofPaccU"
      },
      "source": [
        "## Data Loading\n",
        "Data processing notebook: [python/00_data_formating_and_imputation.ipynb](https://github.com/jchen0000/widsdatathon2025/blob/main/python/00_data_formating_and_imputation.ipynb)\n",
        "\n",
        "Datasets available:\n",
        "1. `df_train_mri` and `df_test_mri`: original train and test MRI flatten fc matrix\n",
        "2. `df_train_meta_imputed` and `df_test_meta_imputed`: imputed train and test meta data (quant and cat combined)\n",
        "3. `connectome_matrices` and `connectome_matrices_test`: reshaped 2d fc matrix (correlation matrix) for train and test\n",
        "4. `df_train_y`: train response data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMUOAs4ArNVI",
        "outputId": "f5fa4444-1a7a-4de1-b1e2-f7f466c4938d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/widsdatathon2025\n",
            " \u001b[0m\u001b[01;34mcv_results\u001b[0m/             SAMPLE_SUBMISSION.xlsx   test_imputed_test.xlsx\n",
            "'Data Dictionary.xlsx'   \u001b[01;34msubmission\u001b[0m/              \u001b[01;34mTRAIN\u001b[0m/\n",
            " \u001b[01;34mgnn\u001b[0m/                    \u001b[01;34mTEST\u001b[0m/                    \u001b[01;34mWork\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## suppose you've created a folder named \"widsdatathon2025\"\n",
        "%cd /content/drive/MyDrive/widsdatathon2025/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load from Jiaqi's file"
      ],
      "metadata": {
        "id": "Y1vzqw3RPu3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## load data\n",
        "df_train_X = pd.read_csv('./Work/jiaqi_imputed/lasso_imputed_train.csv')\n",
        "df_train_X = df_train_X.values\n",
        "\n",
        "df_test_X = pd.read_csv('./Work/jiaqi_imputed/lasso_imputed_test.csv')\n",
        "df_test_X = df_test_X.values\n",
        "\n",
        "df_train_y = pd.read_excel(\"./TRAIN/TRAINING_SOLUTIONS.xlsx\")\n",
        "df_train_y.set_index('participant_id', inplace=True)\n",
        "print(df_train_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-XIOBh_PvA1",
        "outputId": "d150ef73-23b5-45c5-891f-31a0f1b553ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1213, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get column and index\n",
        "df_train_meta = pd.read_excel(\"./TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx\")\n",
        "df_train_meta.set_index('participant_id', inplace=True)\n",
        "print(df_train_meta.shape)\n",
        "\n",
        "df_test_meta = pd.read_excel(\"./TEST/TEST_CATEGORICAL.xlsx\")\n",
        "df_test_meta.set_index('participant_id', inplace=True)\n",
        "print(df_test_meta.shape)\n",
        "\n",
        "dtm = pd.read_csv(\"./TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "dtm.set_index('participant_id', inplace=True)\n",
        "print(dtm.shape)\n",
        "\n",
        "train_idx = df_train_meta.index.values\n",
        "test_idx = df_test_meta.index.values\n",
        "meta_cols = df_test_meta.columns.values\n",
        "mri_cols = dtm.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdRhP9y-TQd8",
        "outputId": "44d1992e-11db-43f3-eec5-5ed68e7da70b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1213, 9)\n",
            "(304, 9)\n",
            "(304, 19900)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write function to standardize and normalize the df_train_X and df_test_X\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_train_X_std = scaler.fit_transform(df_train_X)\n",
        "df_test_X_std = scaler.transform(df_test_X)\n",
        "\n",
        "normalizer = MinMaxScaler()\n",
        "df_train_X_scaled = normalizer.fit_transform(df_train_X_std)\n",
        "df_test_X_scaled = normalizer.transform(df_test_X_std)\n",
        "\n"
      ],
      "metadata": {
        "id": "CUlCxSmaFOXc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Standardize features.\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# df_train_X_scaled = scaler.fit_transform(df_train_X)\n",
        "# df_test_X_scaled = scaler.transform(df_test_X)\n",
        "\n"
      ],
      "metadata": {
        "id": "XiVGlmnoSMVd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### split into mri and meta data\n",
        "df_train_mri = df_train_X_scaled[:, 27:]\n",
        "df_train_meta_imputed = df_train_X_scaled[:, :27]\n",
        "print(df_train_mri.shape)\n",
        "\n",
        "df_test_mri = df_test_X_scaled[:, 27:]\n",
        "df_test_meta_imputed = df_test_X_scaled[:, :27]\n",
        "print(df_test_mri.shape)\n",
        "\n",
        "df_train_mri = pd.DataFrame(df_train_mri, columns=mri_cols, index=df_train_meta.index)\n",
        "df_test_mri = pd.DataFrame(df_test_mri, columns=mri_cols, index=df_test_meta.index)"
      ],
      "metadata": {
        "id": "lGUI0vovlLtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e8c55b-832d-41dc-c9f3-b638f8da1d1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1213, 19900)\n",
            "(304, 19900)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "JMkDlbQ04XTw",
        "outputId": "5c3351b8-7417-4dea-acfa-201222cc9af6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ADHD_Outcome  Sex_F\n",
              "1             0        581\n",
              "              1        250\n",
              "0             0        216\n",
              "              1        166\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXiFcnmDQHxB"
      },
      "source": [
        "#### Load from docs folloing Jiaqi's process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCcyPXZrQGrt",
        "outputId": "ed16a606-3626-4deb-af76-fe11e12d33e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 2)\n"
          ]
        }
      ],
      "source": [
        "# with np.load('./Work/scaled_data_jiaqi.npz') as data:\n",
        "#   X_train_scaled = data['X_train_scaled']\n",
        "#   X_test_scaled = data['X_test_scaled']\n",
        "\n",
        "# df_train_y = pd.read_excel(\"./TRAIN/TRAINING_SOLUTIONS.xlsx\")\n",
        "# df_train_y.set_index('participant_id', inplace=True)\n",
        "# print(df_train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4lW1UKMXfQ7",
        "outputId": "3f4652a9-12d8-4849-ac14-f2dbc61c13e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 19927)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(304, 19927)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('./Work/scaled_data_jiaqi.pkl', 'rb') as f:\n",
        "  loaded_data = pickle.load(f)\n",
        "\n",
        "X_train_scaled = loaded_data['X_train_scaled']\n",
        "X_test_scaled = loaded_data['X_test_scaled']\n",
        "# X_test_scaled = loaded_data['X_test_scaled']\n",
        "\n",
        "print(X_train_scaled.shape)\n",
        "X_test_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl1bwRbLg1TL",
        "outputId": "0eaef06b-6fba-4c6e-cf62-78f972b84b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 2)\n"
          ]
        }
      ],
      "source": [
        "df_train_X = X_train_scaled\n",
        "df_test_X = X_test_scaled\n",
        "\n",
        "df_train_y = pd.read_excel(\"./TRAIN/TRAINING_SOLUTIONS.xlsx\")\n",
        "df_train_y.set_index('participant_id', inplace=True)\n",
        "print(df_train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmDCUKz6VnqX",
        "outputId": "8d0569dc-e14f-487b-8c4d-29546eca1462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(304, 19900)\n",
            "(304, 27)\n"
          ]
        }
      ],
      "source": [
        "df_train_mri = X_train_scaled.iloc[:, :19900]\n",
        "df_train_meta_imputed = X_train_scaled.iloc[:, 19900:]\n",
        "df_test_mri = X_test_scaled.iloc[:, :19900]\n",
        "df_test_meta_imputed = X_test_scaled.iloc[:, 19900:]\n",
        "print(df_test_mri.shape)\n",
        "print(df_test_meta_imputed.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pS1PDMG5ktQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshape Matrix"
      ],
      "metadata": {
        "id": "vufYR0OGkt85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39MPSgouVvF7",
        "outputId": "f61e35c0-9f1d-4bb6-ed89-2030e7fc7470"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1213, 200, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "## reconstruct connecticome matrix\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "def connectivity_vector_to_matrix(vector, n=200):\n",
        "    \"\"\"\n",
        "    Converts a connectivity vector (flattened upper-triangular part of a 200x200 matrix)\n",
        "    into a graph representation:\n",
        "      - X: Node feature matrix (all ones, shape: [n, 1])\n",
        "      - A: Adjacency matrix (dense, shape: [n, n])\n",
        "    \"\"\"\n",
        "    A = squareform(vector)\n",
        "    np.fill_diagonal(A, 0)\n",
        "    # X = np.ones((n, 1))\n",
        "    # X = np.eye(n,n)\n",
        "    # A = create_adjacency_matrix(A, threshold=0.5)\n",
        "    # A = A.astype(np.float32)\n",
        "    return A\n",
        "\n",
        "connectome_matrices = np.array([connectivity_vector_to_matrix(row.values) for _, row in df_train_mri.iterrows()])\n",
        "connectome_matrices_test = np.array([connectivity_vector_to_matrix(row.values) for _, row in df_test_mri.iterrows()])\n",
        "connectome_matrices.shape\n",
        "\n",
        "# import re\n",
        "\n",
        "# def extract_numbers(input_string):\n",
        "#   match = re.match(r\"(\\d+)throw_(\\d+)thcolumn\", input_string)\n",
        "#   if match:\n",
        "#     n = int(match.group(1))\n",
        "#     m = int(match.group(2))\n",
        "#     return n, m\n",
        "#   return None, None\n",
        "\n",
        "# def create_connectome_matrix(row):\n",
        "#   \"\"\"Creates a connectome matrix from a row of the dataframe.\n",
        "\n",
        "#   Args:\n",
        "#     row: A pandas Series representing a row of df_train_mri.\n",
        "\n",
        "#   Returns:\n",
        "#     A NumPy array representing the connectome matrix.\n",
        "#   \"\"\"\n",
        "#   # print(row)\n",
        "\n",
        "#   matrix = np.zeros((200, 200))\n",
        "#   for col_name, value in row.items():\n",
        "#     if isinstance(col_name, str):\n",
        "#       try:\n",
        "#         # print(col_name)\n",
        "#         nth_row, mth_col = extract_numbers(col_name)\n",
        "#         # print(nth_row, mth_col)\n",
        "#         if nth_row is not None and nth_row < 200 and mth_col < 200:\n",
        "#           matrix[nth_row, mth_col] = value\n",
        "#           matrix[mth_col, nth_row] = value\n",
        "#           # if nth_row < 5 and mth_col < 5:\n",
        "#           #   print(matrix[:5, :5])\n",
        "#       except ValueError:\n",
        "#         print('value error detected')\n",
        "#         pass  # Ignore columns that don't match the pattern\n",
        "#   np.fill_diagonal(matrix, 1)\n",
        "#   # print(matrix[:5,:5])\n",
        "#   return matrix\n",
        "\n",
        "\n",
        "# connectome_matrices = np.array([create_connectome_matrix(row) for _, row in df_train_mri.iterrows()])\n",
        "# connectome_matrices_test = np.array([create_connectome_matrix(row) for _, row in df_test_mri.iterrows()])\n",
        "# connectome_matrices.shape\n",
        "\n",
        "# print(df_train_mri.iloc[0:5, :5])\n",
        "# connectome_matrices[1,:5,:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wx08ZAME_mK"
      },
      "source": [
        "#### Load standardized files from pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw6cMaMNE74X",
        "outputId": "293a469a-557b-4676-fa5a-987d1f378358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data loaded successfully.\n",
            "Test data loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# prompt: load the pickle files\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load the training data\n",
        "with open('./Work/data_train_scaled_yiru.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "print(\"Training data loaded successfully.\")\n",
        "\n",
        "# Load the test data\n",
        "with open('./Work/data_test_scaled_yiru.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "print(\"Test data loaded successfully.\")\n",
        "\n",
        "# Access the loaded data\n",
        "connectome_matrices = train_data['connectome_matrices']\n",
        "df_train_mri = train_data['df_train_mri']\n",
        "df_train_meta_imputed = train_data['df_train_meta_imputed']\n",
        "\n",
        "connectome_matrices_test = test_data['connectome_matrices_test']\n",
        "df_test_mri = test_data['df_test_mri']\n",
        "df_test_meta_imputed = test_data['df_test_meta_imputed']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX_XW5qcFDc6",
        "outputId": "c24b6979-2a70-4a54-9185-a986cb8f033a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 2)\n"
          ]
        }
      ],
      "source": [
        "df_train_y = pd.read_excel('./TRAIN/TRAINING_SOLUTIONS.xlsx')\n",
        "df_train_y.set_index('participant_id', inplace=True)\n",
        "print(df_train_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzdLsh4gFENt"
      },
      "source": [
        "#### Load individual files and large imputation file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "XNs7ktMCaLql",
        "outputId": "ea44833c-0a49-45ba-e702-08b2f809d9cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 19900)\n",
            "(1213, 200, 200)\n",
            "(1213, 27)\n",
            "(1213, 19927)\n",
            "(1213, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_meta_imputed"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-96676341-1204-4ce6-83c9-25056f5da413\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Basic_Demos_Enroll_Year</th>\n",
              "      <th>Basic_Demos_Study_Site</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
              "      <th>MRI_Track_Scan_Location</th>\n",
              "      <th>Barratt_Barratt_P1_Edu</th>\n",
              "      <th>Barratt_Barratt_P1_Occ</th>\n",
              "      <th>Barratt_Barratt_P2_Edu</th>\n",
              "      <th>Barratt_Barratt_P2_Occ</th>\n",
              "      <th>EHQ_EHQ_Total</th>\n",
              "      <th>...</th>\n",
              "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
              "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
              "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
              "      <th>SDQ_SDQ_Externalizing</th>\n",
              "      <th>SDQ_SDQ_Generating_Impact</th>\n",
              "      <th>SDQ_SDQ_Hyperactivity</th>\n",
              "      <th>SDQ_SDQ_Internalizing</th>\n",
              "      <th>SDQ_SDQ_Peer_Problems</th>\n",
              "      <th>SDQ_SDQ_Prosocial</th>\n",
              "      <th>MRI_Track_Age_at_Scan</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>participant_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70z8Q2xdTXM3</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>45</td>\n",
              "      <td>21</td>\n",
              "      <td>45</td>\n",
              "      <td>28.88</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>11.889002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WHWymJu6zNZi</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>14.47</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.670088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4PAQp1M6EyAo</th>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>35</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>26.68</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>7.743896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obEacy4Of68I</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>55.67</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>12.116723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>s7WzzDcmDOhF</th>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-26.68</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8.903490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96676341-1204-4ce6-83c9-25056f5da413')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96676341-1204-4ce6-83c9-25056f5da413 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96676341-1204-4ce6-83c9-25056f5da413');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b15ae75-ecd4-4387-9ca0-84182b9a1ce7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b15ae75-ecd4-4387-9ca0-84182b9a1ce7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b15ae75-ecd4-4387-9ca0-84182b9a1ce7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
              "participant_id                                                    \n",
              "70z8Q2xdTXM3                       2018                       1   \n",
              "WHWymJu6zNZi                       2015                       1   \n",
              "4PAQp1M6EyAo                       2019                       1   \n",
              "obEacy4Of68I                       2017                       1   \n",
              "s7WzzDcmDOhF                       2019                       1   \n",
              "\n",
              "                PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
              "participant_id                                                                  \n",
              "70z8Q2xdTXM3                                 0.0                            1   \n",
              "WHWymJu6zNZi                                 1.0                            8   \n",
              "4PAQp1M6EyAo                                 0.0                            0   \n",
              "obEacy4Of68I                                 0.0                            0   \n",
              "s7WzzDcmDOhF                                 2.0                            8   \n",
              "\n",
              "                MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\n",
              "participant_id                                                    \n",
              "70z8Q2xdTXM3                          2                      21   \n",
              "WHWymJu6zNZi                          1                       6   \n",
              "4PAQp1M6EyAo                          2                      18   \n",
              "obEacy4Of68I                          2                      21   \n",
              "s7WzzDcmDOhF                          2                       9   \n",
              "\n",
              "                Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  \\\n",
              "participant_id                                                   \n",
              "70z8Q2xdTXM3                        45                      21   \n",
              "WHWymJu6zNZi                         5                       0   \n",
              "4PAQp1M6EyAo                        35                       9   \n",
              "obEacy4Of68I                        40                      21   \n",
              "s7WzzDcmDOhF                        35                       0   \n",
              "\n",
              "                Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
              "participant_id                                         ...   \n",
              "70z8Q2xdTXM3                        45          28.88  ...   \n",
              "WHWymJu6zNZi                        15          14.47  ...   \n",
              "4PAQp1M6EyAo                        20          26.68  ...   \n",
              "obEacy4Of68I                        40          55.67  ...   \n",
              "s7WzzDcmDOhF                         0         -26.68  ...   \n",
              "\n",
              "                SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
              "participant_id                                                         \n",
              "70z8Q2xdTXM3                           0                           8   \n",
              "WHWymJu6zNZi                           0                           0   \n",
              "4PAQp1M6EyAo                           8                          26   \n",
              "obEacy4Of68I                           0                           7   \n",
              "s7WzzDcmDOhF                           3                          14   \n",
              "\n",
              "                SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
              "participant_id                                                      \n",
              "70z8Q2xdTXM3                             1                      4   \n",
              "WHWymJu6zNZi                             0                      0   \n",
              "4PAQp1M6EyAo                             4                     17   \n",
              "obEacy4Of68I                             2                      4   \n",
              "s7WzzDcmDOhF                             3                      6   \n",
              "\n",
              "                SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  \\\n",
              "participant_id                                                     \n",
              "70z8Q2xdTXM3                            5                      4   \n",
              "WHWymJu6zNZi                            0                      0   \n",
              "4PAQp1M6EyAo                            8                      9   \n",
              "obEacy4Of68I                            1                      4   \n",
              "s7WzzDcmDOhF                            3                      3   \n",
              "\n",
              "                SDQ_SDQ_Internalizing  SDQ_SDQ_Peer_Problems  \\\n",
              "participant_id                                                 \n",
              "70z8Q2xdTXM3                        4                      3   \n",
              "WHWymJu6zNZi                        0                      0   \n",
              "4PAQp1M6EyAo                        9                      5   \n",
              "obEacy4Of68I                        3                      1   \n",
              "s7WzzDcmDOhF                        8                      5   \n",
              "\n",
              "                SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
              "participant_id                                            \n",
              "70z8Q2xdTXM3                    9              11.889002  \n",
              "WHWymJu6zNZi                    0               7.670088  \n",
              "4PAQp1M6EyAo                    8               7.743896  \n",
              "obEacy4Of68I                   10              12.116723  \n",
              "s7WzzDcmDOhF                    6               8.903490  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## train data\n",
        "dir = './TRAIN/' #\"./data/train/\"\n",
        "df_train_mri = pd.read_csv(dir+\"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "df_train_mri.set_index('participant_id', inplace=True)\n",
        "print(df_train_mri.shape)\n",
        "\n",
        "connectome_matrices = np.load(dir+'connectome_matrices_train.npy')\n",
        "print(connectome_matrices.shape)\n",
        "\n",
        "df_train_meta_imputed = pd.read_excel(dir+\"df_train_meta_KNN_imputed_yiru.xlsx\")\n",
        "df_train_meta_imputed.set_index('participant_id', inplace=True)\n",
        "print(df_train_meta_imputed.shape)\n",
        "\n",
        "df_train_X = pd.concat([df_train_mri, df_train_meta_imputed], axis=1)\n",
        "print(df_train_X.shape)\n",
        "\n",
        "df_train_y = pd.read_excel(dir+\"TRAINING_SOLUTIONS.xlsx\")\n",
        "df_train_y.set_index('participant_id', inplace=True)\n",
        "print(df_train_y.shape)\n",
        "\n",
        "# Combine both columns for prediction\n",
        "# (0,0): 0\n",
        "# (0,1): 1\n",
        "# (1,0): 2\n",
        "# (1,1): 3\n",
        "df_train_y_sparse = pd.DataFrame()\n",
        "df_train_y_sparse['sparse_category'] = df_train_y['ADHD_Outcome'] *2 + df_train_y['Sex_F']\n",
        "\n",
        "df_train_meta_imputed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7UpSyYvhd2fy",
        "outputId": "896ccd3c-f2f4-4891-8638-c6aa6d40bf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(304, 19900)\n",
            "(304, 27)\n",
            "(304, 19927)\n",
            "(304, 200, 200)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_meta_imputed"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d45160c7-c1ff-41f9-b0e6-440bfbfdf3dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Basic_Demos_Enroll_Year</th>\n",
              "      <th>Basic_Demos_Study_Site</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
              "      <th>MRI_Track_Scan_Location</th>\n",
              "      <th>Barratt_Barratt_P1_Edu</th>\n",
              "      <th>Barratt_Barratt_P1_Occ</th>\n",
              "      <th>Barratt_Barratt_P2_Edu</th>\n",
              "      <th>Barratt_Barratt_P2_Occ</th>\n",
              "      <th>EHQ_EHQ_Total</th>\n",
              "      <th>...</th>\n",
              "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
              "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
              "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
              "      <th>SDQ_SDQ_Externalizing</th>\n",
              "      <th>SDQ_SDQ_Generating_Impact</th>\n",
              "      <th>SDQ_SDQ_Hyperactivity</th>\n",
              "      <th>SDQ_SDQ_Internalizing</th>\n",
              "      <th>SDQ_SDQ_Peer_Problems</th>\n",
              "      <th>SDQ_SDQ_Prosocial</th>\n",
              "      <th>MRI_Track_Age_at_Scan</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>participant_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cfwaf5FX7jWK</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30</td>\n",
              "      <td>18.0</td>\n",
              "      <td>30</td>\n",
              "      <td>60.03</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.992813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vhGrzmvA3Hjq</th>\n",
              "      <td>2023</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>45</td>\n",
              "      <td>18.6</td>\n",
              "      <td>30</td>\n",
              "      <td>86.71</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.324093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ULliyEXjy4OV</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>40</td>\n",
              "      <td>18.0</td>\n",
              "      <td>40</td>\n",
              "      <td>26.68</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.770933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LZfeAb1xMtql</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>21.0</td>\n",
              "      <td>45</td>\n",
              "      <td>21.0</td>\n",
              "      <td>45</td>\n",
              "      <td>93.38</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.304814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EnFOUv0YK1RG</th>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>45</td>\n",
              "      <td>-93.38</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.261350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d45160c7-c1ff-41f9-b0e6-440bfbfdf3dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d45160c7-c1ff-41f9-b0e6-440bfbfdf3dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d45160c7-c1ff-41f9-b0e6-440bfbfdf3dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1d21fe1-4743-4577-b578-a402dfb2a497\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1d21fe1-4743-4577-b578-a402dfb2a497')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1d21fe1-4743-4577-b578-a402dfb2a497 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
              "participant_id                                                    \n",
              "Cfwaf5FX7jWK                       2022                       4   \n",
              "vhGrzmvA3Hjq                       2023                       4   \n",
              "ULliyEXjy4OV                       2022                       4   \n",
              "LZfeAb1xMtql                       2022                       4   \n",
              "EnFOUv0YK1RG                       2022                       4   \n",
              "\n",
              "                PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
              "participant_id                                                                  \n",
              "Cfwaf5FX7jWK                                 0.0                          0.0   \n",
              "vhGrzmvA3Hjq                                 0.0                          0.0   \n",
              "ULliyEXjy4OV                                 0.0                          0.0   \n",
              "LZfeAb1xMtql                                 0.0                          0.0   \n",
              "EnFOUv0YK1RG                                 2.0                          0.0   \n",
              "\n",
              "                MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\n",
              "participant_id                                                    \n",
              "Cfwaf5FX7jWK                          4                    21.0   \n",
              "vhGrzmvA3Hjq                          4                    21.0   \n",
              "ULliyEXjy4OV                          4                    21.0   \n",
              "LZfeAb1xMtql                          3                    21.0   \n",
              "EnFOUv0YK1RG                          4                    18.0   \n",
              "\n",
              "                Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  \\\n",
              "participant_id                                                   \n",
              "Cfwaf5FX7jWK                        30                    18.0   \n",
              "vhGrzmvA3Hjq                        45                    18.6   \n",
              "ULliyEXjy4OV                        40                    18.0   \n",
              "LZfeAb1xMtql                        45                    21.0   \n",
              "EnFOUv0YK1RG                         0                    21.0   \n",
              "\n",
              "                Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
              "participant_id                                         ...   \n",
              "Cfwaf5FX7jWK                        30          60.03  ...   \n",
              "vhGrzmvA3Hjq                        30          86.71  ...   \n",
              "ULliyEXjy4OV                        40          26.68  ...   \n",
              "LZfeAb1xMtql                        45          93.38  ...   \n",
              "EnFOUv0YK1RG                        45         -93.38  ...   \n",
              "\n",
              "                SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
              "participant_id                                                         \n",
              "Cfwaf5FX7jWK                         2.0                        12.0   \n",
              "vhGrzmvA3Hjq                         2.0                        16.0   \n",
              "ULliyEXjy4OV                         1.0                         7.0   \n",
              "LZfeAb1xMtql                         4.0                        15.0   \n",
              "EnFOUv0YK1RG                         2.0                        18.0   \n",
              "\n",
              "                SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
              "participant_id                                                      \n",
              "Cfwaf5FX7jWK                           3.0                    9.0   \n",
              "vhGrzmvA3Hjq                           8.0                    5.0   \n",
              "ULliyEXjy4OV                           1.0                    6.0   \n",
              "LZfeAb1xMtql                           4.0                   10.0   \n",
              "EnFOUv0YK1RG                           6.0                   12.0   \n",
              "\n",
              "                SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  \\\n",
              "participant_id                                                     \n",
              "Cfwaf5FX7jWK                          2.0                    7.0   \n",
              "vhGrzmvA3Hjq                          7.0                    3.0   \n",
              "ULliyEXjy4OV                          1.0                    5.0   \n",
              "LZfeAb1xMtql                          8.0                    6.0   \n",
              "EnFOUv0YK1RG                          5.0                   10.0   \n",
              "\n",
              "                SDQ_SDQ_Internalizing  SDQ_SDQ_Peer_Problems  \\\n",
              "participant_id                                                 \n",
              "Cfwaf5FX7jWK                      3.0                    0.0   \n",
              "vhGrzmvA3Hjq                     11.0                    3.0   \n",
              "ULliyEXjy4OV                      1.0                    0.0   \n",
              "LZfeAb1xMtql                      5.0                    1.0   \n",
              "EnFOUv0YK1RG                      6.0                    0.0   \n",
              "\n",
              "                SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
              "participant_id                                            \n",
              "Cfwaf5FX7jWK                  8.0               8.992813  \n",
              "vhGrzmvA3Hjq                  9.0              12.324093  \n",
              "ULliyEXjy4OV                  9.0               7.770933  \n",
              "LZfeAb1xMtql                  6.0               9.304814  \n",
              "EnFOUv0YK1RG                 10.0               8.261350  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test data\n",
        "dir = './TEST/'\n",
        "df_test_mri = pd.read_csv(dir+\"TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "df_test_mri.set_index('participant_id', inplace=True)\n",
        "print(df_test_mri.shape)\n",
        "\n",
        "df_test_meta_imputed = pd.read_excel(dir+\"df_test_meta_KNN_imputed_yiru.xlsx\")\n",
        "df_test_meta_imputed.set_index('participant_id', inplace=True)\n",
        "print(df_test_meta_imputed.shape)\n",
        "\n",
        "df_test_X = pd.concat([df_test_mri, df_test_meta_imputed], axis=1)\n",
        "print(df_test_X.shape)\n",
        "\n",
        "connectome_matrices_test = np.load(dir+'connectome_matrices_test.npy')\n",
        "print(connectome_matrices_test.shape)\n",
        "\n",
        "df_test_meta_imputed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emIrHEwodscY",
        "outputId": "b6601e1c-f58c-4023-867c-35920aacd388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of NA values in df_train_X: 0\n",
            "NA value per column (>0): \n",
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "## double check on the test data meta data missing values\n",
        "\n",
        "# check NA in original dataset\n",
        "na_count_old = np.isnan(df_test_X).sum()\n",
        "print(f\"Number of NA values in df_train_X: {na_count_old.sum()}\")\n",
        "print(f\"NA value per column (>0): \\n{na_count_old[na_count_old > 0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUwJW8VToJDw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9S5jI5voKla"
      },
      "source": [
        "#### Test on smaller imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsHumUpYoLSk",
        "outputId": "0909ded1-6864-4d52-fa25-f5f8225415c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 18)\n",
            "(1213, 9)\n",
            "(304, 18)\n",
            "(304, 9)\n"
          ]
        }
      ],
      "source": [
        "dir = './TRAIN/'\n",
        "df_train_meta_quant = pd.read_excel(dir+\"TRAIN_QUANTITATIVE_METADATA.xlsx\")\n",
        "df_train_meta_quant.set_index('participant_id', inplace=True)\n",
        "print(df_train_meta_quant.shape)\n",
        "\n",
        "df_train_meta_cat = pd.read_excel(dir+\"TRAIN_CATEGORICAL_METADATA.xlsx\")\n",
        "df_train_meta_cat.set_index('participant_id', inplace=True)\n",
        "print(df_train_meta_cat.shape)\n",
        "\n",
        "# Test data\n",
        "dir = './TEST/'\n",
        "df_test_meta_quant = pd.read_excel(dir+\"TEST_QUANTITATIVE_METADATA.xlsx\")\n",
        "df_test_meta_quant.set_index('participant_id', inplace=True)\n",
        "print(df_test_meta_quant.shape)\n",
        "\n",
        "df_test_meta_cat = pd.read_excel(dir+\"TEST_CATEGORICAL.xlsx\")\n",
        "df_test_meta_cat.set_index('participant_id', inplace=True)\n",
        "print(df_test_meta_cat.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "5zZBki0wols8",
        "outputId": "4e16dffb-2869-4455-a63e-7291a1d7cd5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1517, 27)\n",
            "(1213, 27)\n",
            "(304, 27)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b20798a3-0fcc-4ebd-89a8-e839430747d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Basic_Demos_Enroll_Year</th>\n",
              "      <th>Basic_Demos_Study_Site</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
              "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
              "      <th>MRI_Track_Scan_Location</th>\n",
              "      <th>Barratt_Barratt_P1_Edu</th>\n",
              "      <th>Barratt_Barratt_P1_Occ</th>\n",
              "      <th>Barratt_Barratt_P2_Edu</th>\n",
              "      <th>Barratt_Barratt_P2_Occ</th>\n",
              "      <th>EHQ_EHQ_Total</th>\n",
              "      <th>...</th>\n",
              "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
              "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
              "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
              "      <th>SDQ_SDQ_Externalizing</th>\n",
              "      <th>SDQ_SDQ_Generating_Impact</th>\n",
              "      <th>SDQ_SDQ_Hyperactivity</th>\n",
              "      <th>SDQ_SDQ_Internalizing</th>\n",
              "      <th>SDQ_SDQ_Peer_Problems</th>\n",
              "      <th>SDQ_SDQ_Prosocial</th>\n",
              "      <th>MRI_Track_Age_at_Scan</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>participant_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cfwaf5FX7jWK</th>\n",
              "      <td>2022.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>60.03</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.992813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vhGrzmvA3Hjq</th>\n",
              "      <td>2023.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>19.2</td>\n",
              "      <td>30.0</td>\n",
              "      <td>86.71</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.324093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b20798a3-0fcc-4ebd-89a8-e839430747d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b20798a3-0fcc-4ebd-89a8-e839430747d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b20798a3-0fcc-4ebd-89a8-e839430747d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e801141b-dde5-4366-8780-e1fb908f1e50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e801141b-dde5-4366-8780-e1fb908f1e50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e801141b-dde5-4366-8780-e1fb908f1e50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
              "participant_id                                                    \n",
              "Cfwaf5FX7jWK                     2022.0                     4.0   \n",
              "vhGrzmvA3Hjq                     2023.0                     4.0   \n",
              "\n",
              "                PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
              "participant_id                                                                  \n",
              "Cfwaf5FX7jWK                                 0.0                          0.0   \n",
              "vhGrzmvA3Hjq                                 0.0                          0.0   \n",
              "\n",
              "                MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\n",
              "participant_id                                                    \n",
              "Cfwaf5FX7jWK                        4.0                    21.0   \n",
              "vhGrzmvA3Hjq                        4.0                    21.0   \n",
              "\n",
              "                Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  \\\n",
              "participant_id                                                   \n",
              "Cfwaf5FX7jWK                      30.0                    18.0   \n",
              "vhGrzmvA3Hjq                      45.0                    19.2   \n",
              "\n",
              "                Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
              "participant_id                                         ...   \n",
              "Cfwaf5FX7jWK                      30.0          60.03  ...   \n",
              "vhGrzmvA3Hjq                      30.0          86.71  ...   \n",
              "\n",
              "                SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
              "participant_id                                                         \n",
              "Cfwaf5FX7jWK                         2.0                        12.0   \n",
              "vhGrzmvA3Hjq                         2.0                        16.0   \n",
              "\n",
              "                SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
              "participant_id                                                      \n",
              "Cfwaf5FX7jWK                           3.0                    9.0   \n",
              "vhGrzmvA3Hjq                           8.0                    5.0   \n",
              "\n",
              "                SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  \\\n",
              "participant_id                                                     \n",
              "Cfwaf5FX7jWK                          2.0                    7.0   \n",
              "vhGrzmvA3Hjq                          7.0                    3.0   \n",
              "\n",
              "                SDQ_SDQ_Internalizing  SDQ_SDQ_Peer_Problems  \\\n",
              "participant_id                                                 \n",
              "Cfwaf5FX7jWK                      3.0                    0.0   \n",
              "vhGrzmvA3Hjq                     11.0                    3.0   \n",
              "\n",
              "                SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
              "participant_id                                            \n",
              "Cfwaf5FX7jWK                  8.0               8.992813  \n",
              "vhGrzmvA3Hjq                  9.0              12.324093  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FAST: imputation only on meta data\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "df_train_meta = pd.concat([df_train_meta_cat, df_train_meta_quant], axis=1)\n",
        "train_idx = df_train_X.index\n",
        "df_test_meta = pd.concat([df_test_meta_cat, df_test_meta_quant], axis=1)\n",
        "test_idx = df_test_X.index\n",
        "\n",
        "df_meta = pd.concat([df_train_meta, df_test_meta], axis=0)\n",
        "print(df_meta.shape)\n",
        "\n",
        "df_meta[df_meta == \"NA\"] = np.nan\n",
        "\n",
        "# Impute missing values with KNN imputation separately\n",
        "imputer_metadata = KNNImputer(n_neighbors=5)  # Using KNN for imputation instead of mean\n",
        "df_train_meta_imputed = imputer_metadata.fit_transform(df_train_meta)  # ((1213, 19927)\n",
        "df_train_meta_imputed = pd.DataFrame(df_train_meta_imputed, columns=df_train_meta.columns, index=df_train_meta.index)\n",
        "print(df_train_meta_imputed.shape)\n",
        "df_train_meta_imputed.head(2)\n",
        "\n",
        "df_test_meta_imputed = imputer_metadata.transform(df_test_meta)\n",
        "# df_test_meta_imputed = imputer_metadata.fit_transform(df_test_meta)  # ((1213, 19927)\n",
        "df_test_meta_imputed = pd.DataFrame(df_test_meta_imputed, columns=df_test_meta.columns, index=df_test_meta.index)\n",
        "print(df_test_meta_imputed.shape)\n",
        "df_test_meta_imputed.head(2)\n",
        "\n",
        "# # Impute missing values with KNN imputation together\n",
        "# imputer_metadata = KNNImputer(n_neighbors=5)  # Using KNN for imputation instead of mean\n",
        "# df_meta_imputed = imputer_metadata.fit_transform(df_meta)  # ((1213, 19927)\n",
        "# df_meta_imputed = pd.DataFrame(df_meta_imputed, columns=df_meta.columns, index=df_meta.index)\n",
        "# print(df_meta_imputed.shape)\n",
        "# df_meta_imputed.head(2)\n",
        "\n",
        "# df_train_meta_imputed = df_meta_imputed.loc[train_idx, :]\n",
        "# df_test_meta_imputed = df_meta_imputed.loc[test_idx, :]\n",
        "# print(df_train_meta_imputed.shape, df_test_meta_imputed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfmwxwCSAhCb"
      },
      "outputs": [],
      "source": [
        "# ## use large imputation for test set\n",
        "# dir = './TEST/'\n",
        "# df_test_meta_imputed = pd.read_excel(dir+\"df_test_meta_KNN_imputed_yiru.xlsx\")\n",
        "# df_test_meta_imputed.set_index('participant_id', inplace=True)\n",
        "# print(df_test_meta_imputed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSRYUOYwAY3V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSh08pd06Bvj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXC1lHAE6Cca"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bu13oB-6CvD",
        "outputId": "b7a67c26-1623-465d-dd0a-a68f3d1eb238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(304, 27)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize features.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_train_X = pd.concat([df_train_mri, df_train_meta_imputed], axis=1)\n",
        "df_test_X = pd.concat([df_test_mri, df_test_meta_imputed], axis=1)\n",
        "\n",
        "df_train_X_scaled = scaler.fit_transform(df_train_X)\n",
        "df_test_X_scaled = scaler.transform(df_test_X)\n",
        "\n",
        "df_train_X = pd.DataFrame(df_train_X_scaled, columns=df_train_X.columns, index=df_train_X.index)\n",
        "df_test_X = pd.DataFrame(df_test_X_scaled, columns=df_test_X.columns, index=df_test_X.index)\n",
        "\n",
        "df_train_mri = df_train_X.loc[:, df_train_mri.columns]\n",
        "df_train_meta_imputed = df_train_X.loc[:, df_train_meta_imputed.columns]\n",
        "df_test_mri = df_test_X.loc[:, df_test_mri.columns]\n",
        "df_test_meta_imputed = df_test_X.loc[:, df_test_meta_imputed.columns]\n",
        "print(df_test_meta_imputed.shape)\n",
        "\n",
        "# df_train_mri_scaled = scaler.fit_transform(df_train_mri)\n",
        "# df_test_mri_scaled = scaler.transform(df_test_mri)\n",
        "\n",
        "# df_train_meta_imputed_scaled = scaler.fit_transform(df_train_meta_imputed)\n",
        "# df_test_meta_imputed_scaled = scaler.transform(df_test_meta_imputed)\n",
        "\n",
        "# df_train_mri = pd.DataFrame(df_train_mri_scaled, columns=df_train_mri.columns, index=df_train_mri.index)\n",
        "# df_test_mri = pd.DataFrame(df_test_mri_scaled, columns=df_test_mri.columns, index=df_test_mri.index)\n",
        "# df_train_meta_imputed = pd.DataFrame(df_train_meta_imputed_scaled, columns=df_train_meta_imputed.columns, index=df_train_meta_imputed.index)\n",
        "# df_test_meta_imputed = pd.DataFrame(df_test_meta_imputed_scaled, columns=df_test_meta_imputed.columns, index=df_test_meta_imputed.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf535L7SIrX7",
        "outputId": "e4969a38-9702-48e8-d4eb-5a86bf976317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1213, 200, 200)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## reconstruct connecticome matrix\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_numbers(input_string):\n",
        "  match = re.match(r\"(\\d+)throw_(\\d+)thcolumn\", input_string)\n",
        "  if match:\n",
        "    n = int(match.group(1))\n",
        "    m = int(match.group(2))\n",
        "    return n, m\n",
        "  return None, None\n",
        "\n",
        "def create_connectome_matrix(row):\n",
        "  \"\"\"Creates a connectome matrix from a row of the dataframe.\n",
        "\n",
        "  Args:\n",
        "    row: A pandas Series representing a row of df_train_mri.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array representing the connectome matrix.\n",
        "  \"\"\"\n",
        "  # print(row)\n",
        "\n",
        "  matrix = np.zeros((200, 200))\n",
        "  for col_name, value in row.items():\n",
        "    if isinstance(col_name, str):\n",
        "      try:\n",
        "        # print(col_name)\n",
        "        nth_row, mth_col = extract_numbers(col_name)\n",
        "        # print(nth_row, mth_col)\n",
        "        if nth_row is not None and nth_row < 200 and mth_col < 200:\n",
        "          matrix[nth_row, mth_col] = value\n",
        "          matrix[mth_col, nth_row] = value\n",
        "          # if nth_row < 5 and mth_col < 5:\n",
        "          #   print(matrix[:5, :5])\n",
        "      except ValueError:\n",
        "        print('value error detected')\n",
        "        pass  # Ignore columns that don't match the pattern\n",
        "  np.fill_diagonal(matrix, 1)\n",
        "  # print(matrix[:5,:5])\n",
        "  return matrix\n",
        "\n",
        "\n",
        "connectome_matrices = np.array([create_connectome_matrix(row) for _, row in df_train_mri.iterrows()])\n",
        "connectome_matrices_test = np.array([create_connectome_matrix(row) for _, row in df_test_mri.iterrows()])\n",
        "connectome_matrices.shape\n",
        "\n",
        "# print(df_train_mri.iloc[0:5, :5])\n",
        "# connectome_matrices[1,:5,:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es9BLvbta2H1"
      },
      "source": [
        "## Train-validation data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qe4yTLza2b8",
        "outputId": "16517dd5-945f-43e5-f4d7-f243fd45a17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(243, 2)\n"
          ]
        }
      ],
      "source": [
        "# # prompt: split df_train_X and df_train_y into train and validation set and convert df into arrays able to be input into keras model\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Split the data into training and validation sets\n",
        "# X_train, X_val, y_train, y_val = train_test_split(df_train_X_scaled, df_train_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Convert DataFrames to NumPy arrays\n",
        "# # X_train = X_train.values\n",
        "# # X_val = X_val.values\n",
        "# y_train = y_train.values\n",
        "# y_val = y_val.values\n",
        "\n",
        "# print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxnSdF29S2yG",
        "outputId": "217aceef-365f-487b-b03a-dadca7ce569a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(970, 19900)\n",
            "(970, 200, 200)\n",
            "(970, 27)\n",
            "(243, 2)\n"
          ]
        }
      ],
      "source": [
        "# prompt: split df_train_X and df_train_y into train and validation set and convert df into arrays able to be input into keras model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_mri_flat, X_val_mri_flat, X_train_mri, X_val_mri, X_train_meta, X_val_meta, y_train, y_val = train_test_split(df_train_mri, connectome_matrices, df_train_meta_imputed, df_train_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrames to NumPy arrays\n",
        "# X_train_meta = X_train_meta.values\n",
        "# X_val_meta = X_val_meta.values\n",
        "X_train_mri_flat = X_train_mri_flat.values\n",
        "X_val_mri_flat = X_val_mri_flat.values\n",
        "y_train = y_train.values\n",
        "y_val = y_val.values\n",
        "\n",
        "print(X_train_mri_flat.shape)\n",
        "print(X_train_mri.shape)\n",
        "print(X_train_meta.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYlBCqxFa2qt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ3qa1a_apzy"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WzpF3HR-XsbN"
      },
      "outputs": [],
      "source": [
        "# prompt: I have a y_true array with two columns and a y_pred array with two columns, I want to use both columns together to determine if it's correct or not. how to calculate the f1 score. customized the weight variable based on the y_true, setting each (1,1) pair in y_true as 2 in weight, all others are 1 in weight. use sklearn f1-score function if possible. construct the function to be used as the keras neural network training metrics. The input is two tensor array\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_f1(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "    y_pred = tf.cast(tf.round(y_pred), tf.int32)\n",
        "\n",
        "    if y_true.shape[-1] == 2:\n",
        "      # Combine both columns for prediction\n",
        "      # (0,0): 0\n",
        "      # (0,1): 1\n",
        "      # (1,0): 2\n",
        "      # (1,1): 3\n",
        "      y_true = y_true[:,0] * 2 + y_true[:,1]\n",
        "      y_pred = y_pred[:,0] * 2 + y_pred[:,1]\n",
        "    elif y_true.shape[-1] == 1:\n",
        "      y_true = tf.squeeze(y_true)\n",
        "      y_pred = tf.squeeze(y_pred)\n",
        "    else:\n",
        "      raise ValueError(\"y_true should have shape (None, 2) or (None, 1)\")\n",
        "\n",
        "    # Calculate weights\n",
        "    weights = tf.where(tf.equal(y_true, 3), 2.0, 1.0)\n",
        "\n",
        "    # Reshape for sklearn f1_score\n",
        "    y_true_reshaped = tf.reshape(y_true, [-1]).numpy()\n",
        "    y_pred_reshaped = tf.reshape(y_pred, [-1]).numpy()\n",
        "    weights_reshaped = tf.reshape(weights, [-1]).numpy()\n",
        "    print(y_true_reshaped.shape)\n",
        "    print(y_pred_reshaped.shape)\n",
        "    print(weights_reshaped.shape)\n",
        "\n",
        "    f1 = f1_score(y_true_reshaped, y_pred_reshaped, average='weighted', sample_weight=weights_reshaped)\n",
        "    return f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE-xN-3PZ3V9",
        "outputId": "8381669d-c34a-4a61-df7c-2231c82283d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(970, 2)\n",
            "(970, 2)\n",
            "(970,)\n",
            "(970,)\n",
            "(970,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23492995564418168"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "## fake y_pred\n",
        "y_pred = np.random.randint(0, 2, size=(y_train.shape[0], 2))\n",
        "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "print(y_train_tensor.shape)\n",
        "print(y_pred_tensor.shape)\n",
        "\n",
        "custom_f1(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define the function to compute weighted F1 score ---\n",
        "def compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex):\n",
        "    \"\"\"\n",
        "    Compute the final weighted F1 score for the competition.\n",
        "    Female ADHD cases (where ADHD_Outcome==1 and Sex_F==1) are given 2x weight.\n",
        "    The final score is the average of the weighted F1 for ADHD_Outcome and the F1 for Sex_F.\n",
        "    \"\"\"\n",
        "    # Create sample weights for ADHD_Outcome: weight=2 for female ADHD cases, else 1.\n",
        "    weights = np.ones_like(y_true_adhd, dtype=float)\n",
        "    weights[(y_true_adhd == 1) & (y_true_sex == 1)] = 2.0\n",
        "\n",
        "    # Calculate weighted F1 for ADHD_Outcome\n",
        "    f1_adhd = f1_score(y_true_adhd, y_pred_adhd, sample_weight=weights)\n",
        "    # Calculate standard F1 for Sex_F\n",
        "    f1_sex = f1_score(y_true_sex, y_pred_sex)\n",
        "\n",
        "    # Final leaderboard score: average of the two F1 scores\n",
        "    final_f1 = (f1_adhd + f1_sex) / 2.0\n",
        "    return final_f1, f1_adhd, f1_sex\n"
      ],
      "metadata": {
        "id": "I4HM_7RWrvzG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate_weighted_f1_score(y_train, y_pred)\n",
        "y_true_sex = y_train[:,1]\n",
        "y_pred_sex = y_pred[:,1]\n",
        "y_true_adhd = y_train[:,0]\n",
        "y_pred_adhd = y_pred[:,0]\n",
        "compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFsJIkCdrzgo",
        "outputId": "423a04d8-325f-473d-b134-d1b19b6b5b2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.48929824561403507, 0.583859649122807, 0.39473684210526316)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Sy9Zoh6ZaqMM"
      },
      "outputs": [],
      "source": [
        "# prompt: help me write function to calculate weighted f1 score with 2 columns using sklearn, calculate the f1 score for each column with sample weights and get average score, each column have the same weight\n",
        "\n",
        "def calculate_weighted_f1_score(y_true, y_pred):\n",
        "  \"\"\"Calculates the weighted F1 score for two columns with sample weights.\n",
        "\n",
        "  Args:\n",
        "    y_true: A NumPy array or pandas DataFrame of true labels with two columns.\n",
        "    y_pred: A NumPy array or pandas DataFrame of predicted labels with two columns.\n",
        "\n",
        "  Returns:\n",
        "    The average weighted F1 score for both columns.\n",
        "  \"\"\"\n",
        "\n",
        "  if isinstance(y_true, pd.DataFrame):\n",
        "    y_true = y_true.values\n",
        "  if isinstance(y_pred, pd.DataFrame):\n",
        "    y_pred = y_pred.values\n",
        "\n",
        "  # Weights\n",
        "  weights = np.where((y_true[:, 0] == 1) & (y_true[:, 1] == 1), 2, 1)\n",
        "\n",
        "  f1_scores = []\n",
        "  for i in range(y_true.shape[1]):\n",
        "    # Calculate F1 score for the current column with sample weights\n",
        "    f1 = f1_score(y_true[:, i], y_pred[:, i], average='weighted', sample_weight=weights)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "  # Calculate the average F1 score for both columns (each with the same weight)\n",
        "  average_f1 = np.mean(f1_scores)\n",
        "  return average_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugxR2oOAYt9X",
        "outputId": "94aaf527-c539-4236-f913-e8cc09208ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5035528491536962)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "calculate_weighted_f1_score(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGrNRIfYygdl"
      },
      "source": [
        "## Neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VFNvi4e2c91"
      },
      "outputs": [],
      "source": [
        "# # prompt: I have a y_true array with two columns and a y_pred array with two columns, I want to use both columns together to determine if it's correct or not. how to calculate the f1 score. customized the weight variable based on the y_true, setting each (1,1) pair in y_true as 2 in weight, all others are 1 in weight. use sklearn f1-score function if possible. construct the function to be used in the keras neural network training metrics. The input is two tensor array\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from sklearn.metrics import f1_score\n",
        "\n",
        "# def custom_f1(y_true, y_pred):\n",
        "#     y_true = tf.cast(y_true, tf.float32)\n",
        "#     y_pred = tf.cast(tf.math.round(y_pred), tf.float32)\n",
        "#     print(y_true.shape)\n",
        "#     print(y_pred.shape)\n",
        "\n",
        "#     # Create weights based on y_true\n",
        "#     weights = tf.where(tf.reduce_all(tf.equal(y_true, [[1.0, 1.0]]), axis=1), 2.0, 1.0)\n",
        "\n",
        "#     # Calculate the F1 score using sklearn\n",
        "#     f1 = tf.numpy_function(f1_score_with_weights,\n",
        "#                            inp=[y_true, y_pred, weights],\n",
        "#                            Tout=tf.float32)\n",
        "#     return f1\n",
        "\n",
        "\n",
        "# def f1_score_with_weights(y_true, y_pred, weights):\n",
        "#     y_true = y_true.astype(int)\n",
        "#     y_pred = y_pred.astype(int)\n",
        "#     weights = weights.flatten()\n",
        "\n",
        "#     # Combine both columns for prediction\n",
        "#     # (0,0): 0\n",
        "#     # (0,1): 1\n",
        "#     # (1,0): 2\n",
        "#     # (1,1): 3\n",
        "#     combined_y_true = y_true[:,0] * 2 + y_true[:,1]\n",
        "#     combined_y_pred = y_pred[:,0] * 2 + y_pred[:,1]\n",
        "\n",
        "#     return f1_score(combined_y_true, combined_y_pred, average='weighted', sample_weight=weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFSYwiYQ-65Y",
        "outputId": "da46e5a7-4a23-475e-a948-95db0e267a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(970, 2)\n",
            "(970, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.26099467277526855>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ## fake y_pred\n",
        "# y_pred = np.random.randint(0, 2, size=(y_train.shape[0], 2))\n",
        "# y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "# y_pred_tensor = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "# custom_f1(y_train_tensor, y_pred_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDN3It9WjjUI",
        "outputId": "97602394-9f34-4bc8-c94f-c7e712af55d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚       \u001b[38;5;34m2,550,784\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚             \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚             \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   â”‚             \u001b[38;5;34m130\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550,784</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,559,938\u001b[0m (9.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,559,938</span> (9.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,559,554\u001b[0m (9.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,559,554</span> (9.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4835 - loss: 4.3270 - val_accuracy: 0.3918 - val_loss: 4.1389\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5702 - loss: 4.0813 - val_accuracy: 0.4433 - val_loss: 4.0783\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6184 - loss: 3.9368 - val_accuracy: 0.4897 - val_loss: 4.0182\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.6350 - loss: 3.8444 - val_accuracy: 0.5258 - val_loss: 3.9625\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6554 - loss: 3.7357 - val_accuracy: 0.5515 - val_loss: 3.9127\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6465 - loss: 3.6519 - val_accuracy: 0.5773 - val_loss: 3.8561\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.6515 - loss: 3.5967 - val_accuracy: 0.6186 - val_loss: 3.8018\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7033 - loss: 3.5064 - val_accuracy: 0.6392 - val_loss: 3.7521\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7073 - loss: 3.4477 - val_accuracy: 0.6546 - val_loss: 3.7010\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6970 - loss: 3.3691 - val_accuracy: 0.6649 - val_loss: 3.6483\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6930 - loss: 3.3033 - val_accuracy: 0.6959 - val_loss: 3.5988\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6779 - loss: 3.2304 - val_accuracy: 0.7010 - val_loss: 3.5478\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6601 - loss: 3.1930 - val_accuracy: 0.7320 - val_loss: 3.4954\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6823 - loss: 3.1054 - val_accuracy: 0.7526 - val_loss: 3.4411\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6850 - loss: 3.0532 - val_accuracy: 0.7474 - val_loss: 3.3896\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6982 - loss: 2.9998 - val_accuracy: 0.7577 - val_loss: 3.3396\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7231 - loss: 2.9223 - val_accuracy: 0.7784 - val_loss: 3.2861\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7256 - loss: 2.8807 - val_accuracy: 0.7835 - val_loss: 3.2349\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7041 - loss: 2.7934 - val_accuracy: 0.7629 - val_loss: 3.1859\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6916 - loss: 2.7296 - val_accuracy: 0.7784 - val_loss: 3.1337\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7356 - loss: 2.6630 - val_accuracy: 0.7784 - val_loss: 3.0857\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7145 - loss: 2.6056 - val_accuracy: 0.7784 - val_loss: 3.0353\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7010 - loss: 2.5711 - val_accuracy: 0.7990 - val_loss: 2.9853\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.7036 - loss: 2.5006 - val_accuracy: 0.7784 - val_loss: 2.9394\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7329 - loss: 2.4439 - val_accuracy: 0.7938 - val_loss: 2.8890\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.7218 - loss: 2.3978 - val_accuracy: 0.7990 - val_loss: 2.8399\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7154 - loss: 2.3524 - val_accuracy: 0.7938 - val_loss: 2.7951\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6969 - loss: 2.3045 - val_accuracy: 0.7887 - val_loss: 2.7550\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6934 - loss: 2.2460 - val_accuracy: 0.7938 - val_loss: 2.7115\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7201 - loss: 2.1959 - val_accuracy: 0.7938 - val_loss: 2.6677\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.7331 - loss: 2.1419 - val_accuracy: 0.8093 - val_loss: 2.6248\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.7193 - loss: 2.0924 - val_accuracy: 0.8144 - val_loss: 2.5826\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7329 - loss: 2.0539 - val_accuracy: 0.8041 - val_loss: 2.5441\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.6761 - loss: 2.0147 - val_accuracy: 0.8093 - val_loss: 2.5034\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.7309 - loss: 1.9544 - val_accuracy: 0.8041 - val_loss: 2.4650\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.7170 - loss: 1.9116 - val_accuracy: 0.8093 - val_loss: 2.4253\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.7089 - loss: 1.8910 - val_accuracy: 0.8247 - val_loss: 2.3858\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7274 - loss: 1.8592 - val_accuracy: 0.8247 - val_loss: 2.3503\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7081 - loss: 1.7975 - val_accuracy: 0.8299 - val_loss: 2.3128\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7177 - loss: 1.7536 - val_accuracy: 0.8247 - val_loss: 2.2769\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7264 - loss: 1.7199 - val_accuracy: 0.8351 - val_loss: 2.2416\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7304 - loss: 1.6761 - val_accuracy: 0.8351 - val_loss: 2.2045\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.7147 - loss: 1.6404 - val_accuracy: 0.8299 - val_loss: 2.1713\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.7031 - loss: 1.5938 - val_accuracy: 0.8351 - val_loss: 2.1369\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6923 - loss: 1.5800 - val_accuracy: 0.8299 - val_loss: 2.1056\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7233 - loss: 1.5355 - val_accuracy: 0.8351 - val_loss: 2.0736\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.7065 - loss: 1.4998 - val_accuracy: 0.8144 - val_loss: 2.0457\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.7245 - loss: 1.4592 - val_accuracy: 0.8144 - val_loss: 2.0188\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7028 - loss: 1.4423 - val_accuracy: 0.8247 - val_loss: 1.9922\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7108 - loss: 1.4115 - val_accuracy: 0.8299 - val_loss: 1.9628\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6902 - loss: 1.3709 - val_accuracy: 0.8196 - val_loss: 1.9348\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6982 - loss: 1.3422 - val_accuracy: 0.8196 - val_loss: 1.9062\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.7208 - loss: 1.3192 - val_accuracy: 0.8196 - val_loss: 1.8815\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7464 - loss: 1.2926 - val_accuracy: 0.8144 - val_loss: 1.8609\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.7250 - loss: 1.2597 - val_accuracy: 0.8196 - val_loss: 1.8356\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7486 - loss: 1.2535 - val_accuracy: 0.8299 - val_loss: 1.8144\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7240 - loss: 1.2116 - val_accuracy: 0.8299 - val_loss: 1.7936\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7244 - loss: 1.1868 - val_accuracy: 0.8299 - val_loss: 1.7729\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7473 - loss: 1.1656 - val_accuracy: 0.8247 - val_loss: 1.7517\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7222 - loss: 1.1527 - val_accuracy: 0.8299 - val_loss: 1.7301\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7000 - loss: 1.1219 - val_accuracy: 0.8351 - val_loss: 1.7113\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7126 - loss: 1.1140 - val_accuracy: 0.8299 - val_loss: 1.6924\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.7243 - loss: 1.0768 - val_accuracy: 0.8351 - val_loss: 1.6745\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7054 - loss: 1.0640 - val_accuracy: 0.8351 - val_loss: 1.6543\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7311 - loss: 1.0240 - val_accuracy: 0.8351 - val_loss: 1.6348\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7155 - loss: 1.0259 - val_accuracy: 0.8402 - val_loss: 1.6164\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7628 - loss: 1.0031 - val_accuracy: 0.8454 - val_loss: 1.5993\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7248 - loss: 0.9757 - val_accuracy: 0.8454 - val_loss: 1.5819\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7279 - loss: 0.9693 - val_accuracy: 0.8402 - val_loss: 1.5703\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7057 - loss: 0.9367 - val_accuracy: 0.8402 - val_loss: 1.5525\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.7086 - loss: 0.9197 - val_accuracy: 0.8454 - val_loss: 1.5390\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7315 - loss: 0.9041 - val_accuracy: 0.8454 - val_loss: 1.5214\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7194 - loss: 0.8818 - val_accuracy: 0.8454 - val_loss: 1.5107\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7473 - loss: 0.8697 - val_accuracy: 0.8454 - val_loss: 1.4994\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7282 - loss: 0.8542 - val_accuracy: 0.8454 - val_loss: 1.4951\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7152 - loss: 0.8516 - val_accuracy: 0.8454 - val_loss: 1.4879\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6908 - loss: 0.8391 - val_accuracy: 0.8454 - val_loss: 1.4762\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7217 - loss: 0.8251 - val_accuracy: 0.8454 - val_loss: 1.4624\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7457 - loss: 0.8017 - val_accuracy: 0.8454 - val_loss: 1.4474\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.7754 - loss: 0.8079 - val_accuracy: 0.8402 - val_loss: 1.4452\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.7111 - loss: 0.7794 - val_accuracy: 0.8402 - val_loss: 1.4388\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.7368 - loss: 0.7673 - val_accuracy: 0.8402 - val_loss: 1.4276\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6986 - loss: 0.7543 - val_accuracy: 0.8402 - val_loss: 1.4131\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7543 - loss: 0.7496 - val_accuracy: 0.8402 - val_loss: 1.4016\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7370 - loss: 0.7317 - val_accuracy: 0.8454 - val_loss: 1.3962\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7450 - loss: 0.7203 - val_accuracy: 0.8454 - val_loss: 1.3872\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7105 - loss: 0.7101 - val_accuracy: 0.8402 - val_loss: 1.3774\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7300 - loss: 0.7034 - val_accuracy: 0.8402 - val_loss: 1.3720\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.7487 - loss: 0.6897 - val_accuracy: 0.8402 - val_loss: 1.3638\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.7160 - loss: 0.6872 - val_accuracy: 0.8454 - val_loss: 1.3551\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.7349 - loss: 0.6749 - val_accuracy: 0.8454 - val_loss: 1.3480\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7224 - loss: 0.6773 - val_accuracy: 0.8402 - val_loss: 1.3424\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.7470 - loss: 0.6580 - val_accuracy: 0.8454 - val_loss: 1.3367\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7498 - loss: 0.6668 - val_accuracy: 0.8402 - val_loss: 1.3268\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.7539 - loss: 0.6397 - val_accuracy: 0.8454 - val_loss: 1.3196\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.7327 - loss: 0.6293 - val_accuracy: 0.8454 - val_loss: 1.3119\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.7288 - loss: 0.6183 - val_accuracy: 0.8454 - val_loss: 1.3079\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7298 - loss: 0.6044 - val_accuracy: 0.8402 - val_loss: 1.2979\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.7378 - loss: 0.6026 - val_accuracy: 0.8454 - val_loss: 1.2994\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.7491 - loss: 0.5895 - val_accuracy: 0.8454 - val_loss: 1.2906\n"
          ]
        }
      ],
      "source": [
        "# prompt: set up a neural network model with an input layer of 19927 cells, and output layer of 2 cells, add dropoff layer if needed, add activation functions. try use keras package to do that.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = keras.Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(19927,), kernel_regularizer=l2(0.01)),  # Input layer with 19927 cells and ReLU activation\n",
        "    Dropout(0.5),  # Dropout layer for regularization\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),  # Hidden layer with 64 cells and ReLU activation\n",
        "    Dropout(0.3), # Another dropout layer\n",
        "    BatchNormalization(),\n",
        "    Dense(2, activation='sigmoid')  # Output layer with 2 cells and sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1)\n",
        "# f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy', # Use binary_crossentropy for binary classification\n",
        "              metrics=['accuracy']) #['accuracy', 'f1_score']) # Include custom F1 metric\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Set up early stopping to monitor validation accuracy and stop when it stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "6_32gnFI_C7A",
        "outputId": "115292b6-0a06-4d1d-d47c-c1a5086b14d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550,784</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_93 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚       \u001b[38;5;34m2,550,784\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_94 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_95 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   â”‚             \u001b[38;5;34m260\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,559,300</span> (9.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,559,300\u001b[0m (9.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,559,300</span> (9.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,559,300\u001b[0m (9.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # prompt: set up a neural network model with an input layer of 19927 cells, and output layer of 1 cells with 4 potential categories, add dropoff layer if needed, add activation functions. try use keras package to do that.\n",
        "\n",
        "# sparse_model = keras.Sequential([\n",
        "#     keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "#     keras.layers.Dropout(0.5),\n",
        "#     keras.layers.Dense(64, activation='relu'),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "#     keras.layers.Dense(4, activation='softmax') # Output layer with 4 categories and softmax activation\n",
        "# ])\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "# sparse_model.compile(optimizer=optimizer,\n",
        "#               loss='sparse_categorical_crossentropy', # Use sparse_categorical_crossentropy for integer labels\n",
        "#               metrics=['accuracy', 'f1_score']) # Use accuracy as metric\n",
        "\n",
        "# sparse_model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBZfJyBC-Bmj"
      },
      "outputs": [],
      "source": [
        "# # prompt: set up a neural network model with an input layer of 19927 cells, and output layer of 2 cells, add dropoff layer if needed, add activation functions. try use keras package to do that.\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# sparse_model = keras.Sequential([\n",
        "#     Dense(128, activation='relu', input_shape=(19900,), kernel_initializer='he_normal'),  # Input layer with 19927 cells and ReLU activation\n",
        "#     Dropout(0.5),  # Dropout layer for regularization\n",
        "#     Dense(64, activation='relu'),  # Hidden layer with 64 cells and ReLU activation\n",
        "#     Dropout(0.3), # Another dropout layer\n",
        "#     Dense(1, activation='softmax')  # Output layer with 2 cells and sigmoid activation for binary classification\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1)\n",
        "# # f1_scorer = tf.keras.metrics.F1Score(average='weight')\n",
        "# sparse_model.compile(optimizer=optimizer,\n",
        "#               loss='sparse_categorical_crossentropy', # Use binary_crossentropy for binary classification\n",
        "#               metrics=['f1_score']) # Include custom F1 metric\n",
        "\n",
        "# # Print model summary\n",
        "# sparse_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAzy0ec4yg80",
        "outputId": "24f0fd9e-f505-4ce7-838e-d870a85ff785"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# # prompt: set up a neural network model with an input layer of 19927 cells, and output layer of 2 cells, add dropoff layer if needed, add activation functions. try use keras package to do that. Use weighted F1 score as training metrics (2x in y=(1,1))\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.layers import Dense, Dropout\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from sklearn.metrics import f1_score\n",
        "\n",
        "# # Assuming df_train_mri, df_train_meta_quant, df_train_meta_cat, and df_train_y are defined as in the previous code.\n",
        "# # And that X_train and y_train are preprocessed appropriately\n",
        "\n",
        "# # Define the model\n",
        "# model = Sequential()\n",
        "# model.add(Dense(128, activation='relu', input_shape=(19927,))) # Input layer with 19927 cells\n",
        "# model.add(Dropout(0.5)) # Dropout layer for regularization\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(2, activation='sigmoid')) # Output layer with 2 cells and softmax activation for classification\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy', # Or categorical_crossentropy if y_train is one-hot encoded\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # Example training (replace with your actual data and training parameters)\n",
        "# # Assuming X_train and y_train are numpy arrays\n",
        "# # X_train = np.array(...)\n",
        "# # y_train = np.array(...)\n",
        "\n",
        "# # history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# # Evaluate the model\n",
        "# # loss, weighted_f1_value = model.evaluate(X_test, y_test)\n",
        "# # print('Weighted F1 Score:', weighted_f1_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjLg_ZiJ5e0o",
        "outputId": "c7b25aba-89d1-489f-d16d-4cdf26759edf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7476 - loss: 0.5920 - val_accuracy: 0.8454 - val_loss: 1.2793\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7281 - loss: 0.5722 - val_accuracy: 0.8402 - val_loss: 1.2705\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.7407 - loss: 0.5602 - val_accuracy: 0.8402 - val_loss: 1.2635\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7481 - loss: 0.5523 - val_accuracy: 0.8402 - val_loss: 1.2583\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7284 - loss: 0.5348 - val_accuracy: 0.8402 - val_loss: 1.2495\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7308 - loss: 0.5312 - val_accuracy: 0.8351 - val_loss: 1.2482\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7182 - loss: 0.5449 - val_accuracy: 0.8454 - val_loss: 1.2496\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.7179 - loss: 0.5310 - val_accuracy: 0.8402 - val_loss: 1.2471\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7236 - loss: 0.5293 - val_accuracy: 0.8351 - val_loss: 1.2400\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7528 - loss: 0.5097 - val_accuracy: 0.8402 - val_loss: 1.2343\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7484 - loss: 0.5045 - val_accuracy: 0.8299 - val_loss: 1.2359\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6882 - loss: 0.4873 - val_accuracy: 0.8299 - val_loss: 1.2331\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7514 - loss: 0.4934 - val_accuracy: 0.8351 - val_loss: 1.2265\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7344 - loss: 0.4910 - val_accuracy: 0.8299 - val_loss: 1.2179\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7153 - loss: 0.4816 - val_accuracy: 0.8351 - val_loss: 1.2159\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7158 - loss: 0.4773 - val_accuracy: 0.8402 - val_loss: 1.2112\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7506 - loss: 0.4705 - val_accuracy: 0.8402 - val_loss: 1.2106\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7248 - loss: 0.4629 - val_accuracy: 0.8402 - val_loss: 1.2113\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7424 - loss: 0.4572 - val_accuracy: 0.8402 - val_loss: 1.2150\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7177 - loss: 0.4558 - val_accuracy: 0.8402 - val_loss: 1.2093\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7180 - loss: 0.4519 - val_accuracy: 0.8402 - val_loss: 1.2046\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7242 - loss: 0.4511 - val_accuracy: 0.8402 - val_loss: 1.2067\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7438 - loss: 0.4461 - val_accuracy: 0.8402 - val_loss: 1.2097\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7104 - loss: 0.4423 - val_accuracy: 0.8402 - val_loss: 1.2057\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.7613 - loss: 0.4416 - val_accuracy: 0.8402 - val_loss: 1.1966\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7416 - loss: 0.4314 - val_accuracy: 0.8351 - val_loss: 1.1996\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7517 - loss: 0.4309 - val_accuracy: 0.8351 - val_loss: 1.1956\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7746 - loss: 0.4416 - val_accuracy: 0.8402 - val_loss: 1.1918\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6953 - loss: 0.4268 - val_accuracy: 0.8402 - val_loss: 1.2018\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7359 - loss: 0.4328 - val_accuracy: 0.8402 - val_loss: 1.1964\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7335 - loss: 0.4163 - val_accuracy: 0.8402 - val_loss: 1.1969\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7432 - loss: 0.4268 - val_accuracy: 0.8402 - val_loss: 1.1941\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7171 - loss: 0.4254 - val_accuracy: 0.8402 - val_loss: 1.1985\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7316 - loss: 0.4103 - val_accuracy: 0.8402 - val_loss: 1.1961\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7364 - loss: 0.4074 - val_accuracy: 0.8351 - val_loss: 1.2029\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7321 - loss: 0.4129 - val_accuracy: 0.8351 - val_loss: 1.1995\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7460 - loss: 0.4080 - val_accuracy: 0.8299 - val_loss: 1.1930\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7285 - loss: 0.4038 - val_accuracy: 0.8351 - val_loss: 1.1901\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7315 - loss: 0.3844 - val_accuracy: 0.8351 - val_loss: 1.1941\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7456 - loss: 0.4028 - val_accuracy: 0.8351 - val_loss: 1.1892\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7236 - loss: 0.3809 - val_accuracy: 0.8351 - val_loss: 1.1862\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7386 - loss: 0.3919 - val_accuracy: 0.8402 - val_loss: 1.1858\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7755 - loss: 0.4254 - val_accuracy: 0.8351 - val_loss: 1.1858\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7465 - loss: 0.3833 - val_accuracy: 0.8351 - val_loss: 1.1857\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7059 - loss: 0.3886 - val_accuracy: 0.8402 - val_loss: 1.1860\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7112 - loss: 0.3759 - val_accuracy: 0.8454 - val_loss: 1.1807\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7283 - loss: 0.3820 - val_accuracy: 0.8402 - val_loss: 1.1794\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7397 - loss: 0.3889 - val_accuracy: 0.8402 - val_loss: 1.1725\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7462 - loss: 0.3817 - val_accuracy: 0.8351 - val_loss: 1.1854\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7395 - loss: 0.3980 - val_accuracy: 0.8351 - val_loss: 1.1993\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7147 - loss: 0.3767 - val_accuracy: 0.8454 - val_loss: 1.2023\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7519 - loss: 0.3861 - val_accuracy: 0.8454 - val_loss: 1.2028\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7390 - loss: 0.3741 - val_accuracy: 0.8505 - val_loss: 1.2027\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7646 - loss: 0.3817 - val_accuracy: 0.8454 - val_loss: 1.2075\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.7511 - loss: 0.3706 - val_accuracy: 0.8505 - val_loss: 1.2000\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.7367 - loss: 0.3674 - val_accuracy: 0.8505 - val_loss: 1.1930\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7514 - loss: 0.3731 - val_accuracy: 0.8454 - val_loss: 1.1937\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7260 - loss: 0.3600 - val_accuracy: 0.8402 - val_loss: 1.1926\n"
          ]
        }
      ],
      "source": [
        "# ## including meta data\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# # Set up early stopping to monitor validation accuracy and stop when it stops improving\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Bquk7fIayhS-",
        "outputId": "a6336fc7-8739-49b5-aa66-5a3ecccce5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'SymbolicTensor' object has no attribute 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-3e72abe27a7c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## only mri data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-137-e0eff64c6007>\u001b[0m in \u001b[0;36mcustom_f1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Reshape for sklearn f1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0my_true_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0my_pred_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mweights_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SymbolicTensor' object has no attribute 'numpy'"
          ]
        }
      ],
      "source": [
        "## only mri data\n",
        "# history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7-_H5D7-btn"
      },
      "outputs": [],
      "source": [
        "## only mri data with single y output\n",
        "# history = sparse_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoVzVMYZ5zbR",
        "outputId": "ecff8b46-d691-45aa-9390-978c54ff0a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9147 - loss: 1.0361\n",
            "[1.0694137811660767, 0.8847736716270447]\n"
          ]
        }
      ],
      "source": [
        "all_metrics = model.evaluate(X_val, y_val)\n",
        "print(all_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m6feHc4akurR",
        "outputId": "f1f27e5b-ce6e-4a3f-e061-2e6977c2db7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8898272 , 0.22226593],\n",
              "       [0.20235491, 0.16006637],\n",
              "       [0.97164834, 0.13835418],\n",
              "       [0.97351784, 0.0561387 ],\n",
              "       [0.89488196, 0.09781115],\n",
              "       [0.9756235 , 0.08534758],\n",
              "       [0.9073171 , 0.7346248 ],\n",
              "       [0.96209705, 0.0590832 ],\n",
              "       [0.96222585, 0.07127088],\n",
              "       [0.981595  , 0.04807183],\n",
              "       [0.9509352 , 0.67838913],\n",
              "       [0.9701894 , 0.24114217],\n",
              "       [0.9737495 , 0.26370272],\n",
              "       [0.9617025 , 0.2320229 ],\n",
              "       [0.9330771 , 0.54487646],\n",
              "       [0.88511366, 0.6286449 ],\n",
              "       [0.9352968 , 0.17904086],\n",
              "       [0.8273005 , 0.31464827],\n",
              "       [0.52047884, 0.3034013 ],\n",
              "       [0.97576886, 0.26745093],\n",
              "       [0.9512349 , 0.06578507],\n",
              "       [0.9437693 , 0.14514221],\n",
              "       [0.95480305, 0.07911268],\n",
              "       [0.90393823, 0.6952102 ],\n",
              "       [0.9573713 , 0.12059509],\n",
              "       [0.9508559 , 0.10104103],\n",
              "       [0.9390821 , 0.48959306],\n",
              "       [0.91996217, 0.14492783],\n",
              "       [0.96816266, 0.05396178],\n",
              "       [0.9538184 , 0.25474772],\n",
              "       [0.95974284, 0.11144926],\n",
              "       [0.96122646, 0.08325632],\n",
              "       [0.93357176, 0.0642869 ],\n",
              "       [0.90111405, 0.0367221 ],\n",
              "       [0.88121647, 0.08143391],\n",
              "       [0.6377252 , 0.28323904],\n",
              "       [0.9499889 , 0.27199596],\n",
              "       [0.9188933 , 0.09331563],\n",
              "       [0.913667  , 0.22566895],\n",
              "       [0.8933014 , 0.10355976],\n",
              "       [0.88042206, 0.12647179],\n",
              "       [0.7794395 , 0.44695368],\n",
              "       [0.9486437 , 0.11898563],\n",
              "       [0.9645629 , 0.07482232],\n",
              "       [0.884738  , 0.39813206],\n",
              "       [0.82293534, 0.4067887 ],\n",
              "       [0.9196705 , 0.08984123],\n",
              "       [0.9693185 , 0.08311445],\n",
              "       [0.9639929 , 0.16763346],\n",
              "       [0.9281018 , 0.21400928],\n",
              "       [0.8116479 , 0.13885826],\n",
              "       [0.9583892 , 0.41798937],\n",
              "       [0.7259125 , 0.12272175],\n",
              "       [0.869429  , 0.517394  ],\n",
              "       [0.9300404 , 0.2565716 ],\n",
              "       [0.93848044, 0.22883622],\n",
              "       [0.9450748 , 0.32404757],\n",
              "       [0.5582479 , 0.747718  ],\n",
              "       [0.89766544, 0.3249812 ],\n",
              "       [0.7900552 , 0.18044856],\n",
              "       [0.92766905, 0.03833016],\n",
              "       [0.82636875, 0.2390529 ],\n",
              "       [0.7807016 , 0.26979992],\n",
              "       [0.7559782 , 0.253933  ],\n",
              "       [0.66464573, 0.08240515],\n",
              "       [0.6973475 , 0.16806397],\n",
              "       [0.9479999 , 0.04246395],\n",
              "       [0.8172128 , 0.38542715],\n",
              "       [0.967021  , 0.04715721],\n",
              "       [0.9683323 , 0.34514582],\n",
              "       [0.9659844 , 0.07944579],\n",
              "       [0.9213927 , 0.04858186],\n",
              "       [0.9678401 , 0.63803506],\n",
              "       [0.8236728 , 0.21678245],\n",
              "       [0.924518  , 0.22040905],\n",
              "       [0.9730262 , 0.05574   ],\n",
              "       [0.9032793 , 0.2111265 ],\n",
              "       [0.9447046 , 0.51121473],\n",
              "       [0.95243305, 0.23952469],\n",
              "       [0.95742977, 0.38138428],\n",
              "       [0.91492134, 0.09190515],\n",
              "       [0.94769186, 0.2921382 ],\n",
              "       [0.9741727 , 0.1205268 ],\n",
              "       [0.62882847, 0.65597546],\n",
              "       [0.91601664, 0.19403683],\n",
              "       [0.9561991 , 0.06471718],\n",
              "       [0.9476517 , 0.07353347],\n",
              "       [0.9059714 , 0.26158336],\n",
              "       [0.9201491 , 0.03305751],\n",
              "       [0.9712916 , 0.1187158 ],\n",
              "       [0.90162265, 0.03197096],\n",
              "       [0.92414165, 0.54905254],\n",
              "       [0.9092983 , 0.14175883],\n",
              "       [0.9488226 , 0.02029023],\n",
              "       [0.85886776, 0.10956207],\n",
              "       [0.96080834, 0.08860562],\n",
              "       [0.93020123, 0.04688042],\n",
              "       [0.91915536, 0.17553377],\n",
              "       [0.9775524 , 0.2250643 ],\n",
              "       [0.8495179 , 0.19768564],\n",
              "       [0.90684754, 0.10202915],\n",
              "       [0.9503944 , 0.07485055],\n",
              "       [0.9477377 , 0.4841079 ],\n",
              "       [0.9253171 , 0.5333738 ],\n",
              "       [0.9619876 , 0.41860768],\n",
              "       [0.9179615 , 0.34344724],\n",
              "       [0.92771834, 0.47958   ],\n",
              "       [0.9100406 , 0.05314064],\n",
              "       [0.9137232 , 0.507066  ],\n",
              "       [0.9600916 , 0.05759166],\n",
              "       [0.9524403 , 0.21404198],\n",
              "       [0.80847114, 0.35019752],\n",
              "       [0.87630117, 0.09395676],\n",
              "       [0.9415073 , 0.10957373],\n",
              "       [0.9669721 , 0.11869997],\n",
              "       [0.9709533 , 0.61088717],\n",
              "       [0.92698026, 0.17746155],\n",
              "       [0.9654335 , 0.100857  ],\n",
              "       [0.97020376, 0.50393903],\n",
              "       [0.953147  , 0.58149695],\n",
              "       [0.9723798 , 0.25868607],\n",
              "       [0.9797085 , 0.16357966],\n",
              "       [0.974406  , 0.6393577 ],\n",
              "       [0.88726586, 0.04930429],\n",
              "       [0.96105576, 0.041747  ],\n",
              "       [0.94950914, 0.27791137],\n",
              "       [0.897942  , 0.13442513],\n",
              "       [0.94782794, 0.31786266],\n",
              "       [0.8679267 , 0.07637053],\n",
              "       [0.931426  , 0.19646989],\n",
              "       [0.88045985, 0.70813125],\n",
              "       [0.94929016, 0.2268747 ],\n",
              "       [0.93675905, 0.10150483],\n",
              "       [0.96549124, 0.09215578],\n",
              "       [0.9833813 , 0.39291742],\n",
              "       [0.96188164, 0.26239923],\n",
              "       [0.9354001 , 0.34401563],\n",
              "       [0.925809  , 0.08560406],\n",
              "       [0.94058305, 0.09608719],\n",
              "       [0.9689594 , 0.21817335],\n",
              "       [0.5695247 , 0.4920372 ],\n",
              "       [0.6054205 , 0.07297716],\n",
              "       [0.9008301 , 0.05270466],\n",
              "       [0.9159559 , 0.1003438 ],\n",
              "       [0.87244964, 0.58095235],\n",
              "       [0.93992984, 0.21715441],\n",
              "       [0.9390509 , 0.23165768],\n",
              "       [0.88242596, 0.25110874],\n",
              "       [0.83244914, 0.16179813],\n",
              "       [0.95780617, 0.3299193 ],\n",
              "       [0.9514348 , 0.07382374],\n",
              "       [0.7702521 , 0.08698012],\n",
              "       [0.7185829 , 0.32287887],\n",
              "       [0.7749022 , 0.86616904],\n",
              "       [0.9717137 , 0.08522081],\n",
              "       [0.9693031 , 0.13281372],\n",
              "       [0.9718398 , 0.06936988],\n",
              "       [0.9743074 , 0.10141528],\n",
              "       [0.92287207, 0.42685208],\n",
              "       [0.9673161 , 0.07515933],\n",
              "       [0.94190085, 0.16008349],\n",
              "       [0.989822  , 0.02382876],\n",
              "       [0.8666072 , 0.5518378 ],\n",
              "       [0.85099363, 0.17926852],\n",
              "       [0.91099274, 0.17124821],\n",
              "       [0.9592534 , 0.30618998],\n",
              "       [0.807908  , 0.47549143],\n",
              "       [0.9809522 , 0.20992735],\n",
              "       [0.97096294, 0.02664233],\n",
              "       [0.9231544 , 0.07935976],\n",
              "       [0.91013   , 0.28219798],\n",
              "       [0.8933583 , 0.12048884],\n",
              "       [0.9639698 , 0.2747893 ],\n",
              "       [0.89016   , 0.07111471],\n",
              "       [0.9390008 , 0.5838294 ],\n",
              "       [0.79594654, 0.42873827],\n",
              "       [0.7590116 , 0.5845871 ],\n",
              "       [0.97601527, 0.05685781],\n",
              "       [0.884768  , 0.13844673],\n",
              "       [0.8406014 , 0.10187061],\n",
              "       [0.8280184 , 0.50372934],\n",
              "       [0.90678865, 0.47829074],\n",
              "       [0.9518749 , 0.5185534 ],\n",
              "       [0.86947465, 0.16147669],\n",
              "       [0.9239563 , 0.1473762 ],\n",
              "       [0.7973737 , 0.48173466],\n",
              "       [0.9675047 , 0.3640965 ],\n",
              "       [0.8894211 , 0.4482325 ],\n",
              "       [0.8472832 , 0.39011684],\n",
              "       [0.884851  , 0.08469913],\n",
              "       [0.9741691 , 0.2758867 ],\n",
              "       [0.90107316, 0.3852473 ],\n",
              "       [0.9246396 , 0.6537286 ],\n",
              "       [0.64761776, 0.27630228],\n",
              "       [0.6018097 , 0.04928058],\n",
              "       [0.9657554 , 0.36046755],\n",
              "       [0.9183253 , 0.08439876],\n",
              "       [0.97927606, 0.44334742],\n",
              "       [0.986566  , 0.10009181],\n",
              "       [0.95090914, 0.08583423],\n",
              "       [0.95367575, 0.08519443],\n",
              "       [0.60419804, 0.06534511],\n",
              "       [0.89038336, 0.18820097],\n",
              "       [0.854533  , 0.2802373 ],\n",
              "       [0.93853194, 0.17829593],\n",
              "       [0.8982406 , 0.06200997],\n",
              "       [0.44761208, 0.28945944],\n",
              "       [0.5656927 , 0.23577625],\n",
              "       [0.9210873 , 0.32596895],\n",
              "       [0.97727066, 0.04680211],\n",
              "       [0.97518265, 0.06462415],\n",
              "       [0.9329138 , 0.03373964],\n",
              "       [0.94477713, 0.41514432],\n",
              "       [0.7791628 , 0.2590669 ],\n",
              "       [0.94031006, 0.21030015],\n",
              "       [0.82479846, 0.08105773],\n",
              "       [0.9739967 , 0.07992933],\n",
              "       [0.96216047, 0.14913964],\n",
              "       [0.9121693 , 0.11140618],\n",
              "       [0.9368109 , 0.57930684],\n",
              "       [0.75860935, 0.04286567],\n",
              "       [0.9164689 , 0.19304217],\n",
              "       [0.9833274 , 0.04091182],\n",
              "       [0.93026626, 0.47096887],\n",
              "       [0.93748677, 0.09918077],\n",
              "       [0.9162228 , 0.3382712 ],\n",
              "       [0.97881395, 0.04060651],\n",
              "       [0.46526462, 0.17220244],\n",
              "       [0.971744  , 0.15893447],\n",
              "       [0.90623975, 0.14268634],\n",
              "       [0.9808759 , 0.07986073],\n",
              "       [0.94281423, 0.23135403],\n",
              "       [0.95393574, 0.1760902 ],\n",
              "       [0.6433085 , 0.17618458],\n",
              "       [0.9602978 , 0.06610271],\n",
              "       [0.9184695 , 0.2698866 ],\n",
              "       [0.9743563 , 0.05031874],\n",
              "       [0.95822704, 0.26473492],\n",
              "       [0.97635657, 0.77517945],\n",
              "       [0.9436983 , 0.09896867],\n",
              "       [0.8501921 , 0.19234599],\n",
              "       [0.8780799 , 0.1356584 ],\n",
              "       [0.97530943, 0.07265561]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# prompt: predict a test set X_val and return the y_pred output\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1aVbKoxRXWH",
        "outputId": "9fddf10a-fde8-4f5c-9fb9-c92acfc470bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(243, 2)\n",
            "(243, 2)\n",
            "Accuracy for column 0: 0.7283950617283951\n",
            "Accuracy for column 1: 0.6707818930041153\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.36466903515332827, 0.6027271930300013\n",
            "Jiaqi's Weighted F1 Score: (0.5350393700787401, 0.8700787401574803, 0.2)\n"
          ]
        }
      ],
      "source": [
        "# prompt: help me calculate the accuracy score of y_pred and y_val for each column separately\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming y_pred and y_val are numpy arrays\n",
        "# and y_pred contains probabilities for each class\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "print(y_val.shape)\n",
        "print(y_pred_classes.shape)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "## weighted F1 score\n",
        "# print(y_val.shape)\n",
        "# print(y_pred_classes.shape)\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.float32)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n",
        "\n",
        "y_true_sex = y_val[:,1]\n",
        "y_pred_sex = y_pred_classes[:,1]\n",
        "y_true_adhd = y_val[:,0]\n",
        "y_pred_adhd = y_pred_classes[:,0]\n",
        "# f1_3 = compute_weighted_f1(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex)\n",
        "f1_3 = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "print(f\"Jiaqi's Weighted F1 Score: {f1_3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34QX_plgE04B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na_o32wSEzyS"
      },
      "source": [
        "## Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgFjLqRKcD27"
      },
      "source": [
        "### Only mri matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hSu-s5u2RJNM",
        "outputId": "41c6f782-468d-4aec-c3f7-78ac2701748a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67712</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,667,264</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚          \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚          \u001b[38;5;34m73,856\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67712\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚       \u001b[38;5;34m8,667,264\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   â”‚             \u001b[38;5;34m258\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,760,194</span> (33.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,760,194\u001b[0m (33.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,760,194</span> (33.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,760,194\u001b[0m (33.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - accuracy: 0.7965 - f1_score: 0.5407 - loss: 0.6973 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6460\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.8539 - f1_score: 0.5172 - loss: 0.6615 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6359\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.8606 - f1_score: 0.5270 - loss: 0.6606 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6280\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8655 - f1_score: 0.5285 - loss: 0.6390 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6287\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8668 - f1_score: 0.5416 - loss: 0.6407 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6406\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.8602 - f1_score: 0.5346 - loss: 0.6438 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6285\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8771 - f1_score: 0.5390 - loss: 0.6400 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6454\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8627 - f1_score: 0.5258 - loss: 0.6529 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6285\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8658 - f1_score: 0.5328 - loss: 0.6407 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6338\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8636 - f1_score: 0.5206 - loss: 0.6518 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6256\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8540 - f1_score: 0.5077 - loss: 0.6555 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6306\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8786 - f1_score: 0.5481 - loss: 0.6359 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6351\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8741 - f1_score: 0.5385 - loss: 0.6382 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6313\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8510 - f1_score: 0.5225 - loss: 0.6479 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6331\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8665 - f1_score: 0.5273 - loss: 0.6472 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6288\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8566 - f1_score: 0.5261 - loss: 0.6464 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6285\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8710 - f1_score: 0.5272 - loss: 0.6455 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6298\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8303 - f1_score: 0.5008 - loss: 0.6626 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6282\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8711 - f1_score: 0.5525 - loss: 0.6293 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6350\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8582 - f1_score: 0.5178 - loss: 0.6546 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6323\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8670 - f1_score: 0.5440 - loss: 0.6369 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6344\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8627 - f1_score: 0.5306 - loss: 0.6418 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6279\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.8830 - f1_score: 0.5507 - loss: 0.6337 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6326\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8305 - f1_score: 0.4960 - loss: 0.6626 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6289\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8751 - f1_score: 0.5353 - loss: 0.6445 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6331\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8723 - f1_score: 0.5343 - loss: 0.6427 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6331\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8677 - f1_score: 0.5322 - loss: 0.6433 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6305\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8663 - f1_score: 0.5370 - loss: 0.6400 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6299\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8438 - f1_score: 0.5044 - loss: 0.6547 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6282\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8531 - f1_score: 0.5096 - loss: 0.6550 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6291\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8749 - f1_score: 0.5176 - loss: 0.6505 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6310\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8614 - f1_score: 0.5261 - loss: 0.6419 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6288\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8549 - f1_score: 0.5063 - loss: 0.6547 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6286\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8365 - f1_score: 0.5048 - loss: 0.6603 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6303\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8477 - f1_score: 0.5104 - loss: 0.6515 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6290\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8433 - f1_score: 0.5080 - loss: 0.6560 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6300\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8384 - f1_score: 0.5071 - loss: 0.6515 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6297\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8551 - f1_score: 0.5300 - loss: 0.6429 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6320\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8602 - f1_score: 0.5071 - loss: 0.6524 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6280\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8525 - f1_score: 0.5119 - loss: 0.6512 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6304\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8795 - f1_score: 0.5341 - loss: 0.6411 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6317\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8418 - f1_score: 0.4905 - loss: 0.6608 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6294\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8464 - f1_score: 0.5328 - loss: 0.6436 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6321\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8613 - f1_score: 0.5207 - loss: 0.6463 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6283\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8555 - f1_score: 0.5200 - loss: 0.6488 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6297\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8472 - f1_score: 0.5058 - loss: 0.6532 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6276\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8572 - f1_score: 0.5256 - loss: 0.6447 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6306\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8661 - f1_score: 0.5315 - loss: 0.6421 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6299\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8592 - f1_score: 0.5138 - loss: 0.6533 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6300\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8704 - f1_score: 0.5250 - loss: 0.6454 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6306\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7954145d77d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt: use the connectome_matrices (n, 200,200) as input, build a convolutional neural network to predict on the y_train, which is a two column of binary categorical output. use keras package\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming connectome_matrices and y_train are defined as in your code\n",
        "\n",
        "# Reshape the connectome matrices for CNN input (add a channel dimension)\n",
        "X_train_cnn = X_train_mri[..., np.newaxis]\n",
        "X_val_cnn = X_val_mri[..., np.newaxis]\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='sigmoid')  # Output layer with 2 cells and sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1)\n",
        "f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', f1_scorer])  # Use your custom_f1 function here\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# Set up early stopping to monitor validation accuracy and stop when it stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vehBqXiaE1-c",
        "outputId": "efa322dd-657e-4152-ac38-5fbf8b02207c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9192 - f1_score: 0.6311 - loss: 0.5936\n",
            "Loss: 0.6076040267944336\n",
            "Accuracy: 0.8888888955116272\n",
            "F1 Score: 0.602071225643158\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy, f1_scores = model.evaluate(X_val_cnn, y_val)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1_scores)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val_cnn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zeaLcUtZ4Ed",
        "outputId": "d6454361-3a88-4f9e-bad3-183555e0eec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(243, 2)\n",
            "(243, 2)\n",
            "Accuracy for column 0: 0.7325102880658436\n",
            "Accuracy for column 1: 0.7037037037037037\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.2917821324887833, 0.5591073187265774\n"
          ]
        }
      ],
      "source": [
        "# prompt: help me calculate the accuracy score of y_pred and y_val for each column separately\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming y_pred and y_val are numpy arrays\n",
        "# and y_pred contains probabilities for each class\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "print(y_val.shape)\n",
        "print(y_pred_classes.shape)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "## weighted F1 score\n",
        "# print(y_val.shape)\n",
        "# print(y_pred_classes.shape)\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.float32)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-lk4c8taEfx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8FVmAr4cJBj"
      },
      "source": [
        "### Add meta data in dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH346VGAccSg",
        "outputId": "edb9f704-88c2-46c4-d5f0-dec598f988c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(970, 27)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_meta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdLTx77UcJj9",
        "outputId": "8410483d-a547-4e77-e9eb-f59f81ab84ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚            \u001b[38;5;34m320\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m18,496\u001b[0m â”‚ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚         \u001b[38;5;34m73,856\u001b[0m â”‚ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67712\u001b[0m)          â”‚              \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚      \u001b[38;5;34m8,667,264\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_1             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)             â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m155\u001b[0m)            â”‚              \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚          \u001b[38;5;34m9,984\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚              \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚            \u001b[38;5;34m130\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)              </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">        Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to           </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67712</span>)          â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,667,264</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_1             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)             â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span>)            â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,984</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,770,050\u001b[0m (33.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,770,050</span> (33.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,770,050\u001b[0m (33.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,770,050</span> (33.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.7056 - loss: 1.0406 - val_accuracy: 0.7990 - val_loss: 0.6133\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.7197 - loss: 0.6494 - val_accuracy: 0.8608 - val_loss: 0.5708\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.7697 - loss: 0.6460 - val_accuracy: 0.8144 - val_loss: 0.5630\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.8074 - loss: 0.6076 - val_accuracy: 0.8041 - val_loss: 0.5532\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.7808 - loss: 0.5855 - val_accuracy: 0.8247 - val_loss: 0.5393\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.7746 - loss: 0.5834 - val_accuracy: 0.8247 - val_loss: 0.5401\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8028 - loss: 0.5564 - val_accuracy: 0.8144 - val_loss: 0.5342\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.7984 - loss: 0.5629 - val_accuracy: 0.8247 - val_loss: 0.5252\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.8095 - loss: 0.5478 - val_accuracy: 0.8093 - val_loss: 0.5240\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.8057 - loss: 0.5341 - val_accuracy: 0.7938 - val_loss: 0.5224\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.7919 - loss: 0.5500 - val_accuracy: 0.8299 - val_loss: 0.5138\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8082 - loss: 0.5360 - val_accuracy: 0.8299 - val_loss: 0.5138\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.7684 - loss: 0.5482 - val_accuracy: 0.8247 - val_loss: 0.5117\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8074 - loss: 0.5255 - val_accuracy: 0.8247 - val_loss: 0.5095\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.7970 - loss: 0.5106 - val_accuracy: 0.8247 - val_loss: 0.5073\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8144 - loss: 0.5266 - val_accuracy: 0.8247 - val_loss: 0.5051\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.8130 - loss: 0.5192 - val_accuracy: 0.8196 - val_loss: 0.5042\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8244 - loss: 0.5164 - val_accuracy: 0.8144 - val_loss: 0.5043\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8038 - loss: 0.5087 - val_accuracy: 0.8144 - val_loss: 0.5032\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.8099 - loss: 0.5314 - val_accuracy: 0.8196 - val_loss: 0.5026\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.8418 - loss: 0.5052 - val_accuracy: 0.8196 - val_loss: 0.5027\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8008 - loss: 0.4992 - val_accuracy: 0.8196 - val_loss: 0.5002\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8078 - loss: 0.5083 - val_accuracy: 0.8144 - val_loss: 0.4985\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8246 - loss: 0.5032 - val_accuracy: 0.8144 - val_loss: 0.4958\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.7982 - loss: 0.5146 - val_accuracy: 0.8093 - val_loss: 0.4968\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.8039 - loss: 0.5118 - val_accuracy: 0.8299 - val_loss: 0.4981\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.8154 - loss: 0.4894 - val_accuracy: 0.8041 - val_loss: 0.4972\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.7876 - loss: 0.5097 - val_accuracy: 0.8247 - val_loss: 0.4979\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8214 - loss: 0.5085 - val_accuracy: 0.8247 - val_loss: 0.4980\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.8200 - loss: 0.5019 - val_accuracy: 0.8093 - val_loss: 0.4983\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8072 - loss: 0.4906 - val_accuracy: 0.8402 - val_loss: 0.4998\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.8024 - loss: 0.4895 - val_accuracy: 0.8196 - val_loss: 0.5003\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.7919 - loss: 0.4882 - val_accuracy: 0.8196 - val_loss: 0.4986\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.8064 - loss: 0.4698 - val_accuracy: 0.8299 - val_loss: 0.4992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d5b74ac77d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# prompt: use the connectome_matrices (n, 200,200) as input, build a convolutional neural network to predict on the y_train, which is a two column of binary categorical output. use keras package. In the dense layer, add another input of X_train_meta with shape (n, 27) and combine with the cnn layer outputs together to get final prediction. use keras sequential if possible\n",
        "\n",
        "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Reshape the connectome matrices for CNN input (add a channel dimension)\n",
        "X_train_cnn = X_train_mri[..., np.newaxis]\n",
        "X_val_cnn = X_val_mri[..., np.newaxis]\n",
        "\n",
        "# Define the input layers\n",
        "input_cnn = Input(shape=(200, 200, 1))\n",
        "input_meta = Input(shape=(27,))  # Assuming X_train_meta has shape (n, 27)\n",
        "\n",
        "# CNN part\n",
        "x = Conv2D(32, (3, 3), activation='relu')(input_cnn)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Combine CNN output with meta data\n",
        "combined = concatenate([x, input_meta])\n",
        "\n",
        "# Dense layers\n",
        "y = Dense(64, activation='relu')(combined)\n",
        "y = Dropout(0.5)(y)\n",
        "output = Dense(2, activation='sigmoid')(y)  # Output layer with 2 cells and sigmoid activation\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[input_cnn, input_meta], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit([X_train_cnn, X_train_meta], y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h__-F4bdtPc",
        "outputId": "5d1e9740-4095-4898-9690-3a824c96a86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8470 - loss: 0.5169\n",
            "Loss: 0.5104838013648987\n",
            "Accuracy: 0.8353909254074097\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 658ms/step\n",
            "Accuracy for column 0: 0.7983539094650206\n",
            "Accuracy for column 1: 0.6995884773662552\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.4458827777719181, 0.6906567037134168\n"
          ]
        }
      ],
      "source": [
        " from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_val_cnn, X_val_meta], y_val)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"F1 Score:\", f1_scores)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict([X_val_cnn, X_val_meta])\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.float32)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6CBH02VcJvh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egzjf2r8jLOj"
      },
      "source": [
        "### 1D Conv NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV4arv-NjLkh",
        "outputId": "07be1278-6ffa-40c3-ef06-c5bdf930a021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(970, 19927)\n",
            "(970, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PGI6PfozjLwg",
        "outputId": "45b327f7-7bf6-4392-9481-006590411a5e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c052606fe8c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Reshape the data for 1D CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_val_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_test_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "# prompt: build a 1D convolutional neural network using keras, use X_train and y_train to train the model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Reshape the data for 1D CNN\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "X_test_cnn = df_test_X.reshape(df_test_X.shape[0], df_test_X.shape[1], 1)\n",
        "\n",
        "# Define the 1D CNN model\n",
        "# model = keras.Sequential([\n",
        "#     Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "#     MaxPooling1D(pool_size=2),\n",
        "#     Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "#     MaxPooling1D(pool_size=2),\n",
        "#     Flatten(),\n",
        "#     Dense(128, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(2, activation='sigmoid')  # Output layer with 2 cells and sigmoid activation\n",
        "# ])\n",
        "\n",
        "model = keras.Sequential([\n",
        "    Conv1D(filters=1024, kernel_size=3, dilation_rate= 2, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    Conv1D(filters=128, kernel_size=3, dilation_rate= 2, activation='relu'),\n",
        "    # GlobalAveragePooling1D(),\n",
        "    GlobalMaxPooling1D(),\n",
        "    # Flatten(),\n",
        "    # Dense(128, activation='relu'),\n",
        "    Dropout(0.6),\n",
        "    Dense(2, activation='sigmoid')  # Output layer with 2 cells and sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# Set up early stopping to monitor validation accuracy and stop when it stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o7H7k9rLmyWU",
        "outputId": "482198d2-c086-4bc4-d25a-1312acdf70eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_1d_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"cnn_1d_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_3           â”‚ ?                           â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d_3               â”‚ ?                           â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ ?                           â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_3           â”‚ ?                           â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d_3               â”‚ ?                           â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ ?                           â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling CNN_1D.call().\n\n\u001b[1mLayer \"conv1d_8\" expects 1 input(s), but it received 2500 input tensors. Inputs received: [<tf.Tensor 'cnn_1d_3_1/Cast:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_3:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_4:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_5:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_6:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_7:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_8:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_9:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_10:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_11:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_12:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_13:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_14:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_15:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_16:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_17:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_18:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_19:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_20:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_21:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_22:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_23:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_24:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_25:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_26:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_27:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_28:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_29:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_30:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_31:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_32:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_33:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_34:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_35:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_36:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_37:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_38:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_39:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_40:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_41:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_42:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_43:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_44:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_45:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_46:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_47:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_48:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_49:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_50:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_51:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_52:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_53:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_54:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_55:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_56:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_57:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_58:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_59:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_60:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_61:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_62:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_63:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_64:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_65:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_66:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_67:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_68:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_69:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_70:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_71:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_72:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_73:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_74:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_75:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_76:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_77:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_78:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_79:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_80:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_81:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_82:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_83:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_84:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_85:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_86:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_87:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_88:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_89:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_90:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_91:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_92:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_93:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_94:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_95:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_96:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_97:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_98:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_99:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_100:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_101:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_102:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_103:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_104:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_105:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_106:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_107:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_108:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_109:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_110:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_111:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_112:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_113:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_114:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_115:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_116:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_117:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_118:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_119:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_120:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_121:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_122:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_123:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_124:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_125:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_126:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_127:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_128:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_129:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_130:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_131:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_132:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_133:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_134:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_135:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_136:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_137:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_138:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_139:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_140:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_141:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_142:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_143:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_144:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_145:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_146:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_147:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_148:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_149:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_150:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_151:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_152:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_153:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_154:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_155:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_156:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_157:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_158:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_159:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_160:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_161:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_162:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_163:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_164:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_165:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_166:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_167:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_168:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_169:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_170:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_171:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_172:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_173:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_174:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_175:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_176:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_177:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_178:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_179:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_180:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_181:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_182:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_183:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_184:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_185:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_186:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_187:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_188:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_189:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_190:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_191:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_192:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_193:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_194:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_195:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_196:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_197:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_198:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_199:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_200:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_201:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_202:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_203:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_204:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_205:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_206:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_207:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_208:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_209:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_210:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_211:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_212:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_213:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_214:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_215:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_216:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_217:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_218:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_219:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_220:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_221:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_222:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_223:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_224:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_225:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_226:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_227:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_228:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_229:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_230:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_231:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_232:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_233:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_234:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_235:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_236:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_237:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_238:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_239:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_240:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_241:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_242:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_243:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_244:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_245:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_246:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_247:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_248:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_249:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_250:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_251:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_252:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_253:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_254:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_255:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_256:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_257:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_258:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_259:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_260:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_261:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_262:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_263:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_264:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_265:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_266:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_267:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_268:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_269:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_270:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_271:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_272:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_273:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_274:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_275:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_276:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_277:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_278:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_279:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_280:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_281:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_282:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_283:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_284:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_285:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_286:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_287:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_288:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_289:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_290:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_291:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_292:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_293:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_294:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_295:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_296:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_297:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_298:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_299:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_300:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_301:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_302:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_303:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_304:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_305:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_306:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_307:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_308:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_309:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_310:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_311:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_312:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_313:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_314:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_315:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_316:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_317:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_318:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_319:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_320:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_321:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_322:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_323:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_324:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_325:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_326:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_327:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_328:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_329:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_330:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_331:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_332:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_333:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_334:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_335:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_336:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_337:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_338:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_339:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_340:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_341:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_342:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_343:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_344:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_345:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_346:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_347:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_348:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_349:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_350:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_351:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_352:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_353:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_354:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_355:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_356:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_357:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_358:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_359:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_360:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_361:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_362:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_363:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_364:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_365:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_366:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_367:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_368:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_369:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_370:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_371:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_372:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_373:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_374:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_375:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_376:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_377:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_378:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_379:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_380:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_381:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_382:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_383:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_384:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_385:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_386:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_387:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_388:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_389:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_390:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_391:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_392:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_393:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_394:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_395:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_396:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_397:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_398:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_399:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_400:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_401:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_402:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_403:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_404:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_405:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_406:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_407:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_408:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_409:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_410:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_411:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_412:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_413:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_414:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_415:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_416:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_417:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_418:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_419:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_420:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_421:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_422:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_423:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_424:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_425:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_426:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_427:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_428:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_429:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_430:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_431:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_432:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_433:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_434:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_435:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_436:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_437:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_438:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_439:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_440:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_441:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_442:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_443:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_444:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_445:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_446:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_447:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_448:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_449:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_450:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_451:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_452:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_453:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_454:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_455:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_456:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_457:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_458:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_459:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_460:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_461:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_462:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_463:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_464:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_465:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_466:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_467:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_468:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_469:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_470:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_471:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_472:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_473:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_474:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_475:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_476:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_477:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_478:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_479:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_480:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_481:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_482:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_483:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_484:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_485:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_486:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_487:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_488:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_489:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_490:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_491:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_492:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_493:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_494:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_495:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_496:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_497:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_498:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_499:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_500:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_501:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_502:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_503:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_504:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_505:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_506:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_507:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_508:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_509:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_510:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_511:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_512:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_513:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_514:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_515:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_516:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_517:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_518:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_519:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_520:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_521:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_522:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_523:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_524:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_525:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_526:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_527:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_528:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_529:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_530:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_531:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_532:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_533:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_534:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_535:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_536:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_537:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_538:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_539:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_540:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_541:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_542:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_543:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_544:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_545:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_546:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_547:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_548:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_549:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_550:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_551:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_552:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_553:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_554:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_555:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_556:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_557:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_558:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_559:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_560:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_561:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_562:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_563:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_564:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_565:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_566:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_567:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_568:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_569:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_570:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_571:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_572:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_573:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_574:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_575:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_576:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_577:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_578:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_579:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_580:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_581:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_582:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_583:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_584:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_585:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_586:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_587:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_588:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_589:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_590:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_591:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_592:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_593:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_594:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_595:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_596:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_597:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_598:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_599:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_600:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_601:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_602:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_603:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_604:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_605:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_606:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_607:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_608:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_609:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_610:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_611:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_612:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_613:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_614:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_615:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_616:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_617:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_618:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_619:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_620:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_621:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_622:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_623:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_624:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_625:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_626:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_627:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_628:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_629:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_630:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_631:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_632:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_633:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_634:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_635:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_636:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_637:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_638:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_639:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_640:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_641:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_642:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_643:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_644:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_645:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_646:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_647:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_648:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_649:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_650:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_651:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_652:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_653:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_654:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_655:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_656:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_657:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_658:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_659:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_660:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_661:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_662:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_663:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_664:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_665:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_666:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_667:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_668:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_669:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_670:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_671:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_672:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_673:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_674:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_675:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_676:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_677:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_678:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_679:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_680:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_681:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_682:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_683:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_684:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_685:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_686:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_687:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_688:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_689:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_690:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_691:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_692:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_693:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_694:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_695:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_696:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_697:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_698:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_699:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_700:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_701:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_702:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_703:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_704:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_705:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_706:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_707:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_708:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_709:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_710:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_711:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_712:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_713:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_714:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_715:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_716:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_717:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_718:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_719:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_720:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_721:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_722:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_723:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_724:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_725:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_726:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_727:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_728:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_729:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_730:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_731:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_732:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_733:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_734:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_735:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_736:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_737:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_738:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_739:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_740:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_741:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_742:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_743:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_744:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_745:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_746:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_747:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_748:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_749:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_750:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_751:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_752:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_753:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_754:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_755:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_756:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_757:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_758:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_759:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_760:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_761:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_762:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_763:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_764:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_765:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_766:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_767:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_768:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_769:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_770:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_771:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_772:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_773:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_774:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_775:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_776:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_777:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_778:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_779:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_780:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_781:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_782:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_783:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_784:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_785:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_786:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_787:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_788:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_789:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_790:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_791:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_792:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_793:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_794:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_795:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_796:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_797:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_798:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_799:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_800:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_801:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_802:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_803:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_804:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_805:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_806:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_807:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_808:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_809:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_810:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_811:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_812:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_813:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_814:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_815:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_816:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_817:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_818:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_819:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_820:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_821:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_822:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_823:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_824:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_825:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_826:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_827:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_828:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_829:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_830:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_831:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_832:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_833:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_834:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_835:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_836:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_837:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_838:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_839:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_840:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_841:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_842:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_843:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_844:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_845:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_846:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_847:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_848:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_849:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_850:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_851:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_852:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_853:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_854:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_855:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_856:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_857:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_858:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_859:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_860:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_861:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_862:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_863:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_864:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_865:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_866:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_867:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_868:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_869:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_870:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_871:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_872:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_873:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_874:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_875:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_876:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_877:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_878:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_879:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_880:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_881:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_882:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_883:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_884:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_885:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_886:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_887:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_888:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_889:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_890:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_891:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_892:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_893:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_894:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_895:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_896:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_897:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_898:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_899:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_900:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_901:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_902:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_903:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_904:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_905:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_906:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_907:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_908:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_909:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_910:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_911:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_912:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_913:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_914:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_915:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_916:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_917:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_918:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_919:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_920:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_921:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_922:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_923:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_924:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_925:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_926:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_927:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_928:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_929:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_930:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_931:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_932:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_933:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_934:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_935:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_936:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_937:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_938:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_939:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_940:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_941:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_942:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_943:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_944:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_945:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_946:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_947:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_948:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_949:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_950:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_951:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_952:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_953:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_954:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_955:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_956:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_957:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_958:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_959:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_960:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_961:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_962:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_963:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_964:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_965:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_966:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_967:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_968:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_969:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_970:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_971:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_972:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_973:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_974:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_975:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_976:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_977:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_978:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_979:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_980:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_981:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_982:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_983:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_984:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_985:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_986:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_987:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_988:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_989:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_990:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_991:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_992:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_993:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_994:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_995:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_996:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_997:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_998:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_999:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1000:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1001:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1002:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1003:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1004:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1005:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1006:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1007:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1008:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1009:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1010:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1011:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1012:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1013:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1014:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1015:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1016:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1017:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1018:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1019:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1020:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1021:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1022:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1023:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1024:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1025:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1026:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1027:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1028:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1029:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1030:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1031:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1032:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1033:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1034:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1035:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1036:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1037:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1038:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1039:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1040:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1041:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1042:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1043:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1044:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1045:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1046:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1047:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1048:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1049:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1050:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1051:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1052:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1053:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1054:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1055:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1056:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1057:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1058:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1059:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1060:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1061:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1062:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1063:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1064:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1065:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1066:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1067:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1068:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1069:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1070:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1071:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1072:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1073:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1074:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1075:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1076:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1077:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1078:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1079:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1080:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1081:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1082:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1083:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1084:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1085:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1086:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1087:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1088:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1089:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1090:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1091:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1092:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1093:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1094:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1095:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1096:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1097:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1098:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1099:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1100:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1101:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1102:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1103:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1104:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1105:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1106:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1107:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1108:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1109:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1110:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1111:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1112:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1113:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1114:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1115:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1116:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1117:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1118:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1119:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1120:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1121:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1122:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1123:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1124:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1125:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1126:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1127:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1128:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1129:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1130:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1131:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1132:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1133:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1134:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1135:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1136:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1137:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1138:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1139:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1140:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1141:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1142:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1143:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1144:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1145:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1146:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1147:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1148:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1149:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1150:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1151:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1152:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1153:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1154:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1155:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1156:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1157:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1158:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1159:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1160:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1161:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1162:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1163:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1164:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1165:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1166:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1167:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1168:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1169:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1170:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1171:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1172:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1173:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1174:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1175:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1176:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1177:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1178:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1179:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1180:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1181:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1182:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1183:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1184:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1185:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1186:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1187:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1188:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1189:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1190:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1191:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1192:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1193:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1194:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1195:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1196:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1197:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1198:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1199:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1200:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1201:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1202:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1203:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1204:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1205:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1206:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1207:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1208:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1209:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1210:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1211:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1212:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1213:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1214:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1215:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1216:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1217:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1218:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1219:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1220:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1221:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1222:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1223:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1224:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1225:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1226:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1227:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1228:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1229:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1230:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1231:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1232:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1233:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1234:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1235:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1236:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1237:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1238:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1239:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1240:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1241:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1242:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1243:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1244:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1245:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1246:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1247:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1248:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1249:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1250:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1251:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1252:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1253:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1254:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1255:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1256:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1257:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1258:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1259:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1260:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1261:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1262:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1263:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1264:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1265:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1266:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1267:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1268:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1269:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1270:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1271:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1272:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1273:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1274:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1275:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1276:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1277:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1278:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1279:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1280:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1281:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1282:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1283:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1284:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1285:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1286:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1287:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1288:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1289:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1290:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1291:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1292:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1293:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1294:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1295:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1296:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1297:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1298:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1299:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1300:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1301:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1302:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1303:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1304:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1305:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1306:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1307:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1308:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1309:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1310:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1311:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1312:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1313:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1314:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1315:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1316:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1317:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1318:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1319:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1320:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1321:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1322:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1323:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1324:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1325:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1326:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1327:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1328:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1329:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1330:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1331:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1332:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1333:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1334:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1335:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1336:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1337:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1338:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1339:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1340:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1341:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1342:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1343:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1344:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1345:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1346:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1347:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1348:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1349:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1350:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1351:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1352:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1353:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1354:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1355:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1356:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1357:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1358:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1359:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1360:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1361:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1362:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1363:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1364:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1365:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1366:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1367:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1368:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1369:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1370:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1371:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1372:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1373:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1374:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1375:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1376:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1377:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1378:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1379:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1380:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1381:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1382:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1383:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1384:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1385:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1386:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1387:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1388:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1389:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1390:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1391:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1392:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1393:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1394:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1395:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1396:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1397:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1398:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1399:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1400:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1401:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1402:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1403:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1404:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1405:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1406:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1407:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1408:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1409:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1410:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1411:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1412:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1413:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1414:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1415:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1416:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1417:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1418:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1419:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1420:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1421:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1422:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1423:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1424:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1425:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1426:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1427:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1428:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1429:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1430:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1431:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1432:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1433:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1434:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1435:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1436:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1437:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1438:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1439:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1440:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1441:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1442:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1443:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1444:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1445:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1446:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1447:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1448:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1449:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1450:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1451:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1452:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1453:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1454:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1455:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1456:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1457:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1458:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1459:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1460:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1461:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1462:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1463:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1464:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1465:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1466:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1467:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1468:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1469:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1470:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1471:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1472:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1473:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1474:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1475:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1476:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1477:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1478:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1479:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1480:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1481:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1482:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1483:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1484:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1485:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1486:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1487:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1488:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1489:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1490:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1491:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1492:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1493:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1494:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1495:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1496:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1497:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1498:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1499:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1500:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1501:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1502:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1503:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1504:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1505:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1506:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1507:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1508:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1509:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1510:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1511:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1512:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1513:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1514:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1515:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1516:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1517:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1518:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1519:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1520:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1521:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1522:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1523:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1524:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1525:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1526:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1527:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1528:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1529:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1530:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1531:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1532:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1533:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1534:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1535:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1536:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1537:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1538:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1539:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1540:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1541:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1542:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1543:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1544:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1545:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1546:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1547:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1548:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1549:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1550:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1551:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1552:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1553:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1554:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1555:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1556:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1557:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1558:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1559:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1560:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1561:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1562:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1563:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1564:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1565:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1566:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1567:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1568:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1569:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1570:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1571:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1572:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1573:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1574:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1575:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1576:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1577:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1578:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1579:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1580:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1581:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1582:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1583:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1584:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1585:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1586:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1587:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1588:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1589:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1590:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1591:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1592:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1593:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1594:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1595:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1596:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1597:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1598:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1599:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1600:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1601:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1602:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1603:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1604:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1605:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1606:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1607:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1608:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1609:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1610:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1611:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1612:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1613:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1614:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1615:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1616:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1617:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1618:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1619:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1620:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1621:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1622:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1623:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1624:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1625:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1626:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1627:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1628:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1629:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1630:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1631:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1632:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1633:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1634:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1635:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1636:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1637:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1638:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1639:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1640:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1641:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1642:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1643:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1644:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1645:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1646:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1647:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1648:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1649:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1650:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1651:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1652:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1653:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1654:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1655:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1656:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1657:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1658:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1659:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1660:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1661:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1662:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1663:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1664:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1665:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1666:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1667:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1668:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1669:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1670:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1671:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1672:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1673:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1674:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1675:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1676:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1677:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1678:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1679:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1680:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1681:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1682:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1683:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1684:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1685:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1686:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1687:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1688:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1689:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1690:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1691:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1692:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1693:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1694:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1695:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1696:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1697:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1698:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1699:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1700:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1701:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1702:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1703:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1704:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1705:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1706:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1707:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1708:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1709:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1710:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1711:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1712:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1713:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1714:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1715:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1716:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1717:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1718:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1719:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1720:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1721:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1722:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1723:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1724:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1725:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1726:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1727:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1728:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1729:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1730:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1731:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1732:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1733:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1734:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1735:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1736:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1737:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1738:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1739:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1740:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1741:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1742:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1743:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1744:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1745:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1746:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1747:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1748:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1749:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1750:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1751:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1752:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1753:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1754:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1755:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1756:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1757:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1758:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1759:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1760:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1761:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1762:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1763:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1764:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1765:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1766:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1767:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1768:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1769:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1770:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1771:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1772:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1773:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1774:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1775:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1776:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1777:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1778:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1779:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1780:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1781:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1782:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1783:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1784:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1785:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1786:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1787:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1788:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1789:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1790:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1791:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1792:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1793:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1794:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1795:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1796:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1797:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1798:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1799:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1800:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1801:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1802:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1803:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1804:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1805:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1806:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1807:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1808:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1809:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1810:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1811:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1812:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1813:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1814:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1815:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1816:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1817:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1818:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1819:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1820:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1821:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1822:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1823:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1824:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1825:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1826:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1827:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1828:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1829:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1830:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1831:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1832:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1833:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1834:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1835:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1836:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1837:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1838:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1839:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1840:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1841:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1842:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1843:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1844:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1845:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1846:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1847:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1848:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1849:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1850:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1851:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1852:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1853:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1854:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1855:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1856:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1857:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1858:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1859:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1860:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1861:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1862:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1863:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1864:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1865:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1866:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1867:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1868:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1869:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1870:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1871:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1872:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1873:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1874:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1875:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1876:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1877:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1878:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1879:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1880:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1881:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1882:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1883:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1884:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1885:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1886:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1887:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1888:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1889:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1890:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1891:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1892:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1893:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1894:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1895:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1896:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1897:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1898:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1899:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1900:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1901:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1902:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1903:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1904:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1905:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1906:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1907:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1908:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1909:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1910:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1911:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1912:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1913:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1914:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1915:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1916:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1917:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1918:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1919:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1920:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1921:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1922:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1923:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1924:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1925:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1926:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1927:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1928:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1929:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1930:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1931:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1932:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1933:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1934:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1935:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1936:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1937:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1938:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1939:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1940:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1941:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1942:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1943:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1944:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1945:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1946:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1947:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1948:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1949:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1950:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1951:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1952:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1953:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1954:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1955:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1956:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1957:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1958:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1959:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1960:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1961:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1962:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1963:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1964:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1965:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1966:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1967:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1968:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1969:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1970:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1971:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1972:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1973:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1974:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1975:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1976:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1977:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1978:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1979:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1980:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1981:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1982:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1983:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1984:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1985:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1986:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1987:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1988:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1989:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1990:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1991:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1992:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1993:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1994:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1995:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1996:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1997:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1998:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1999:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2000:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2001:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2002:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2003:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2004:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2005:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2006:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2007:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2008:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2009:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2010:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2011:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2012:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2013:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2014:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2015:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2016:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2017:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2018:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2019:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2020:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2021:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2022:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2023:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2024:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2025:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2026:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2027:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2028:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2029:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2030:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2031:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2032:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2033:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2034:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2035:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2036:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2037:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2038:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2039:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2040:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2041:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2042:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2043:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2044:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2045:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2046:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2047:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2048:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2049:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2050:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2051:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2052:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2053:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2054:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2055:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2056:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2057:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2058:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2059:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2060:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2061:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2062:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2063:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2064:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2065:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2066:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2067:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2068:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2069:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2070:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2071:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2072:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2073:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2074:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2075:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2076:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2077:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2078:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2079:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2080:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2081:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2082:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2083:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2084:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2085:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2086:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2087:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2088:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2089:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2090:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2091:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2092:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2093:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2094:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2095:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2096:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2097:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2098:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2099:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2100:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2101:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2102:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2103:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2104:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2105:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2106:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2107:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2108:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2109:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2110:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2111:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2112:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2113:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2114:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2115:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2116:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2117:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2118:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2119:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2120:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2121:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2122:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2123:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2124:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2125:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2126:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2127:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2128:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2129:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2130:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2131:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2132:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2133:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2134:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2135:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2136:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2137:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2138:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2139:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2140:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2141:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2142:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2143:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2144:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2145:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2146:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2147:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2148:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2149:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2150:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2151:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2152:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2153:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2154:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2155:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2156:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2157:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2158:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2159:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2160:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2161:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2162:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2163:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2164:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2165:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2166:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2167:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2168:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2169:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2170:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2171:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2172:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2173:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2174:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2175:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2176:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2177:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2178:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2179:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2180:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2181:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2182:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2183:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2184:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2185:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2186:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2187:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2188:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2189:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2190:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2191:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2192:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2193:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2194:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2195:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2196:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2197:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2198:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2199:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2200:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2201:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2202:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2203:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2204:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2205:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2206:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2207:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2208:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2209:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2210:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2211:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2212:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2213:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2214:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2215:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2216:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2217:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2218:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2219:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2220:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2221:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2222:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2223:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2224:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2225:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2226:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2227:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2228:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2229:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2230:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2231:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2232:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2233:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2234:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2235:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2236:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2237:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2238:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2239:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2240:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2241:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2242:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2243:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2244:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2245:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2246:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2247:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2248:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2249:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2250:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2251:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2252:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2253:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2254:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2255:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2256:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2257:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2258:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2259:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2260:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2261:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2262:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2263:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2264:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2265:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2266:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2267:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2268:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2269:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2270:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2271:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2272:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2273:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2274:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2275:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2276:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2277:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2278:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2279:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2280:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2281:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2282:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2283:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2284:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2285:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2286:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2287:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2288:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2289:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2290:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2291:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2292:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2293:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2294:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2295:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2296:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2297:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2298:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2299:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2300:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2301:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2302:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2303:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2304:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2305:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2306:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2307:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2308:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2309:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2310:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2311:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2312:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2313:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2314:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2315:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2316:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2317:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2318:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2319:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2320:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2321:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2322:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2323:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2324:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2325:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2326:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2327:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2328:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2329:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2330:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2331:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2332:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2333:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2334:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2335:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2336:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2337:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2338:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2339:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2340:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2341:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2342:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2343:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2344:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2345:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2346:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2347:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2348:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2349:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2350:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2351:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2352:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2353:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2354:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2355:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2356:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2357:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2358:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2359:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2360:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2361:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2362:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2363:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2364:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2365:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2366:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2367:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2368:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2369:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2370:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2371:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2372:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2373:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2374:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2375:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2376:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2377:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2378:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2379:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2380:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2381:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2382:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2383:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2384:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2385:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2386:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2387:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2388:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2389:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2390:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2391:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2392:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2393:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2394:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2395:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2396:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2397:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2398:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2399:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2400:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2401:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2402:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2403:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2404:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2405:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2406:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2407:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2408:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2409:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2410:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2411:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2412:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2413:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2414:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2415:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2416:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2417:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2418:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2419:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2420:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2421:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2422:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2423:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2424:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2425:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2426:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2427:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2428:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2429:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2430:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2431:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2432:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2433:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2434:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2435:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2436:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2437:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2438:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2439:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2440:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2441:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2442:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2443:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2444:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2445:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2446:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2447:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2448:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2449:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2450:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2451:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2452:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2453:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2454:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2455:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2456:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2457:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2458:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2459:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2460:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2461:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2462:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2463:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2464:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2465:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2466:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2467:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2468:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2469:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2470:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2471:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2472:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2473:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2474:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2475:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2476:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2477:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2478:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2479:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2480:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2481:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2482:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2483:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2484:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2485:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2486:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2487:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2488:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2489:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2490:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2491:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2492:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2493:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2494:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2495:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2496:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2497:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2498:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2499:0' shape=() dtype=float32>]\u001b[0m\n\nArguments received by CNN_1D.call():\n  â€¢ inputs=tf.Tensor(shape=(None, 19927), dtype=float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-da863401a259>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Set up early stopping to monitor validation accuracy and stop when it stops improving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-da863401a259>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# x = tf.squeeze(inputs, axis=1)  # B, T, C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B, T, C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mh_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling CNN_1D.call().\n\n\u001b[1mLayer \"conv1d_8\" expects 1 input(s), but it received 2500 input tensors. Inputs received: [<tf.Tensor 'cnn_1d_3_1/Cast:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_1:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_2:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_3:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_4:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_5:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_6:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_7:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_8:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_9:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_10:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_11:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_12:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_13:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_14:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_15:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_16:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_17:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_18:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_19:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_20:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_21:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_22:0' shape=() dtype=float32>, <tf.Tensor 'cnn_1d_3_1/Cast_23:0' shape=() dtype=float32>...\n\nArguments received by CNN_1D.call():\n  â€¢ inputs=tf.Tensor(shape=(None, 19927), dtype=float32)"
          ]
        }
      ],
      "source": [
        "# prompt: Help me write a 1D convolutional neural network layer using keras package. convert the given model to keras with a cutome class but do not change any layer and setups. the given model is written in pytorch:\n",
        "# ### get from benchmark paper: https://github.com/elgazzarr/fMRIGNNs/blob/main/networks/baseline_models.py\n",
        "# class CNN_1D(nn.Module):\n",
        "#     def __init__(self, nrois, f1, f2, dilation_exponential, k1, k2, dropout, readout):\n",
        "#         super(CNN_1D, self).__init__()\n",
        "#         self.readout = readout\n",
        "#         self.layer0 = Temporal_Conv(nrois, f1, k1, dilation_exponential, F.relu)\n",
        "#         self.layer1 = Temporal_Conv(f1, f2, k1, dilation_exponential, F.relu)\n",
        "#         self.avg = nn.AdaptiveAvgPool1d(1)\n",
        "#         self.max = nn.AdaptiveMaxPool1d(1)\n",
        "#         dim = 2 if readout == 'meanmax' else 1\n",
        "#         self.drop = nn.Dropout(p=dropout)\n",
        "#         self.classify = nn.Linear(f2*dim, 2)\n",
        "#     def forward(self, data):\n",
        "#         x = torch.squeeze(data.t) # B, 1, T,C\n",
        "#         h0 = self.layer0(x)  # B,t,C\n",
        "#         h1 = self.layer1(h0)\n",
        "#         h_avg = torch.squeeze(self.avg(h1))\n",
        "#         h_max = torch.squeeze(self.max(h1))\n",
        "#         if self.readout == 'meanmax':\n",
        "#             h = torch.cat((h_avg, h_max),1)\n",
        "#         else:\n",
        "#             h = h_avg\n",
        "#         h = self.drop(h)\n",
        "#         hg = self.classify(h)\n",
        "#         return hg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class CNN_1D(keras.Model):\n",
        "    def __init__(self, nrois, f1, f2, dilation_exponential, k1, k2, dropout, readout):\n",
        "        super(CNN_1D, self).__init__()\n",
        "        self.readout = readout\n",
        "        self.layer0 = Conv1D(filters=f1, kernel_size=k1, dilation_rate = dilation_exponential, activation='relu', input_shape=nrois)\n",
        "        self.layer1 = Conv1D(filters=f2, kernel_size=k1, dilation_rate = dilation_exponential, activation='relu')\n",
        "        self.avg = tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.max = tf.keras.layers.GlobalMaxPooling1D()\n",
        "        dim = 2 if readout == 'meanmax' else 1\n",
        "        self.drop = Dropout(dropout)\n",
        "        self.classify = Dense(2, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x = tf.squeeze(inputs, axis=1)  # B, T, C\n",
        "        h0 = self.layer0(x)  # B, T, C\n",
        "        h1 = self.layer1(h0)\n",
        "        h_avg = self.avg(h1)\n",
        "        h_max = self.max(h1)\n",
        "        if self.readout == 'meanmax':\n",
        "            h = tf.concat([h_avg, h_max], axis=1)\n",
        "        else:\n",
        "            h = h_avg\n",
        "        h = self.drop(h)\n",
        "        hg = self.classify(h)\n",
        "        return hg\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X_train_cnn is your input data with shape (num_samples, timesteps, num_features)\n",
        "# nrois, f1, f2, dilation_exponential, k1, k2, dropout, readout = ...  # Your hyperparameters\n",
        "\n",
        "model = CNN_1D(X_train_cnn.shape[1], 1024, 128, 2, 3, 3, 0.2, 'mean')\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# Set up early stopping to monitor validation accuracy and stop when it stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9IGnKGHkIIE",
        "outputId": "4afba2f3-0232-4b32-c8a9-4c84892784d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9192 - loss: 0.5886\n",
            "Loss: 0.6029148101806641\n",
            "Accuracy: 0.8888888955116272\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step\n",
            "Accuracy for column 0: 0.7325102880658436\n",
            "Accuracy for column 1: 0.7037037037037037\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.2917821324887833, 0.5591073187265774\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val_cnn, y_val)\n",
        "# loss, f1_scores = model.evaluate([val_feature_matrices, val_adjacency_matrices, X_val_meta], y_val)\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"F1 Score:\", f1_scores)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val_cnn)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.int16)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.int16)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXvtd991aeiT",
        "outputId": "712c3bf8-dfde-4434-c42c-3de7c27385ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6701628 , 0.36580786],\n",
              "       [0.70929277, 0.33245313],\n",
              "       [0.66198105, 0.37266955],\n",
              "       [0.66988957, 0.36610785],\n",
              "       [0.67010266, 0.36592004],\n",
              "       [0.6697527 , 0.36617792],\n",
              "       [0.67086065, 0.36521444],\n",
              "       [0.6699452 , 0.36614496],\n",
              "       [0.66844577, 0.3673511 ],\n",
              "       [0.68649197, 0.3519568 ],\n",
              "       [0.67094713, 0.3651801 ],\n",
              "       [0.668623  , 0.3671449 ],\n",
              "       [0.69652355, 0.3433908 ],\n",
              "       [0.670494  , 0.36554435],\n",
              "       [0.6706049 , 0.36546618],\n",
              "       [0.6703826 , 0.36572167],\n",
              "       [0.67239136, 0.36395487],\n",
              "       [0.67024   , 0.3657479 ],\n",
              "       [0.6699944 , 0.36595142],\n",
              "       [0.67110175, 0.3651044 ],\n",
              "       [0.6694167 , 0.36646432],\n",
              "       [0.685463  , 0.3528602 ],\n",
              "       [0.6692479 , 0.36657172],\n",
              "       [0.67327774, 0.36319688],\n",
              "       [0.6694805 , 0.36639315],\n",
              "       [0.6725984 , 0.36374056],\n",
              "       [0.6827173 , 0.35517776],\n",
              "       [0.6718733 , 0.36438206],\n",
              "       [0.6730414 , 0.36335593],\n",
              "       [0.6708032 , 0.3654232 ],\n",
              "       [0.6710332 , 0.36508316],\n",
              "       [0.6851445 , 0.35307205],\n",
              "       [0.6711504 , 0.36501876],\n",
              "       [0.669816  , 0.36607537],\n",
              "       [0.6710001 , 0.36512876],\n",
              "       [0.68348855, 0.3545507 ],\n",
              "       [0.6714426 , 0.364707  ],\n",
              "       [0.67027956, 0.3656966 ],\n",
              "       [0.6712755 , 0.3648995 ],\n",
              "       [0.6701001 , 0.3658709 ],\n",
              "       [0.6709591 , 0.36517292],\n",
              "       [0.6682934 , 0.3674085 ],\n",
              "       [0.6775938 , 0.35954502],\n",
              "       [0.6712955 , 0.36493793],\n",
              "       [0.67414254, 0.36244363],\n",
              "       [0.68550944, 0.3527739 ],\n",
              "       [0.6721354 , 0.3641176 ],\n",
              "       [0.67046374, 0.36562195],\n",
              "       [0.6709122 , 0.36518627],\n",
              "       [0.68009055, 0.35745373],\n",
              "       [0.67144513, 0.36476344],\n",
              "       [0.6706753 , 0.36546144],\n",
              "       [0.67177033, 0.36451492],\n",
              "       [0.66902316, 0.36692128],\n",
              "       [0.68205243, 0.35574526],\n",
              "       [0.6701467 , 0.36583385],\n",
              "       [0.67068905, 0.3653465 ],\n",
              "       [0.70823216, 0.33339277],\n",
              "       [0.671599  , 0.3645978 ],\n",
              "       [0.6707203 , 0.36531833],\n",
              "       [0.67028314, 0.36577892],\n",
              "       [0.6716279 , 0.3646248 ],\n",
              "       [0.66946304, 0.366446  ],\n",
              "       [0.6700672 , 0.36591598],\n",
              "       [0.6706852 , 0.3653632 ],\n",
              "       [0.67132854, 0.364918  ],\n",
              "       [0.6714043 , 0.36478338],\n",
              "       [0.66938883, 0.36649472],\n",
              "       [0.6732709 , 0.3631627 ],\n",
              "       [0.66928625, 0.3665484 ],\n",
              "       [0.66873896, 0.36706737],\n",
              "       [0.67065156, 0.36544994],\n",
              "       [0.68520325, 0.3530613 ],\n",
              "       [0.6702004 , 0.36573896],\n",
              "       [0.6685324 , 0.36718857],\n",
              "       [0.6695302 , 0.36634725],\n",
              "       [0.67130417, 0.36493945],\n",
              "       [0.66979843, 0.3662201 ],\n",
              "       [0.6730059 , 0.36337745],\n",
              "       [0.66783667, 0.3678814 ],\n",
              "       [0.6820409 , 0.3557759 ],\n",
              "       [0.6717125 , 0.364588  ],\n",
              "       [0.67154473, 0.36465576],\n",
              "       [0.672917  , 0.36354733],\n",
              "       [0.6670284 , 0.3685287 ],\n",
              "       [0.66910404, 0.3667853 ],\n",
              "       [0.67080194, 0.36527875],\n",
              "       [0.6706432 , 0.3654636 ],\n",
              "       [0.6724424 , 0.3638715 ],\n",
              "       [0.669039  , 0.36682972],\n",
              "       [0.668891  , 0.36691663],\n",
              "       [0.67038256, 0.36563975],\n",
              "       [0.66700673, 0.3685053 ],\n",
              "       [0.6708298 , 0.36526254],\n",
              "       [0.6713282 , 0.3648453 ],\n",
              "       [0.67187214, 0.36434546],\n",
              "       [0.6713401 , 0.36488834],\n",
              "       [0.6688269 , 0.36693475],\n",
              "       [0.68244237, 0.35541984],\n",
              "       [0.7051974 , 0.33600762],\n",
              "       [0.66951716, 0.3663896 ],\n",
              "       [0.6727602 , 0.36356172],\n",
              "       [0.6714699 , 0.3647917 ],\n",
              "       [0.6673382 , 0.36819115],\n",
              "       [0.6698532 , 0.36611328],\n",
              "       [0.669147  , 0.36666265],\n",
              "       [0.6703351 , 0.36565557],\n",
              "       [0.6716888 , 0.36455503],\n",
              "       [0.67066145, 0.36537948],\n",
              "       [0.66781855, 0.36786687],\n",
              "       [0.6720574 , 0.36422694],\n",
              "       [0.67350465, 0.36304682],\n",
              "       [0.67017233, 0.36583263],\n",
              "       [0.67151445, 0.3648137 ],\n",
              "       [0.66926605, 0.36655122],\n",
              "       [0.6792502 , 0.35817808],\n",
              "       [0.6699245 , 0.3660659 ],\n",
              "       [0.6840016 , 0.35409236],\n",
              "       [0.66999865, 0.36605048],\n",
              "       [0.6843788 , 0.3537661 ],\n",
              "       [0.6714302 , 0.36475575],\n",
              "       [0.6708572 , 0.36527357],\n",
              "       [0.68552023, 0.35275474],\n",
              "       [0.67195255, 0.36434218],\n",
              "       [0.6686719 , 0.36709705],\n",
              "       [0.6731149 , 0.3632926 ],\n",
              "       [0.6684298 , 0.36734247],\n",
              "       [0.6709924 , 0.36515024],\n",
              "       [0.67002225, 0.36595324],\n",
              "       [0.70467865, 0.33644652],\n",
              "       [0.67097765, 0.36510113],\n",
              "       [0.670571  , 0.36547336],\n",
              "       [0.6717143 , 0.36449882],\n",
              "       [0.67265207, 0.36367586],\n",
              "       [0.682418  , 0.35545647],\n",
              "       [0.668753  , 0.3669928 ],\n",
              "       [0.6750398 , 0.3616473 ],\n",
              "       [0.67311543, 0.36336777],\n",
              "       [0.7053161 , 0.33591866],\n",
              "       [0.66987336, 0.3660337 ],\n",
              "       [0.67174155, 0.36450592],\n",
              "       [0.68285406, 0.35507745],\n",
              "       [0.6716885 , 0.36457586],\n",
              "       [0.68453395, 0.35361803],\n",
              "       [0.67936623, 0.3580249 ],\n",
              "       [0.67307174, 0.3634193 ],\n",
              "       [0.6848979 , 0.35333073],\n",
              "       [0.66855395, 0.36721992],\n",
              "       [0.68229467, 0.35553053],\n",
              "       [0.66678774, 0.368693  ],\n",
              "       [0.6704951 , 0.3655339 ],\n",
              "       [0.67120045, 0.3650727 ],\n",
              "       [0.68313795, 0.35479993],\n",
              "       [0.68248796, 0.35536107],\n",
              "       [0.66942024, 0.36653346],\n",
              "       [0.6694199 , 0.3665591 ],\n",
              "       [0.67124474, 0.3649394 ],\n",
              "       [0.6684926 , 0.36726588],\n",
              "       [0.6717636 , 0.3644397 ],\n",
              "       [0.68383867, 0.35423347],\n",
              "       [0.6699202 , 0.36605477],\n",
              "       [0.6776885 , 0.35939887],\n",
              "       [0.6721856 , 0.3640921 ],\n",
              "       [0.6702051 , 0.36583197],\n",
              "       [0.66853184, 0.36722627],\n",
              "       [0.6731096 , 0.36344013],\n",
              "       [0.6734266 , 0.36301598],\n",
              "       [0.66961324, 0.36633605],\n",
              "       [0.6681859 , 0.36756718],\n",
              "       [0.66962653, 0.36632538],\n",
              "       [0.6731815 , 0.36325037],\n",
              "       [0.6665007 , 0.3689334 ],\n",
              "       [0.6689105 , 0.3668787 ],\n",
              "       [0.6715585 , 0.36463773],\n",
              "       [0.67040604, 0.36562157],\n",
              "       [0.68404686, 0.35409164],\n",
              "       [0.68436736, 0.35378137],\n",
              "       [0.67215586, 0.36414766],\n",
              "       [0.6708294 , 0.36523914],\n",
              "       [0.67350477, 0.36297733],\n",
              "       [0.6718029 , 0.3644883 ],\n",
              "       [0.6855018 , 0.35280797],\n",
              "       [0.67018265, 0.36584073],\n",
              "       [0.6723654 , 0.36395726],\n",
              "       [0.6751212 , 0.36171857],\n",
              "       [0.68186337, 0.35591403],\n",
              "       [0.6689089 , 0.3669006 ],\n",
              "       [0.67067206, 0.36536667],\n",
              "       [0.6726387 , 0.36374933],\n",
              "       [0.71046066, 0.33144966],\n",
              "       [0.66720843, 0.36832023],\n",
              "       [0.67005104, 0.36593816],\n",
              "       [0.66880894, 0.36701623],\n",
              "       [0.70289665, 0.3379377 ],\n",
              "       [0.6811193 , 0.35659033],\n",
              "       [0.67126805, 0.36491612],\n",
              "       [0.6682862 , 0.36756283],\n",
              "       [0.67216426, 0.36412752],\n",
              "       [0.6857926 , 0.35252267],\n",
              "       [0.67050385, 0.36553526],\n",
              "       [0.6698334 , 0.366197  ],\n",
              "       [0.66945446, 0.36644727],\n",
              "       [0.67073524, 0.36537895],\n",
              "       [0.70131505, 0.33932152],\n",
              "       [0.684603  , 0.3535764 ],\n",
              "       [0.6690516 , 0.36678842],\n",
              "       [0.68293273, 0.35502875],\n",
              "       [0.6696214 , 0.36627024],\n",
              "       [0.6701002 , 0.36595953],\n",
              "       [0.6826414 , 0.3552115 ],\n",
              "       [0.67351496, 0.3630115 ],\n",
              "       [0.669582  , 0.36630157],\n",
              "       [0.6695574 , 0.36632988],\n",
              "       [0.6823494 , 0.35547972],\n",
              "       [0.6703519 , 0.36565518],\n",
              "       [0.67239505, 0.36395565],\n",
              "       [0.6701315 , 0.36585042],\n",
              "       [0.67464805, 0.36199528],\n",
              "       [0.6713362 , 0.36493894],\n",
              "       [0.6808024 , 0.3568873 ],\n",
              "       [0.67933565, 0.35808286],\n",
              "       [0.6713488 , 0.3647995 ],\n",
              "       [0.6680735 , 0.3675429 ],\n",
              "       [0.67095923, 0.36517972],\n",
              "       [0.6719897 , 0.3642585 ],\n",
              "       [0.67204463, 0.36424482],\n",
              "       [0.66853946, 0.36724555],\n",
              "       [0.672514  , 0.36383304],\n",
              "       [0.6702638 , 0.36581457],\n",
              "       [0.6680766 , 0.36762682],\n",
              "       [0.6723861 , 0.3640269 ],\n",
              "       [0.6706836 , 0.3654147 ],\n",
              "       [0.67043114, 0.36561048],\n",
              "       [0.6816771 , 0.35607758],\n",
              "       [0.6724049 , 0.3638981 ],\n",
              "       [0.6685376 , 0.3672959 ],\n",
              "       [0.6840887 , 0.35398734],\n",
              "       [0.6723481 , 0.3640657 ],\n",
              "       [0.6722555 , 0.3640502 ],\n",
              "       [0.66687906, 0.36858362],\n",
              "       [0.67537636, 0.36140364],\n",
              "       [0.6722646 , 0.3640032 ],\n",
              "       [0.6699644 , 0.36601567]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD3S-7OdhBOz"
      },
      "source": [
        "## Graphical Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F27fvg3WXSHY",
        "outputId": "b4538def-d618-49b7-f11d-fba52b739a79",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spektral\n",
            "  Downloading spektral-1.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from spektral) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from spektral) (5.3.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from spektral) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from spektral) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from spektral) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from spektral) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from spektral) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from spektral) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from spektral) (4.67.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from spektral) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.2.0->spektral) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->spektral) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->spektral) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->spektral) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->spektral) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->spektral) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->spektral) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->spektral) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.2.0->spektral) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.2.0->spektral) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.2.0->spektral) (0.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2.0->spektral) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2.0->spektral) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.2.0->spektral) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.2.0->spektral) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.2.0->spektral) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.2.0->spektral) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.2.0->spektral) (0.1.2)\n",
            "Downloading spektral-1.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spektral\n",
            "Successfully installed spektral-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install spektral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tsalLTAmOXAY"
      },
      "outputs": [],
      "source": [
        "# Convert correlation matrices to adjacency matrices using a threshold\n",
        "import numpy as np\n",
        "\n",
        "def create_adjacency_matrix(correlation_matrix, threshold=0.5):\n",
        "  \"\"\"Creates an adjacency matrix from a correlation matrix using a threshold.\"\"\"\n",
        "  adjacency_matrix = (np.abs(correlation_matrix) > threshold).astype(int)\n",
        "  return adjacency_matrix\n",
        "\n",
        "def create_weighted_adj_matrix(correlation_matrix, threshold=0.5):\n",
        "  \"\"\"Creates an adjacency matrix from a correlation matrix using a threshold.\"\"\"\n",
        "  adjacency_matrix = (np.abs(correlation_matrix) > threshold).astype(int)\n",
        "  masked_matrix = np.where(adjacency_matrix == 1, correlation_matrix, 0)\n",
        "  return masked_matrix\n",
        "\n",
        "# Create adjacency matrices for training and validation data\n",
        "train_adjacency_matrices = [create_adjacency_matrix(cm) for cm in X_train_mri]\n",
        "val_adjacency_matrices = [create_adjacency_matrix(cm) for cm in X_val_mri]\n",
        "full_train_adjacency_matrices = [create_adjacency_matrix(cm) for cm in connectome_matrices]\n",
        "test_adjacency_matrices = [create_adjacency_matrix(cm) for cm in connectome_matrices_test]\n",
        "train_adjacency_matrices = np.array(train_adjacency_matrices)\n",
        "val_adjacency_matrices = np.array(val_adjacency_matrices)\n",
        "full_train_adjacency_matrices = np.array(full_train_adjacency_matrices)\n",
        "test_adjacency_matrices = np.array(test_adjacency_matrices)\n",
        "\n",
        "# Create adjacency matrices for training and validation data\n",
        "train_weighted_adj_matrices = [create_weighted_adj_matrix(cm) for cm in X_train_mri]\n",
        "val_weighted_adj_matrices = [create_weighted_adj_matrix(cm) for cm in X_val_mri]\n",
        "full_train_weighted_adj_matrices = [create_weighted_adj_matrix(cm) for cm in connectome_matrices]\n",
        "test_weighted_adj_matrices = [create_weighted_adj_matrix(cm) for cm in connectome_matrices_test]\n",
        "train_weighted_adj_matrices = np.array(train_weighted_adj_matrices)\n",
        "val_weighted_adj_matrices = np.array(val_weighted_adj_matrices)\n",
        "full_train_weighted_adj_matrices = np.array(full_train_weighted_adj_matrices)\n",
        "test_weighted_adj_matrices = np.array(test_weighted_adj_matrices)\n",
        "\n",
        "# Create feature matrices for training and validation data\n",
        "train_feature_matrices = [np.eye(200,200) for _ in X_train_mri]\n",
        "val_feature_matrices = [np.eye(200,200) for _ in X_val_mri]\n",
        "full_train_feature_matrices = [np.eye(200,200) for _ in connectome_matrices]\n",
        "test_feature_matrices = [np.eye(200,200) for _ in connectome_matrices_test]\n",
        "train_feature_matrices = np.array(train_feature_matrices)\n",
        "val_feature_matrices = np.array(val_feature_matrices)\n",
        "full_train_feature_matrices = np.array(full_train_feature_matrices)\n",
        "test_feature_matrices = np.array(test_feature_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN"
      ],
      "metadata": {
        "id": "hxjW4VRQ0qRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvwrKgijPP0n"
      },
      "outputs": [],
      "source": [
        "# # prompt: build a spektral dataset object from the spektral graph objects that's ready to be used in BatchLoader\n",
        "# # !pip install spektral\n",
        "\n",
        "# import numpy as np\n",
        "# from spektral.data import Dataset, Graph\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# def create_adjacency_matrix(correlation_matrix, threshold=0.1):\n",
        "#   \"\"\"Creates an adjacency matrix from a correlation matrix using a threshold.\"\"\"\n",
        "#   adjacency_matrix = (np.abs(correlation_matrix) > threshold).astype(int)\n",
        "#   return adjacency_matrix\n",
        "\n",
        "# # Create adjacency matrices for training and validation data\n",
        "# train_adjacency_matrices = [create_adjacency_matrix(cm) for cm in X_train_mri]\n",
        "# val_adjacency_matrices = [create_adjacency_matrix(cm) for cm in X_val_mri]\n",
        "\n",
        "# # Create Spektral Graph objects\n",
        "# train_graphs = [Graph(x=np.eye(200,200), a=adj, y=y) for adj, y in zip(train_adjacency_matrices, y_train)]\n",
        "# val_graphs = [Graph(x=np.eye(200,200), a=adj, y=y) for adj, y in zip(val_adjacency_matrices, y_val)]\n",
        "\n",
        "# class MyDataset(Dataset):\n",
        "#     def __init__(self, graph_list, **kwargs):\n",
        "#         self.graph_list = graph_list\n",
        "#         super().__init__(**kwargs)\n",
        "\n",
        "\n",
        "#     def read(self):\n",
        "\n",
        "#         return self.graph_list\n",
        "\n",
        "\n",
        "# # Create the dataset\n",
        "# train_dataset = MyDataset(graph_list = train_graphs)\n",
        "# val_dataset = MyDataset(graph_list = val_graphs)\n",
        "\n",
        "# # Now you can use the dataset with a BatchLoader\n",
        "# from spektral.data.loaders import BatchLoader\n",
        "\n",
        "# train_loader = BatchLoader(train_dataset, batch_size=32)\n",
        "# val_loader = BatchLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# # for batch in train_loader:\n",
        "# #     print(batch)\n",
        "# #     break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BLP7FSQ5fUH4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from spektral.layers import ops\n",
        "from spektral.layers.convolutional.conv import Conv\n",
        "from spektral.utils import gcn_filter\n",
        "\n",
        "\n",
        "class NewGCNConv(Conv):\n",
        "    r\"\"\"\n",
        "    A graph convolutional layer (GCN) from the paper\n",
        "\n",
        "    > [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)<br>\n",
        "    > Thomas N. Kipf and Max Welling\n",
        "\n",
        "    **Mode**: single, disjoint, mixed, batch.\n",
        "\n",
        "    This layer computes:\n",
        "    $$\n",
        "        \\X' = \\hat \\D^{-1/2} \\hat \\A \\hat \\D^{-1/2} \\X \\W + \\b\n",
        "    $$\n",
        "    where \\( \\hat \\A = \\A + \\I \\) is the adjacency matrix with added self-loops\n",
        "    and \\(\\hat\\D\\) is its degree matrix.\n",
        "\n",
        "    **Input**\n",
        "\n",
        "    - Node features of shape `([batch], n_nodes, n_node_features)`;\n",
        "    - Modified Laplacian of shape `([batch], n_nodes, n_nodes)`; can be computed with\n",
        "    `spektral.utils.convolution.gcn_filter`.\n",
        "\n",
        "    **Output**\n",
        "\n",
        "    - Node features with the same shape as the input, but with the last\n",
        "    dimension changed to `channels`.\n",
        "\n",
        "    **Arguments**\n",
        "\n",
        "    - `channels`: number of output channels;\n",
        "    - `activation`: activation function;\n",
        "    - `use_bias`: bool, add a bias vector to the output;\n",
        "    - `kernel_initializer`: initializer for the weights;\n",
        "    - `bias_initializer`: initializer for the bias vector;\n",
        "    - `kernel_regularizer`: regularization applied to the weights;\n",
        "    - `bias_regularizer`: regularization applied to the bias vector;\n",
        "    - `activity_regularizer`: regularization applied to the output;\n",
        "    - `kernel_constraint`: constraint applied to the weights;\n",
        "    - `bias_constraint`: constraint applied to the bias vector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.channels = channels\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[0][-1]\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_dim, self.channels),\n",
        "            initializer=self.kernel_initializer,\n",
        "            name=\"kernel\",\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(self.channels,),\n",
        "                initializer=self.bias_initializer,\n",
        "                name=\"bias\",\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "            )\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        x, a = inputs\n",
        "\n",
        "        output = K.dot(x, self.kernel)\n",
        "        output = ops.modal_dot(a, output)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias)\n",
        "        # if mask is not None:\n",
        "        #     output *= mask[0]\n",
        "        output = self.activation(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        return {\"channels\": self.channels}\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(a):\n",
        "        return gcn_filter(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uobjq12_OZtU"
      },
      "outputs": [],
      "source": [
        "# # prompt: using graphical lasso to get adjacency matrix of each sample in the correlation matrix (X_train_mri), specify the penalty parameter. calculate how many edges in each matrix returned. define a function to get adj matrix. input all the matrices\n",
        "\n",
        "# import numpy as np\n",
        "# from sklearn.covariance import GraphicalLasso\n",
        "\n",
        "# def get_adj_matrix(correlation_matrices, alpha=0.01):\n",
        "#   \"\"\"\n",
        "#   Calculates the adjacency matrix using Graphical Lasso for each correlation matrix.\n",
        "\n",
        "#   Args:\n",
        "#     correlation_matrices: A list of correlation matrices.\n",
        "#     alpha: The penalty parameter for Graphical Lasso.\n",
        "\n",
        "#   Returns:\n",
        "#     A list of adjacency matrices.\n",
        "#   \"\"\"\n",
        "#   adjacency_matrices = []\n",
        "#   for correlation_matrix in correlation_matrices:\n",
        "#     model = GraphicalLasso(alpha=alpha)\n",
        "#     model.fit(correlation_matrix)\n",
        "#     precision_matrix = model.precision_\n",
        "#     adjacency_matrix = (precision_matrix != 0).astype(int)\n",
        "#     adjacency_matrices.append(adjacency_matrix)\n",
        "#     print(np.sum(adjacency_matrix) // 2)\n",
        "#     # print(adjacency_matrix[:5,:5])\n",
        "#   return np.array(adjacency_matrices)\n",
        "\n",
        "\n",
        "# # Assuming X_train_mri contains your correlation matrices\n",
        "# alpha = 0.002\n",
        "# train_adjacency_matrices = get_adj_matrix(X_train_mri, alpha)\n",
        "# val_adjacency_matrices = get_adj_matrix(X_val_mri, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MMnNUlZ-Gw4k",
        "outputId": "b27a0cc7-64de-4b00-c8db-ca7dac9ae48d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gnn_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gnn_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gcn_conv_3 (\u001b[38;5;33mNewGCNConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gcn_conv_4 (\u001b[38;5;33mNewGCNConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gcn_conv_5 (\u001b[38;5;33mNewGCNConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_12     â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_38 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gcn_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGCNConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gcn_conv_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGCNConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gcn_conv_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGCNConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_12     â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gnn_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.5704 - loss: 477452.2500 - val_accuracy: 0.8505 - val_loss: 1919.4066 - learning_rate: 0.1000\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7220 - loss: 771.3827 - val_accuracy: 0.8505 - val_loss: 1.9649 - learning_rate: 0.1000\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6547 - loss: 2.0052 - val_accuracy: 0.8505 - val_loss: 1.0480 - learning_rate: 0.1000\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7006 - loss: 1.1795 - val_accuracy: 0.8505 - val_loss: 1.6183 - learning_rate: 0.1000\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5768 - loss: 5.2850 - val_accuracy: 0.2577 - val_loss: 1.7582 - learning_rate: 0.1000\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6654 - loss: 1.3062 - val_accuracy: 0.2371 - val_loss: 1.6798 - learning_rate: 0.1000\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6099 - loss: 1.2509 - val_accuracy: 0.2062 - val_loss: 1.6106 - learning_rate: 0.1000\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6015 - loss: 1.4730 - val_accuracy: 0.7784 - val_loss: 0.6093 - learning_rate: 0.1000\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6511 - loss: 1.1608 - val_accuracy: 0.1546 - val_loss: 2.9538 - learning_rate: 0.1000\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6011 - loss: 2.4186 - val_accuracy: 0.1495 - val_loss: 12.2253 - learning_rate: 0.1000\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5901 - loss: 7.7082 - val_accuracy: 0.8247 - val_loss: 0.7744 - learning_rate: 0.1000\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7147 - loss: 0.9552 - val_accuracy: 0.6495 - val_loss: 0.6760 - learning_rate: 0.1000\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6853 - loss: 0.7178 - val_accuracy: 0.1546 - val_loss: 2.5651 - learning_rate: 0.1000\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5788 - loss: 2.6308 - val_accuracy: 0.8505 - val_loss: 3.8802 - learning_rate: 0.1000\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6238 - loss: 2.9449 - val_accuracy: 0.8557 - val_loss: 1.4714 - learning_rate: 0.1000\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6743 - loss: 1.5048 - val_accuracy: 0.3402 - val_loss: 1.3517 - learning_rate: 0.1000\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6326 - loss: 0.9691 - val_accuracy: 0.8505 - val_loss: 2.9311 - learning_rate: 0.1000\n",
            "Epoch 18/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6498 - loss: 1.7325\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6492 - loss: 1.6748 - val_accuracy: 0.7938 - val_loss: 0.6270 - learning_rate: 0.1000\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7471 - loss: 0.7043 - val_accuracy: 0.7577 - val_loss: 0.6153 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7628 - loss: 0.6584 - val_accuracy: 0.7629 - val_loss: 0.6034 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7530 - loss: 0.6422 - val_accuracy: 0.6598 - val_loss: 0.6813 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6929 - loss: 0.7265 - val_accuracy: 0.7062 - val_loss: 0.6408 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7073 - loss: 0.6599 - val_accuracy: 0.6649 - val_loss: 0.6788 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7329 - loss: 0.6830 - val_accuracy: 0.7990 - val_loss: 0.5844 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7607 - loss: 0.6410 - val_accuracy: 0.7113 - val_loss: 0.6302 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7057 - loss: 0.6439 - val_accuracy: 0.7680 - val_loss: 0.5842 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7642 - loss: 0.6136 - val_accuracy: 0.7835 - val_loss: 0.5660 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7579 - loss: 0.6539 - val_accuracy: 0.7371 - val_loss: 0.5981 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7051 - loss: 0.6485 - val_accuracy: 0.7629 - val_loss: 0.5799 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7290 - loss: 0.6189 - val_accuracy: 0.8247 - val_loss: 0.5744 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7452 - loss: 0.6709 - val_accuracy: 0.2938 - val_loss: 1.1396 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6509 - loss: 0.7416 - val_accuracy: 0.8144 - val_loss: 0.5548 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7660 - loss: 0.6119 - val_accuracy: 0.6701 - val_loss: 0.6556 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7433 - loss: 0.6126 - val_accuracy: 0.7113 - val_loss: 0.6219 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7572 - loss: 0.5944 - val_accuracy: 0.7938 - val_loss: 0.5548 - learning_rate: 0.0100\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7809 - loss: 0.5694 - val_accuracy: 0.8608 - val_loss: 0.6400 - learning_rate: 0.0100\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7862 - loss: 0.6169 - val_accuracy: 0.6134 - val_loss: 0.6867 - learning_rate: 0.0100\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6956 - loss: 0.6499 - val_accuracy: 0.7268 - val_loss: 0.6116 - learning_rate: 0.0100\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7609 - loss: 0.6206 - val_accuracy: 0.6340 - val_loss: 0.6703 - learning_rate: 0.0100\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7479 - loss: 0.5930 - val_accuracy: 0.7577 - val_loss: 0.5733 - learning_rate: 0.0100\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7246 - loss: 0.6050 - val_accuracy: 0.6443 - val_loss: 0.6586 - learning_rate: 0.0100\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7915 - loss: 0.5949 - val_accuracy: 0.8454 - val_loss: 0.5398 - learning_rate: 0.0100\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7938 - loss: 0.5893 - val_accuracy: 0.8041 - val_loss: 0.5523 - learning_rate: 0.0100\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7804 - loss: 0.5710 - val_accuracy: 0.8041 - val_loss: 0.5412 - learning_rate: 0.0100\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7078 - loss: 0.6453 - val_accuracy: 0.8557 - val_loss: 0.5933 - learning_rate: 0.0100\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7406 - loss: 0.6374 - val_accuracy: 0.7990 - val_loss: 0.5531 - learning_rate: 0.0100\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8209 - loss: 0.5498 - val_accuracy: 0.7629 - val_loss: 0.5726 - learning_rate: 0.0100\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7600 - loss: 0.5866 - val_accuracy: 0.7526 - val_loss: 0.5753 - learning_rate: 0.0100\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7781 - loss: 0.5765 - val_accuracy: 0.8505 - val_loss: 0.5429 - learning_rate: 0.0100\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8032 - loss: 0.6086 - val_accuracy: 0.8557 - val_loss: 0.5440 - learning_rate: 0.0100\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7720 - loss: 0.6331 - val_accuracy: 0.8608 - val_loss: 0.8074 - learning_rate: 0.0100\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7029 - loss: 0.7521 - val_accuracy: 0.8454 - val_loss: 0.5330 - learning_rate: 0.0100\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7841 - loss: 0.5836 - val_accuracy: 0.4227 - val_loss: 0.7676 - learning_rate: 0.0100\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6986 - loss: 0.6303 - val_accuracy: 0.8299 - val_loss: 0.5318 - learning_rate: 0.0100\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7942 - loss: 0.5846 - val_accuracy: 0.8608 - val_loss: 0.5676 - learning_rate: 0.0100\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8032 - loss: 0.5579 - val_accuracy: 0.8454 - val_loss: 0.5302 - learning_rate: 0.0100\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7261 - loss: 0.6620 - val_accuracy: 0.4072 - val_loss: 0.7779 - learning_rate: 0.0100\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7245 - loss: 0.6146 - val_accuracy: 0.7938 - val_loss: 0.5445 - learning_rate: 0.0100\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8106 - loss: 0.5467 - val_accuracy: 0.8557 - val_loss: 0.5467 - learning_rate: 0.0100\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7801 - loss: 0.5841 - val_accuracy: 0.7165 - val_loss: 0.6102 - learning_rate: 0.0100\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7652 - loss: 0.5844 - val_accuracy: 0.7990 - val_loss: 0.5401 - learning_rate: 0.0100\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7739 - loss: 0.5963 - val_accuracy: 0.8351 - val_loss: 0.5355 - learning_rate: 0.0100\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7675 - loss: 0.5843 - val_accuracy: 0.7990 - val_loss: 0.5373 - learning_rate: 0.0100\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7316 - loss: 0.6599 - val_accuracy: 0.8557 - val_loss: 0.5642 - learning_rate: 0.0100\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7692 - loss: 0.5957 - val_accuracy: 0.8041 - val_loss: 0.5369 - learning_rate: 0.0100\n",
            "Epoch 66/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.5743\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8020 - loss: 0.5745 - val_accuracy: 0.5979 - val_loss: 0.6625 - learning_rate: 0.0100\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7395 - loss: 0.5869 - val_accuracy: 0.7680 - val_loss: 0.5731 - learning_rate: 1.0000e-03\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8198 - loss: 0.5512 - val_accuracy: 0.7887 - val_loss: 0.5572 - learning_rate: 1.0000e-03\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7817 - loss: 0.5643 - val_accuracy: 0.7938 - val_loss: 0.5426 - learning_rate: 1.0000e-03\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8091 - loss: 0.5476 - val_accuracy: 0.8041 - val_loss: 0.5372 - learning_rate: 1.0000e-03\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8344 - loss: 0.5615 - val_accuracy: 0.7887 - val_loss: 0.5557 - learning_rate: 1.0000e-03\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8014 - loss: 0.5576 - val_accuracy: 0.8299 - val_loss: 0.5307 - learning_rate: 1.0000e-03\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8236 - loss: 0.5742 - val_accuracy: 0.8041 - val_loss: 0.5385 - learning_rate: 1.0000e-03\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8071 - loss: 0.5553 - val_accuracy: 0.7835 - val_loss: 0.5626 - learning_rate: 1.0000e-03\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7968 - loss: 0.5592 - val_accuracy: 0.8196 - val_loss: 0.5333 - learning_rate: 1.0000e-03\n",
            "Epoch 76/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8439 - loss: 0.5180\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8381 - loss: 0.5250 - val_accuracy: 0.8351 - val_loss: 0.5308 - learning_rate: 1.0000e-03\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8643 - loss: 0.5454 - val_accuracy: 0.8041 - val_loss: 0.5369 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8232 - loss: 0.5425 - val_accuracy: 0.8041 - val_loss: 0.5377 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7956 - loss: 0.5570 - val_accuracy: 0.8093 - val_loss: 0.5346 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8082 - loss: 0.5510 - val_accuracy: 0.8093 - val_loss: 0.5368 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8131 - loss: 0.5582 - val_accuracy: 0.8093 - val_loss: 0.5355 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7985 - loss: 0.5650 - val_accuracy: 0.8041 - val_loss: 0.5378 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8261 - loss: 0.5470 - val_accuracy: 0.8093 - val_loss: 0.5361 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8236 - loss: 0.5462 - val_accuracy: 0.8093 - val_loss: 0.5347 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8209 - loss: 0.5512 - val_accuracy: 0.8041 - val_loss: 0.5385 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8097 - loss: 0.5466\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8134 - loss: 0.5483 - val_accuracy: 0.8093 - val_loss: 0.5367 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8083 - loss: 0.5599 - val_accuracy: 0.8041 - val_loss: 0.5370 - learning_rate: 1.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8212 - loss: 0.5485 - val_accuracy: 0.8041 - val_loss: 0.5372 - learning_rate: 1.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8013 - loss: 0.5671 - val_accuracy: 0.8041 - val_loss: 0.5372 - learning_rate: 1.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8191 - loss: 0.5529 - val_accuracy: 0.8041 - val_loss: 0.5372 - learning_rate: 1.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8122 - loss: 0.5506 - val_accuracy: 0.8041 - val_loss: 0.5369 - learning_rate: 1.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8312 - loss: 0.5443 - val_accuracy: 0.8093 - val_loss: 0.5365 - learning_rate: 1.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8136 - loss: 0.5523 - val_accuracy: 0.8093 - val_loss: 0.5364 - learning_rate: 1.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8211 - loss: 0.5493 - val_accuracy: 0.8093 - val_loss: 0.5367 - learning_rate: 1.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8083 - loss: 0.5536 - val_accuracy: 0.8093 - val_loss: 0.5363 - learning_rate: 1.0000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8420 - loss: 0.5598\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8370 - loss: 0.5578 - val_accuracy: 0.8093 - val_loss: 0.5365 - learning_rate: 1.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8035 - loss: 0.5567 - val_accuracy: 0.8093 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8039 - loss: 0.5636 - val_accuracy: 0.8093 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8090 - loss: 0.5654 - val_accuracy: 0.8093 - val_loss: 0.5366 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8089 - loss: 0.5556 - val_accuracy: 0.8093 - val_loss: 0.5366 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f3ae4982250>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.data import Graph\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class GNN(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Gconv1 = NewGCNConv(92, activation='relu')\n",
        "    self.Gconv2 = NewGCNConv(92, activation='relu')\n",
        "    self.Gconv3 = NewGCNConv(92, activation='relu')\n",
        "    self.normalization = BatchNormalization()\n",
        "    self.dropout = Dropout(0.65)\n",
        "    self.pool = keras.layers.GlobalAveragePooling1D()\n",
        "    self.dense1 = Dense(64, activation='relu')\n",
        "    self.dense2 = Dense(32, activation='relu')\n",
        "    self.dense3 = Dense(2, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x, adj, meta = inputs\n",
        "    # x, adj = graph.x, graph.a\n",
        "    out = self.Gconv1([x, adj])\n",
        "    out = self.dropout(out)\n",
        "    out = self.normalization(out)\n",
        "    out = self.Gconv2([out, adj])\n",
        "    out = self.dropout(out)\n",
        "    out = self.normalization(out)\n",
        "    out = self.Gconv3([out, adj])\n",
        "    # out = self.dropout(out)\n",
        "    # out = self.normalization(out)\n",
        "    out = self.pool(out)\n",
        "    # out = self.dense1(out)\n",
        "\n",
        "    # out = self.dropout(out)\n",
        "    out = concatenate([out, meta])\n",
        "\n",
        "    out = self.dense1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.dense3(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = GNN()\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1) #, weight_decay=0.0005)\n",
        "f1_scorer = tf.keras.metrics.F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "## Sample Weights\n",
        "weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "# print(weights.shape)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit([train_feature_matrices, train_adjacency_matrices, X_train_meta], y_train,\n",
        "          epochs=100, batch_size=32, validation_split=0.2,\n",
        "          # sample_weight=weights,\n",
        "          callbacks=[reduce_lr]) #reduce_lr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0xtKkmjjAtB",
        "outputId": "baec924c-882a-4020-b1d3-b4edf62bb568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7368 - loss: 0.5887\n",
            "Loss: 0.5822163820266724\n",
            "Accuracy: 0.7242798209190369\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "Accuracy for column 0: 0.7695473251028807\n",
            "Accuracy for column 1: 0.6419753086419753\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.44264066767686444, 0.6865169666499435\n",
            "Jiaqi's Weighted F1 Score: (0.627565886397119, 0.8390243902439024, 0.4161073825503356)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model\n",
        "# loss, accuracy, f1_scores = model.evaluate([val_feature_matrices, val_weighted_adj_matrices, X_val_meta], y_val)\n",
        "loss, accuracy = model.evaluate([val_feature_matrices, val_weighted_adj_matrices, X_val_meta], y_val)\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"F1 Score:\", f1_scores)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict([val_feature_matrices, val_weighted_adj_matrices, X_val_meta])\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.int16)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.int16)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n",
        "f1_3 = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "print(f\"Jiaqi's Weighted F1 Score: {f1_3}\")\n",
        "\n",
        "### use eye feature\n",
        "# 8/8 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 43ms/step - accuracy: 0.8236 - loss: 0.5229\n",
        "# Loss: 0.5226803421974182\n",
        "# Accuracy: 0.798353910446167\n",
        "# WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7da7d2455760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "# 8/8 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 48ms/step\n",
        "# Accuracy for column 0: 0.8065843621399177\n",
        "# Accuracy for column 1: 0.7119341563786008\n",
        "# (243,)\n",
        "# (243,)\n",
        "# (243,)\n",
        "# Weighted F1 Score: 0.46930952978581, 0.7067192040009458\n",
        "# Jiaqi's Weighted F1 Score: (0.6299778761061947, 0.8849557522123894, 0.375)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azBKGriRgY9A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAT"
      ],
      "metadata": {
        "id": "kmKPi3TgkjEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import constraints, initializers, regularizers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from spektral.layers import ops\n",
        "from spektral.layers.convolutional.conv import Conv\n",
        "from spektral.layers.ops import modes\n",
        "\n",
        "\n",
        "class NewGATConv(Conv):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        attn_heads=1,\n",
        "        concat_heads=True,\n",
        "        dropout_rate=0.5,\n",
        "        return_attn_coef=False,\n",
        "        add_self_loops=True,\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        attn_kernel_initializer=\"glorot_uniform\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        attn_kernel_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        attn_kernel_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.channels = channels\n",
        "        self.attn_heads = attn_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.return_attn_coef = return_attn_coef\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.attn_kernel_initializer = initializers.get(attn_kernel_initializer)\n",
        "        self.attn_kernel_regularizer = regularizers.get(attn_kernel_regularizer)\n",
        "        self.attn_kernel_constraint = constraints.get(attn_kernel_constraint)\n",
        "\n",
        "        if concat_heads:\n",
        "            self.output_dim = self.channels * self.attn_heads\n",
        "        else:\n",
        "            self.output_dim = self.channels\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[0][-1]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=[input_dim, self.attn_heads, self.channels],\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        self.attn_kernel_self = self.add_weight(\n",
        "            name=\"attn_kernel_self\",\n",
        "            shape=[self.channels, self.attn_heads, 1],\n",
        "            initializer=self.attn_kernel_initializer,\n",
        "            regularizer=self.attn_kernel_regularizer,\n",
        "            constraint=self.attn_kernel_constraint,\n",
        "        )\n",
        "        self.attn_kernel_neighs = self.add_weight(\n",
        "            name=\"attn_kernel_neigh\",\n",
        "            shape=[self.channels, self.attn_heads, 1],\n",
        "            initializer=self.attn_kernel_initializer,\n",
        "            regularizer=self.attn_kernel_regularizer,\n",
        "            constraint=self.attn_kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=[self.output_dim],\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                name=\"bias\",\n",
        "            )\n",
        "\n",
        "        self.dropout = Dropout(self.dropout_rate, dtype=self.dtype)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        x, a = inputs\n",
        "\n",
        "        mode = ops.autodetect_mode(x, a)\n",
        "        if mode == modes.SINGLE and K.is_sparse(a):\n",
        "            output, attn_coef = self._call_single(x, a)\n",
        "        else:\n",
        "            if K.is_sparse(a):\n",
        "                a = tf.sparse.to_dense(a)\n",
        "            output, attn_coef = self._call_dense(x, a)\n",
        "\n",
        "        if self.concat_heads:\n",
        "            shape = tf.concat(\n",
        "                (tf.shape(output)[:-2], [self.attn_heads * self.channels]), axis=0\n",
        "            )\n",
        "            output = tf.reshape(output, shape)\n",
        "        else:\n",
        "            output = tf.reduce_mean(output, axis=-2)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output += self.bias\n",
        "        # if mask is not None:\n",
        "        #     output *= mask[0]\n",
        "        output = self.activation(output)\n",
        "\n",
        "        if self.return_attn_coef:\n",
        "            return output, attn_coef\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def _call_single(self, x, a):\n",
        "        # Reshape kernels for efficient message-passing\n",
        "        kernel = tf.reshape(self.kernel, (-1, self.attn_heads * self.channels))\n",
        "        attn_kernel_self = ops.transpose(self.attn_kernel_self, (2, 1, 0))\n",
        "        attn_kernel_neighs = ops.transpose(self.attn_kernel_neighs, (2, 1, 0))\n",
        "\n",
        "        # Prepare message-passing\n",
        "        indices = a.indices\n",
        "        N = tf.shape(x, out_type=indices.dtype)[-2]\n",
        "        if self.add_self_loops:\n",
        "            indices = ops.add_self_loops_indices(indices, N)\n",
        "        targets, sources = indices[:, 1], indices[:, 0]\n",
        "\n",
        "        # Update node features\n",
        "        x = K.dot(x, kernel)\n",
        "        x = tf.reshape(x, (-1, self.attn_heads, self.channels))\n",
        "\n",
        "        # Compute attention\n",
        "        attn_for_self = tf.reduce_sum(x * attn_kernel_self, -1)\n",
        "        attn_for_self = tf.gather(attn_for_self, targets)\n",
        "        attn_for_neighs = tf.reduce_sum(x * attn_kernel_neighs, -1)\n",
        "        attn_for_neighs = tf.gather(attn_for_neighs, sources)\n",
        "\n",
        "        attn_coef = attn_for_self + attn_for_neighs\n",
        "        attn_coef = tf.nn.leaky_relu(attn_coef, alpha=0.2)\n",
        "        attn_coef = ops.unsorted_segment_softmax(attn_coef, targets, N)\n",
        "        attn_coef = self.dropout(attn_coef)\n",
        "        attn_coef = attn_coef[..., None]\n",
        "\n",
        "        # Update representation\n",
        "        output = attn_coef * tf.gather(x, sources)\n",
        "        output = tf.math.unsorted_segment_sum(output, targets, N)\n",
        "\n",
        "        return output, attn_coef\n",
        "\n",
        "    def _call_dense(self, x, a):\n",
        "        shape = tf.shape(a)[:-1]\n",
        "        if self.add_self_loops:\n",
        "            a = tf.linalg.set_diag(a, tf.ones(shape, a.dtype))\n",
        "        x = tf.einsum(\"...NI , IHO -> ...NHO\", x, self.kernel)\n",
        "        attn_for_self = tf.einsum(\"...NHI , IHO -> ...NHO\", x, self.attn_kernel_self)\n",
        "        attn_for_neighs = tf.einsum(\n",
        "            \"...NHI , IHO -> ...NHO\", x, self.attn_kernel_neighs\n",
        "        )\n",
        "        attn_for_neighs = tf.einsum(\"...ABC -> ...CBA\", attn_for_neighs)\n",
        "\n",
        "        attn_coef = attn_for_self + attn_for_neighs\n",
        "        attn_coef = tf.nn.leaky_relu(attn_coef, alpha=0.2)\n",
        "\n",
        "        mask = tf.where(a == 0.0, -10e9, 0.0)\n",
        "        mask = tf.cast(mask, dtype=attn_coef.dtype)\n",
        "        attn_coef += mask[..., None, :]\n",
        "        attn_coef = tf.nn.softmax(attn_coef, axis=-1)\n",
        "        attn_coef_drop = self.dropout(attn_coef)\n",
        "\n",
        "        output = tf.einsum(\"...NHM , ...MHI -> ...NHI\", attn_coef_drop, x)\n",
        "\n",
        "        return output, attn_coef\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"attn_heads\": self.attn_heads,\n",
        "            \"concat_heads\": self.concat_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"return_attn_coef\": self.return_attn_coef,\n",
        "            \"attn_kernel_initializer\": initializers.serialize(\n",
        "                self.attn_kernel_initializer\n",
        "            ),\n",
        "            \"attn_kernel_regularizer\": regularizers.serialize(\n",
        "                self.attn_kernel_regularizer\n",
        "            ),\n",
        "            \"attn_kernel_constraint\": constraints.serialize(\n",
        "                self.attn_kernel_constraint\n",
        "            ),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "nGG6_sE-oAcq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a GAT model class similar to GNN model and train\n",
        "\n",
        "import keras\n",
        "from spektral.layers import GATConv\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import F1Score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class GAT(Model):\n",
        "    def __init__(self, n_hidden, n_heads, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.gat1 = NewGATConv(n_hidden, attn_heads=n_heads, concat_heads=True, activation=\"relu\") #, kernel_regularizer=l2(0.01))\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.gat2 = NewGATConv(n_hidden, attn_heads=n_heads, concat_heads=True, activation=\"relu\") #, kernel_regularizer=l2(0.01))\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.gat3 = NewGATConv(n_hidden, attn_heads=1, concat_heads=False, activation=\"relu\") #, kernel_regularizer=l2(0.01))\n",
        "        self.dropout3 = Dropout(dropout_rate)\n",
        "        self.normalization = BatchNormalization()\n",
        "        self.pool = keras.layers.GlobalAveragePooling1D()\n",
        "        self.dense1 = Dense(64, activation='relu')\n",
        "        self.dense2 = Dense(32, activation='relu')\n",
        "        self.dense3 = Dense(2, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, adj, meta = inputs\n",
        "        out = self.gat1([x, adj])\n",
        "        out = self.dropout1(out)\n",
        "        # out = self.normalization(out)\n",
        "        out = self.gat2([out, adj])\n",
        "        out = self.dropout2(out)\n",
        "        # out = self.normalization(out)\n",
        "        out = self.gat3([out, adj])\n",
        "        out = self.dropout3(out)\n",
        "        # out = self.normalization(out)\n",
        "        out = self.pool(out)\n",
        "        out = concatenate([out, meta])\n",
        "        out = self.dense1(out)\n",
        "        out = self.dropout1(out)\n",
        "        out = self.dense3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "n_hidden = 64  # Number of hidden units\n",
        "n_heads = 1  # Number of attention heads\n",
        "dropout_rate = 0.5\n",
        "\n",
        "model = GAT(n_hidden, n_heads, dropout_rate)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=1e-2)\n",
        "f1_scorer = F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "weights = np.where((df_train_y.iloc[:, 0] == 1) & (df_train_y.iloc[:, 1] == 1), 2, 1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit([train_feature_matrices, train_adjacency_matrices, X_train_meta], y_train,\n",
        "# model.fit([full_train_feature_matrices, full_train_adjacency_matrices, df_train_meta_imputed], df_train_y.values,\n",
        "          epochs=100, batch_size=32, validation_split=0.2,\n",
        "          # sample_weight=weights,\n",
        "          callbacks=[reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n3LFaOsakjZt",
        "outputId": "caa1d3d0-108a-4c21-822c-903c1c5afdf9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gat_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gat_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gat_conv_30 (\u001b[38;5;33mNewGATConv\u001b[0m)    â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_31 (\u001b[38;5;33mNewGATConv\u001b[0m)    â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_32 (\u001b[38;5;33mNewGATConv\u001b[0m)    â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_10     â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_32 (\u001b[38;5;33mDense\u001b[0m)                â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gat_conv_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)    â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)    â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)    â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_10     â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - accuracy: 0.7586 - loss: 0.6510 - val_accuracy: 0.8763 - val_loss: 0.5887 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8089 - loss: 0.5909 - val_accuracy: 0.8247 - val_loss: 0.5512 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8165 - loss: 0.5646 - val_accuracy: 0.8608 - val_loss: 0.5186 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8187 - loss: 0.5519 - val_accuracy: 0.8557 - val_loss: 0.5137 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8183 - loss: 0.5449 - val_accuracy: 0.8041 - val_loss: 0.5233 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7990 - loss: 0.5330 - val_accuracy: 0.8351 - val_loss: 0.4966 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8114 - loss: 0.5290 - val_accuracy: 0.8402 - val_loss: 0.4968 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8081 - loss: 0.5467 - val_accuracy: 0.8351 - val_loss: 0.5414 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8199 - loss: 0.5467 - val_accuracy: 0.8454 - val_loss: 0.5061 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8113 - loss: 0.5363 - val_accuracy: 0.7990 - val_loss: 0.5037 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8160 - loss: 0.5341 - val_accuracy: 0.8402 - val_loss: 0.4987 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8054 - loss: 0.5305 - val_accuracy: 0.8351 - val_loss: 0.4910 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8265 - loss: 0.5222 - val_accuracy: 0.8351 - val_loss: 0.5047 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8074 - loss: 0.5461 - val_accuracy: 0.8454 - val_loss: 0.5058 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8140 - loss: 0.5234 - val_accuracy: 0.8144 - val_loss: 0.5256 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8320 - loss: 0.5139 - val_accuracy: 0.7938 - val_loss: 0.5186 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8003 - loss: 0.5336 - val_accuracy: 0.8454 - val_loss: 0.4865 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7992 - loss: 0.5172 - val_accuracy: 0.7990 - val_loss: 0.5056 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7557 - loss: 0.5387 - val_accuracy: 0.7990 - val_loss: 0.5239 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8178 - loss: 0.5047 - val_accuracy: 0.8454 - val_loss: 0.4864 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8052 - loss: 0.5198 - val_accuracy: 0.8351 - val_loss: 0.5305 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8066 - loss: 0.5269 - val_accuracy: 0.8557 - val_loss: 0.5116 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8433 - loss: 0.5365 - val_accuracy: 0.8196 - val_loss: 0.4939 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7827 - loss: 0.5139 - val_accuracy: 0.8299 - val_loss: 0.4871 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8198 - loss: 0.5100 - val_accuracy: 0.8351 - val_loss: 0.4983 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8296 - loss: 0.4992 - val_accuracy: 0.8454 - val_loss: 0.4933 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8246 - loss: 0.5089 - val_accuracy: 0.8351 - val_loss: 0.4966 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8265 - loss: 0.5053 - val_accuracy: 0.8454 - val_loss: 0.4970 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8260 - loss: 0.4909 - val_accuracy: 0.8351 - val_loss: 0.4994 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8136 - loss: 0.4944\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8142 - loss: 0.4955 - val_accuracy: 0.7990 - val_loss: 0.5128 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7777 - loss: 0.5007 - val_accuracy: 0.8351 - val_loss: 0.4957 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7914 - loss: 0.5024 - val_accuracy: 0.8402 - val_loss: 0.4981 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8323 - loss: 0.4702 - val_accuracy: 0.8351 - val_loss: 0.4979 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8138 - loss: 0.4710 - val_accuracy: 0.8299 - val_loss: 0.5005 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8053 - loss: 0.4894 - val_accuracy: 0.8351 - val_loss: 0.4984 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8222 - loss: 0.4788 - val_accuracy: 0.8402 - val_loss: 0.4985 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8175 - loss: 0.4772 - val_accuracy: 0.8351 - val_loss: 0.4984 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8244 - loss: 0.4947 - val_accuracy: 0.8402 - val_loss: 0.4977 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8287 - loss: 0.5004 - val_accuracy: 0.8351 - val_loss: 0.4975 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8217 - loss: 0.5043\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8211 - loss: 0.5016 - val_accuracy: 0.8402 - val_loss: 0.4989 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8024 - loss: 0.4906 - val_accuracy: 0.8402 - val_loss: 0.4983 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8282 - loss: 0.4563 - val_accuracy: 0.8402 - val_loss: 0.4990 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8156 - loss: 0.4851 - val_accuracy: 0.8402 - val_loss: 0.4992 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8112 - loss: 0.5003 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8297 - loss: 0.4894 - val_accuracy: 0.8351 - val_loss: 0.4999 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8150 - loss: 0.4755 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8163 - loss: 0.4879 - val_accuracy: 0.8351 - val_loss: 0.4996 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8235 - loss: 0.4872 - val_accuracy: 0.8351 - val_loss: 0.4998 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 0.4796 - val_accuracy: 0.8351 - val_loss: 0.4997 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8338 - loss: 0.4692\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8310 - loss: 0.4725 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8194 - loss: 0.4915 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7977 - loss: 0.4971 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8288 - loss: 0.4638 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8177 - loss: 0.4865 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8228 - loss: 0.4860 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8108 - loss: 0.4968 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8321 - loss: 0.4727 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8130 - loss: 0.4842 - val_accuracy: 0.8351 - val_loss: 0.4992 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8068 - loss: 0.4814 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8217 - loss: 0.5066\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8211 - loss: 0.5027 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8468 - loss: 0.4851 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8326 - loss: 0.4752 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8518 - loss: 0.4638 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8341 - loss: 0.4733 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8282 - loss: 0.4992 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8025 - loss: 0.4914 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8385 - loss: 0.4685 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8278 - loss: 0.4837 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8294 - loss: 0.4772 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8286 - loss: 0.4646 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8052 - loss: 0.4855 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8001 - loss: 0.4991 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8317 - loss: 0.4770 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8376 - loss: 0.4690 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8394 - loss: 0.4757 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8157 - loss: 0.4735 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8158 - loss: 0.5031 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8111 - loss: 0.4822 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8086 - loss: 0.5017 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8287 - loss: 0.4950 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8234 - loss: 0.4746 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8265 - loss: 0.4779 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8243 - loss: 0.4863 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8416 - loss: 0.4806 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7938 - loss: 0.4946 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8337 - loss: 0.4779 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8081 - loss: 0.4857 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8070 - loss: 0.4984 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8078 - loss: 0.4851 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8348 - loss: 0.4804 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8041 - loss: 0.4718 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8097 - loss: 0.4818 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8176 - loss: 0.4711 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7915 - loss: 0.4888 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8032 - loss: 0.4899 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8167 - loss: 0.4819 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8314 - loss: 0.4833 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8184 - loss: 0.4907 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8374 - loss: 0.4712 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8190 - loss: 0.4942 - val_accuracy: 0.8351 - val_loss: 0.4993 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f3ae391f590>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([val_feature_matrices, val_adjacency_matrices, X_val_meta], y_val)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"F1 Score:\", f1_scores)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict([val_feature_matrices, val_adjacency_matrices, X_val_meta])\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.int16)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.int16)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n",
        "f1_3 = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "print(f\"Jiaqi's Weighted F1 Score: {f1_3}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7RKHa1Vkjiy",
        "outputId": "43c4c0ca-3357-4462-f68d-94ca0dc93f4e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8073 - loss: 0.5296\n",
            "Loss: 0.5252934694290161\n",
            "Accuracy: 0.790123462677002\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step\n",
            "Accuracy for column 0: 0.8148148148148148\n",
            "Accuracy for column 1: 0.6790123456790124\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.441149006311888, 0.6998624861425276\n",
            "Jiaqi's Weighted F1 Score: (0.6232808889866872, 0.8859060402684564, 0.36065573770491804)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "odPx36vkkjoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIN"
      ],
      "metadata": {
        "id": "Drizrw76p3yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.layers import Input, Dense, Dropout, concatenate, BatchNormalization\n",
        "# from tensorflow.keras.models import Model\n",
        "# from spektral.layers import GCNConv\n",
        "# from spektral.data import Graph\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# from spektral.layers import GINConv\n",
        "# from scipy.spatial.distance import squareform\n",
        "# import scipy.sparse as sp\n",
        "\n",
        "# def connectivity_vector_to_graph(vector, n=200):\n",
        "#     \"\"\"\n",
        "#     Converts a connectivity vector (flattened upper-triangular part of a 200x200 matrix)\n",
        "#     into a graph representation:\n",
        "#       - X: Node feature matrix (all ones, shape: [n, 1])\n",
        "#       - A: Adjacency matrix (dense, shape: [n, n])\n",
        "#     \"\"\"\n",
        "#     A = squareform(vector)\n",
        "#     np.fill_diagonal(A, 0)\n",
        "#     X = np.ones((n, 1))\n",
        "#     A = A.astype(np.float32)\n",
        "#     return X, A\n",
        "\n",
        "# def read(connectivity_data):\n",
        "#     outputX = []\n",
        "#     outputA = []\n",
        "#     n_samples = connectivity_data.shape[0]\n",
        "#     for i in range(n_samples):\n",
        "#         X, A_dense = connectivity_vector_to_graph(connectivity_data[i])\n",
        "#         A_sparse = sp.csr_matrix(A_dense)\n",
        "#         outputX.append(X)\n",
        "#         outputA.append(A_sparse)\n",
        "\n",
        "#     # outputX = np.stack(outputX)\n",
        "\n",
        "#     return outputX, outputA\n",
        "\n",
        "# X_train, A_train = read(X_train_mri_flat)\n",
        "# X_val, A_val = read(X_val_mri_flat)\n",
        "# print(X_train[0].shape)\n",
        "# print(A_train[0].shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZLxJRy3JjNZ",
        "outputId": "fcce9272-48bd-4184-ce8c-482998da0973"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1)\n",
            "(200, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spektral.data import Graph, Dataset, DisjointLoader, BatchLoader\n",
        "from scipy.spatial.distance import squareform\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def connectivity_vector_to_graph(vector, n=200):\n",
        "    \"\"\"\n",
        "    Converts a connectivity vector (flattened upper-triangular part of a 200x200 matrix)\n",
        "    into a graph representation:\n",
        "      - X: Node feature matrix (all ones, shape: [n, 1])\n",
        "      - A: Adjacency matrix (dense, shape: [n, n])\n",
        "    \"\"\"\n",
        "    A = squareform(vector)\n",
        "    np.fill_diagonal(A, 0)\n",
        "    # X = np.ones((n, 1))\n",
        "    X = np.eye(n,n)\n",
        "    A = create_adjacency_matrix(A, threshold=0.5)\n",
        "    A = A.astype(np.float32)\n",
        "    return X, A\n",
        "\n",
        "class FMRI_Dataset(Dataset):\n",
        "    def __init__(self, connectivity_data, meta_data, targets, **kwargs):\n",
        "        \"\"\"\n",
        "        connectivity_data: NumPy array of shape (n_samples, 19900)\n",
        "        targets: NumPy array of shape (n_samples, 2) with columns [ADHD_Outcome, Sex_F]\n",
        "        \"\"\"\n",
        "        self.connectivity_data = connectivity_data\n",
        "        self.meta_data = meta_data\n",
        "        self.targets = targets\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def read(self):\n",
        "        output = []\n",
        "        n_samples = self.connectivity_data.shape[0]\n",
        "        for i in range(n_samples):\n",
        "            X, A_dense = connectivity_vector_to_graph(self.connectivity_data[i])\n",
        "            # Convert dense adjacency to a SciPy CSR sparse matrix (Spektral accepts this)\n",
        "            A_sparse = sp.csr_matrix(A_dense)\n",
        "            y = self.targets[i]\n",
        "            graph_obj = Graph(x=X, a=A_sparse, y=y)\n",
        "            graph_obj.metadata = self.meta_data[i]\n",
        "            # print(graph_obj.metadata)\n",
        "            output.append(graph_obj)\n",
        "        return output\n",
        "\n",
        "# Create the dataset:\n",
        "dataset = FMRI_Dataset(X_train_mri_flat, X_train_meta, y_train)\n",
        "val_dataset = FMRI_Dataset(X_val_mri_flat, X_val_meta, y_val)\n",
        "\n",
        "n_samples = len(dataset)\n",
        "train_idx, val_idx = train_test_split(np.arange(n_samples), test_size=0.2, random_state=42)\n",
        "dataset_train = dataset[train_idx]\n",
        "dataset_val = dataset[val_idx]\n",
        "\n",
        "# Create DisjointLoaders:\n",
        "loader_train = DisjointLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "loader_val = DisjointLoader(dataset_val, batch_size=32, shuffle=True)\n",
        "\n",
        "validation_loader = DisjointLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "36m_H0KkSywJ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from spektral.layers import ops\n",
        "from spektral.layers.convolutional.message_passing import MessagePassing\n",
        "\n",
        "\n",
        "class NewGINConv(MessagePassing):\n",
        "    r\"\"\"\n",
        "    A Graph Isomorphism Network (GIN) from the paper\n",
        "\n",
        "    > [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826)<br>\n",
        "    > Keyulu Xu et al.\n",
        "\n",
        "    **Mode**: single, disjoint, mixed.\n",
        "\n",
        "    **This layer expects a sparse adjacency matrix.**\n",
        "\n",
        "    This layer computes for each node \\(i\\):\n",
        "    $$\n",
        "        \\x_i' = \\textrm{MLP}\\big( (1 + \\epsilon) \\cdot \\x_i + \\sum\\limits_{j\n",
        "        \\in \\mathcal{N}(i)} \\x_j \\big)\n",
        "    $$\n",
        "    where \\(\\textrm{MLP}\\) is a multi-layer perceptron.\n",
        "\n",
        "    **Input**\n",
        "\n",
        "    - Node features of shape `(n_nodes, n_node_features)`;\n",
        "    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n",
        "\n",
        "    **Output**\n",
        "\n",
        "    - Node features with the same shape of the input, but the last dimension\n",
        "    changed to `channels`.\n",
        "\n",
        "    **Arguments**\n",
        "\n",
        "    - `channels`: integer, number of output channels;\n",
        "    - `epsilon`: unnamed parameter, see the original paper and the equation\n",
        "    above.\n",
        "    By setting `epsilon=None`, the parameter will be learned (default behaviour).\n",
        "    If given as a value, the parameter will stay fixed.\n",
        "    - `mlp_hidden`: list of integers, number of hidden units for each hidden\n",
        "    layer in the MLP (if None, the MLP has only the output layer);\n",
        "    - `mlp_activation`: activation for the MLP layers;\n",
        "    - `mlp_batchnorm`: apply batch normalization after every hidden layer of the MLP;\n",
        "    - `activation`: activation function;\n",
        "    - `use_bias`: bool, add a bias vector to the output;\n",
        "    - `kernel_initializer`: initializer for the weights;\n",
        "    - `bias_initializer`: initializer for the bias vector;\n",
        "    - `kernel_regularizer`: regularization applied to the weights;\n",
        "    - `bias_regularizer`: regularization applied to the bias vector;\n",
        "    - `activity_regularizer`: regularization applied to the output;\n",
        "    - `kernel_constraint`: constraint applied to the weights;\n",
        "    - `bias_constraint`: constraint applied to the bias vector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        epsilon=None,\n",
        "        mlp_hidden=None,\n",
        "        mlp_activation=\"relu\",\n",
        "        mlp_batchnorm=True,\n",
        "        aggregate=\"sum\",\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            aggregate=aggregate,\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.channels = channels\n",
        "        self.epsilon = epsilon\n",
        "        self.mlp_hidden = mlp_hidden if mlp_hidden else []\n",
        "        self.mlp_activation = activations.get(mlp_activation)\n",
        "        self.mlp_batchnorm = mlp_batchnorm\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        layer_kwargs = dict(\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "            kernel_regularizer=self.kernel_regularizer,\n",
        "            bias_regularizer=self.bias_regularizer,\n",
        "            kernel_constraint=self.kernel_constraint,\n",
        "            bias_constraint=self.bias_constraint,\n",
        "        )\n",
        "\n",
        "        self.mlp = Sequential()\n",
        "        for channels in self.mlp_hidden:\n",
        "            self.mlp.add(Dense(channels, self.mlp_activation, **layer_kwargs))\n",
        "            if self.mlp_batchnorm:\n",
        "                self.mlp.add(BatchNormalization())\n",
        "        self.mlp.add(\n",
        "            Dense(\n",
        "                self.channels, self.activation, use_bias=self.use_bias, **layer_kwargs\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if self.epsilon is None:\n",
        "            self.eps = self.add_weight(shape=(1,), initializer=\"zeros\", name=\"eps\")\n",
        "        else:\n",
        "            # If epsilon is given, keep it constant\n",
        "            self.eps = tf.cast(self.epsilon, self.dtype)\n",
        "        # self.one = tf.cast(1, self.dtype)\n",
        "        self.one = tf.constant(1, self.dtype)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x, a, _ = self.get_inputs(inputs)\n",
        "        self.one = tf.constant(1, self.dtype)\n",
        "        output = self.mlp((self.one + self.eps) * x + self.propagate(x, a))\n",
        "\n",
        "        return output\n",
        "\n",
        "    @property\n",
        "    def config(self):\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"epsilon\": self.epsilon,\n",
        "            \"mlp_hidden\": self.mlp_hidden,\n",
        "            \"mlp_activation\": self.mlp_activation,\n",
        "            \"mlp_batchnorm\": self.mlp_batchnorm,\n",
        "        }\n",
        "\n",
        "\n",
        "class NewGINConvBatch(NewGINConv):\n",
        "    r\"\"\"\n",
        "    A batch-mode version of GINConv.\n",
        "\n",
        "    **Mode**: batch.\n",
        "\n",
        "    **This layer expects a dense adjacency matrix.**\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x, a = inputs\n",
        "        self.one = tf.constant(1, self.dtype)\n",
        "        output = self.mlp((self.one + self.eps) * x + ops.modal_dot(a, x))\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "xKKzO7jWj8tt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "from spektral.data.utils import to_disjoint\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from spektral.layers import GINConv, GINConvBatch, GlobalAvgPool, GlobalMaxPool\n",
        "# from spektral.utils import graph_readout\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import F1Score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class GIN(tf.keras.Model):\n",
        "    def __init__(self, num_nodes, f1, f2, readout='meanmax', extra_fc=True):\n",
        "        super().__init__()\n",
        "        self.readout = readout\n",
        "        self.conv1 = NewGINConv(f1, mlp_hidden=[f1], activation=\"relu\", mlp_batchnorm=True)\n",
        "        self.conv2 = NewGINConv(f2, mlp_hidden=[f2], activation=\"relu\", mlp_batchnorm=True)\n",
        "        self.avgpool = GlobalAvgPool()\n",
        "        self.maxpool = GlobalMaxPool()\n",
        "        self.dropout = Dropout(0.5)\n",
        "\n",
        "        last_dim = 2 if readout == 'meanmax' else 1\n",
        "        if extra_fc:\n",
        "            self.last = Sequential([Dense(f2 * last_dim * 2), ReLU(),\n",
        "                                   Dense(2)])\n",
        "        else:\n",
        "            self.last = Dense(2)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x, edge_index, batch = inputs\n",
        "        x, adj, _ = inputs\n",
        "        # adj = tf.sparse.to_dense(adj)\n",
        "        # print(x.shape)\n",
        "        # print(adj.shape)\n",
        "        x = self.conv1([x, adj])\n",
        "        x = self.conv2([x, adj])\n",
        "        # x = graph_readout(x, batch, self.readout)\n",
        "        if self.readout == 'meanmax':\n",
        "            x = tf.concat([self.avgpool(x), self.maxpool(x)], axis=1)\n",
        "        else:\n",
        "            x = self.avgpool(x)\n",
        "        x = self.dropout(x) # Apply dropout\n",
        "        # x = tf.concat([x, meta], axis=1)\n",
        "        x = self.last(x)\n",
        "        return x\n",
        "\n",
        "# Example usage (replace with your actual data and hyperparameters)\n",
        "num_nodes = 200  # Example number of nodes\n",
        "f1 = 64        # Example feature dimension 1\n",
        "f2 = 32        # Example feature dimension 2\n",
        "\n",
        "model = GIN(num_nodes, f1, f2)\n",
        "\n",
        "# if tf.config.list_physical_devices('GPU'):\n",
        "#   with tf.device('/GPU:0'):\n",
        "    # Compile the model\n",
        "optimizer = Adam(learning_rate=1e-1) # Adjust learning rate if necessary\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# model.fit([train_feature_matrices, train_adjacency_matrices, X_train_meta], y_train,\n",
        "# model.fit(dataset_train,\n",
        "#           batch_size = 32,\n",
        "#           validation_data=dataset_val,\n",
        "#           epochs=20,\n",
        "#           callbacks=[reduce_lr])\n",
        "\n",
        "model.fit(loader_train.load(),\n",
        "          steps_per_epoch=loader_train.steps_per_epoch,\n",
        "          validation_data=loader_val.load(),\n",
        "          validation_steps=loader_val.steps_per_epoch,\n",
        "          epochs=100,\n",
        "          # sample_weight=weights,\n",
        "          callbacks=[reduce_lr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JfKztLOtUGkZ",
        "outputId": "9d8c70d9-d1d9-42fd-d776-11d0d082ae9e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gin_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gin_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gin_conv_2 (\u001b[38;5;33mNewGINConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gin_conv_3 (\u001b[38;5;33mNewGINConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_avg_pool_5               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAvgPool\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pool_5               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalMaxPool\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)       â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gin_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGINConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gin_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGINConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_avg_pool_5               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAvgPool</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pool_5               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPool</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'FMRI_Dataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
            "  np.random.shuffle(a)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 828ms/step - accuracy: 0.8494 - loss: 5.5156 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.1000\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 944ms/step - accuracy: 0.8470 - loss: 5.6638 - val_accuracy: 0.8351 - val_loss: 5.5787 - learning_rate: 0.1000\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8491 - loss: 5.5344 - val_accuracy: 0.8711 - val_loss: 5.2883 - learning_rate: 0.1000\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8621 - loss: 5.3511 - val_accuracy: 0.8144 - val_loss: 5.9489 - learning_rate: 0.1000\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8654 - loss: 5.3477 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.1000\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 792ms/step - accuracy: 0.8461 - loss: 5.5983 - val_accuracy: 0.8402 - val_loss: 5.8261 - learning_rate: 0.1000\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 889ms/step - accuracy: 0.8671 - loss: 5.3570 - val_accuracy: 0.8299 - val_loss: 5.7850 - learning_rate: 0.1000\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 798ms/step - accuracy: 0.8589 - loss: 5.3297 - val_accuracy: 0.8351 - val_loss: 5.8270 - learning_rate: 0.1000\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 790ms/step - accuracy: 0.8683 - loss: 5.3474 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.1000\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 0.8660 - loss: 5.3816 - val_accuracy: 0.8763 - val_loss: 5.5362 - learning_rate: 0.1000\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 799ms/step - accuracy: 0.8679 - loss: 5.5065 - val_accuracy: 0.8505 - val_loss: 5.3294 - learning_rate: 0.1000\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 862ms/step - accuracy: 0.8763 - loss: 5.2914 - val_accuracy: 0.8505 - val_loss: 5.4139 - learning_rate: 0.1000\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.8535 - loss: 5.5246\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8537 - loss: 5.5220 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.1000\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 801ms/step - accuracy: 0.8533 - loss: 5.4459 - val_accuracy: 0.8608 - val_loss: 5.4130 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 859ms/step - accuracy: 0.8493 - loss: 5.6245 - val_accuracy: 0.8299 - val_loss: 5.7855 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 791ms/step - accuracy: 0.8600 - loss: 5.6014 - val_accuracy: 0.8866 - val_loss: 5.1217 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 884ms/step - accuracy: 0.8608 - loss: 5.4162 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8638 - loss: 5.4551 - val_accuracy: 0.8557 - val_loss: 5.2897 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 793ms/step - accuracy: 0.8598 - loss: 5.4116 - val_accuracy: 0.8247 - val_loss: 5.6175 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 884ms/step - accuracy: 0.8790 - loss: 5.1965 - val_accuracy: 0.8557 - val_loss: 5.4938 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8487 - loss: 5.6138 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8540 - loss: 5.3526 - val_accuracy: 0.8247 - val_loss: 5.9087 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8610 - loss: 5.4337 - val_accuracy: 0.8660 - val_loss: 5.2052 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8476 - loss: 5.6223 - val_accuracy: 0.8660 - val_loss: 5.6188 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8612 - loss: 5.2839 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.8501 - loss: 5.5656\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8504 - loss: 5.5613 - val_accuracy: 0.8711 - val_loss: 5.3728 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 807ms/step - accuracy: 0.8347 - loss: 5.6104 - val_accuracy: 0.8660 - val_loss: 5.4554 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 882ms/step - accuracy: 0.8636 - loss: 5.3445 - val_accuracy: 0.8402 - val_loss: 5.5778 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 810ms/step - accuracy: 0.8754 - loss: 5.1581 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 874ms/step - accuracy: 0.8757 - loss: 5.2441 - val_accuracy: 0.8454 - val_loss: 5.4130 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 799ms/step - accuracy: 0.8528 - loss: 5.6334 - val_accuracy: 0.8608 - val_loss: 5.3294 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 858ms/step - accuracy: 0.8605 - loss: 5.3969 - val_accuracy: 0.8351 - val_loss: 5.5362 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.8616 - loss: 5.2383 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.8515 - loss: 5.5794 - val_accuracy: 0.8454 - val_loss: 5.5380 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 817ms/step - accuracy: 0.8528 - loss: 5.2347 - val_accuracy: 0.8814 - val_loss: 5.1651 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.8482 - loss: 5.6071\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8486 - loss: 5.6012 - val_accuracy: 0.8247 - val_loss: 5.7850 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8623 - loss: 5.5235 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8637 - loss: 5.4567 - val_accuracy: 0.8454 - val_loss: 5.6184 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8558 - loss: 5.3825 - val_accuracy: 0.8608 - val_loss: 5.1664 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 864ms/step - accuracy: 0.8630 - loss: 5.4121 - val_accuracy: 0.8711 - val_loss: 5.2052 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 829ms/step - accuracy: 0.8422 - loss: 5.7386 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.8636 - loss: 5.2883 - val_accuracy: 0.8505 - val_loss: 5.4974 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 831ms/step - accuracy: 0.8533 - loss: 5.3956 - val_accuracy: 0.8402 - val_loss: 5.5385 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 863ms/step - accuracy: 0.8661 - loss: 5.4232 - val_accuracy: 0.8557 - val_loss: 5.6595 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 800ms/step - accuracy: 0.8562 - loss: 5.4848 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - accuracy: 0.8536 - loss: 5.6734\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 874ms/step - accuracy: 0.8538 - loss: 5.6650 - val_accuracy: 0.8557 - val_loss: 5.5764 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8631 - loss: 5.3468 - val_accuracy: 0.8505 - val_loss: 5.2906 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 806ms/step - accuracy: 0.8623 - loss: 5.4575 - val_accuracy: 0.8660 - val_loss: 5.3714 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8536 - loss: 5.6524 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8656 - loss: 5.2511 - val_accuracy: 0.8454 - val_loss: 5.5376 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8720 - loss: 5.3651 - val_accuracy: 0.8247 - val_loss: 5.9900 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.8566 - loss: 5.2633 - val_accuracy: 0.8711 - val_loss: 5.1235 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 814ms/step - accuracy: 0.8592 - loss: 5.5649 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8650 - loss: 5.4791 - val_accuracy: 0.8660 - val_loss: 5.2892 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 856ms/step - accuracy: 0.8544 - loss: 5.5134 - val_accuracy: 0.8144 - val_loss: 6.0325 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.8643 - loss: 5.2182\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 823ms/step - accuracy: 0.8640 - loss: 5.2273 - val_accuracy: 0.8608 - val_loss: 5.3299 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8612 - loss: 5.4481 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8566 - loss: 5.6360 - val_accuracy: 0.8660 - val_loss: 5.5800 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8699 - loss: 5.4100 - val_accuracy: 0.8505 - val_loss: 5.2897 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8560 - loss: 5.3325 - val_accuracy: 0.8608 - val_loss: 5.3308 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 864ms/step - accuracy: 0.8595 - loss: 5.6346 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.8517 - loss: 5.5603 - val_accuracy: 0.8557 - val_loss: 5.3281 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.8529 - loss: 5.5738 - val_accuracy: 0.8247 - val_loss: 5.6604 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 846ms/step - accuracy: 0.8596 - loss: 5.3066 - val_accuracy: 0.8660 - val_loss: 5.4120 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 826ms/step - accuracy: 0.8375 - loss: 5.9726 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.8513 - loss: 5.5473 - val_accuracy: 0.8711 - val_loss: 5.0400 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 840ms/step - accuracy: 0.8666 - loss: 5.3203 - val_accuracy: 0.8144 - val_loss: 5.9905 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 888ms/step - accuracy: 0.8556 - loss: 5.6986 - val_accuracy: 0.8660 - val_loss: 5.2481 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 819ms/step - accuracy: 0.8565 - loss: 5.4953 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 864ms/step - accuracy: 0.8497 - loss: 5.6269 - val_accuracy: 0.8402 - val_loss: 5.6202 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 820ms/step - accuracy: 0.8563 - loss: 5.4995 - val_accuracy: 0.8814 - val_loss: 5.1619 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8692 - loss: 5.0670 - val_accuracy: 0.8402 - val_loss: 5.6613 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 875ms/step - accuracy: 0.8602 - loss: 5.3124 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 796ms/step - accuracy: 0.8396 - loss: 5.5958 - val_accuracy: 0.8608 - val_loss: 5.4536 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8743 - loss: 5.2230 - val_accuracy: 0.8454 - val_loss: 5.6608 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8643 - loss: 5.4946 - val_accuracy: 0.8454 - val_loss: 5.6179 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8658 - loss: 5.4471 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 871ms/step - accuracy: 0.8575 - loss: 5.4831 - val_accuracy: 0.8608 - val_loss: 5.1258 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 821ms/step - accuracy: 0.8521 - loss: 5.5387 - val_accuracy: 0.8454 - val_loss: 5.6617 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 5.6731 - val_accuracy: 0.8505 - val_loss: 5.5782 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 859ms/step - accuracy: 0.8662 - loss: 5.5357 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 832ms/step - accuracy: 0.8553 - loss: 5.5177 - val_accuracy: 0.8505 - val_loss: 5.4125 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8484 - loss: 5.6453 - val_accuracy: 0.8505 - val_loss: 5.6193 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8412 - loss: 5.7409 - val_accuracy: 0.8402 - val_loss: 5.7444 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8651 - loss: 5.3851 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 0.8457 - loss: 5.5491 - val_accuracy: 0.8505 - val_loss: 5.6202 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 829ms/step - accuracy: 0.8487 - loss: 5.6302 - val_accuracy: 0.8660 - val_loss: 5.6211 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8609 - loss: 5.3501 - val_accuracy: 0.8454 - val_loss: 5.6188 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 0.8653 - loss: 5.3267 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8335 - loss: 5.6650 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 0.8617 - loss: 5.5169 - val_accuracy: 0.8351 - val_loss: 5.7430 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8603 - loss: 5.5280 - val_accuracy: 0.8557 - val_loss: 5.4125 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8591 - loss: 5.4600 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 837ms/step - accuracy: 0.8747 - loss: 5.4473 - val_accuracy: 0.8505 - val_loss: 5.5800 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 836ms/step - accuracy: 0.8590 - loss: 5.4122 - val_accuracy: 0.8557 - val_loss: 5.4536 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.8450 - loss: 5.6740 - val_accuracy: 0.8557 - val_loss: 5.3719 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 821ms/step - accuracy: 0.8613 - loss: 5.5629 - val_accuracy: 0.8505 - val_loss: 5.4956 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 895ms/step - accuracy: 0.8620 - loss: 5.3754 - val_accuracy: 0.8557 - val_loss: 5.5367 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 835ms/step - accuracy: 0.8492 - loss: 5.6626 - val_accuracy: 0.8402 - val_loss: 5.7846 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8425 - loss: 5.6825 - val_accuracy: 0.8505 - val_loss: 5.4951 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x789f00103650>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = DisjointLoader(val_dataset, batch_size=1, shuffle=False, epochs=1)\n",
        "\n",
        "y_pred = []\n",
        "y_target = []\n",
        "for batch in validation_loader:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    y_pred.append(predictions)\n",
        "    y_target.append(target)\n",
        "y_pred = np.concatenate(y_pred, axis=0)\n",
        "y_target = np.concatenate(y_target, axis=0)\n",
        "\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy for each column separately\n",
        "for i in range(y_val.shape[1]):\n",
        "    accuracy = accuracy_score(y_val[:, i], y_pred_classes[:, i])\n",
        "    print(f\"Accuracy for column {i}: {accuracy}\")\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.int16)\n",
        "y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.int16)\n",
        "f1 = custom_f1(y_val_tensor, y_pred_tensor)\n",
        "f1_2 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "print(f\"Weighted F1 Score: {f1}, {f1_2}\")\n",
        "f1_3 = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "print(f\"Jiaqi's Weighted F1 Score: {f1_3}\")\n",
        "\n",
        "##\n",
        "# Accuracy for column 0: 0.7325102880658436\n",
        "# Accuracy for column 1: 0.7037037037037037\n",
        "# (243,)\n",
        "# (243,)\n",
        "# (243,)\n",
        "# Weighted F1 Score: 0.2917821324887833, 0.5591073187265774\n",
        "# Jiaqi's Weighted F1 Score: (0.436399217221135, 0.87279843444227, 0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-N18IS4b_Lk",
        "outputId": "212cc6df-1940-4224-a89d-b8ce6ea7478b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for column 0: 0.7325102880658436\n",
            "Accuracy for column 1: 0.7037037037037037\n",
            "(243,)\n",
            "(243,)\n",
            "(243,)\n",
            "Weighted F1 Score: 0.2917821324887833, 0.5591073187265774\n",
            "Jiaqi's Weighted F1 Score: (0.436399217221135, 0.87279843444227, 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4eFdaOtAp558"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph threshold tuning"
      ],
      "metadata": {
        "id": "ZASlzIhz1s6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_graph_threshold(model, thres, lr=1e-2):\n",
        "  ## adj matrix creation\n",
        "  # Create adjacency matrices for training and validation data\n",
        "  train_adjacency_matrices = [create_adjacency_matrix(cm, threshold=thres) for cm in X_train_mri]\n",
        "  val_adjacency_matrices = [create_adjacency_matrix(cm, threshold=thres) for cm in X_val_mri]\n",
        "  test_adjacency_matrices = [create_adjacency_matrix(cm, threshold=thres) for cm in connectome_matrices_test]\n",
        "  train_adjacency_matrices = np.array(train_adjacency_matrices)\n",
        "  val_adjacency_matrices = np.array(val_adjacency_matrices)\n",
        "  test_adjacency_matrices = np.array(test_adjacency_matrices)\n",
        "\n",
        "  # Create adjacency matrices for training and validation data\n",
        "  train_weighted_adj_matrices = [create_weighted_adj_matrix(cm, threshold=thres) for cm in X_train_mri]\n",
        "  val_weighted_adj_matrices = [create_weighted_adj_matrix(cm, threshold=thres) for cm in X_val_mri]\n",
        "  test_weighted_adj_matrices = [create_weighted_adj_matrix(cm, threshold=thres) for cm in connectome_matrices_test]\n",
        "  train_weighted_adj_matrices = np.array(train_weighted_adj_matrices)\n",
        "  val_weighted_adj_matrices = np.array(val_weighted_adj_matrices)\n",
        "  test_weighted_adj_matrices = np.array(test_weighted_adj_matrices)\n",
        "\n",
        "  # Create feature matrices for training and validation data\n",
        "  train_feature_matrices = [np.eye(200,200) for _ in X_train_mri]\n",
        "  val_feature_matrices = [np.eye(200,200) for _ in X_val_mri]\n",
        "  test_feature_matrices = [np.eye(200,200) for _ in connectome_matrices_test]\n",
        "  train_feature_matrices = np.array(train_feature_matrices)\n",
        "  val_feature_matrices = np.array(val_feature_matrices)\n",
        "  test_feature_matrices = np.array(test_feature_matrices)\n",
        "\n",
        "  ## Train model\n",
        "  # Compile the model\n",
        "  optimizer = Adam(learning_rate=lr)\n",
        "  f1_scorer = F1Score(average='weighted')\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  model.fit([train_feature_matrices, train_adjacency_matrices, X_train_meta], y_train,\n",
        "            epochs=100, batch_size=32, validation_split=0.2,\n",
        "            sample_weight=weights,\n",
        "            callbacks=[reduce_lr])\n",
        "\n",
        "  ## Model Evaluation\n",
        "  y_pred = model.predict([val_feature_matrices, val_adjacency_matrices, X_val_meta])\n",
        "  y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "  f1_3 = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "  print(f\"Jiaqi's Weighted F1 Score: {f1_3}\")\n",
        "  return model, f1_3[0], y_pred"
      ],
      "metadata": {
        "id": "UHIKzpO11tpP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.linspace(0, 1, 21)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thres = 0\n",
        "best_model = None\n",
        "best_val = None\n",
        "f1_scores = []\n",
        "for thres in thresholds:\n",
        "  model = GAT(64, 1, 0.5)\n",
        "  trained_model, f1, y_pred = tune_graph_threshold(model, thres)\n",
        "  f1_scores.append(f1)\n",
        "  if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_thres = thres\n",
        "    best_model = trained_model\n",
        "    best_val = y_pred\n",
        "\n",
        "print(f\"Best threshold: {best_thres}, Best F1: {best_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5lqX5km3jFr",
        "outputId": "63c454b5-bb11-440d-ed62-abfbdee1b846"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 175ms/step - accuracy: 0.8482 - f1_score: 0.5110 - loss: 0.7661 - val_accuracy: 0.8144 - val_f1_score: 0.7169 - val_loss: 0.7013 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7828 - f1_score: 0.6331 - loss: 0.7425 - val_accuracy: 0.8660 - val_f1_score: 0.6995 - val_loss: 0.6421 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7999 - f1_score: 0.6421 - loss: 0.6910 - val_accuracy: 0.8247 - val_f1_score: 0.7147 - val_loss: 0.6376 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8210 - f1_score: 0.6471 - loss: 0.6805 - val_accuracy: 0.8505 - val_f1_score: 0.7104 - val_loss: 0.6208 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8262 - f1_score: 0.6384 - loss: 0.6768 - val_accuracy: 0.8505 - val_f1_score: 0.7104 - val_loss: 0.6075 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8147 - f1_score: 0.6451 - loss: 0.6799 - val_accuracy: 0.8608 - val_f1_score: 0.7097 - val_loss: 0.6225 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8338 - f1_score: 0.6718 - loss: 0.6703 - val_accuracy: 0.7887 - val_f1_score: 0.7374 - val_loss: 0.6141 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8010 - f1_score: 0.6906 - loss: 0.6721 - val_accuracy: 0.8196 - val_f1_score: 0.7439 - val_loss: 0.6008 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8069 - f1_score: 0.6943 - loss: 0.6548 - val_accuracy: 0.8041 - val_f1_score: 0.7443 - val_loss: 0.6184 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7991 - f1_score: 0.7101 - loss: 0.6465 - val_accuracy: 0.8351 - val_f1_score: 0.7081 - val_loss: 0.6531 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8181 - f1_score: 0.6656 - loss: 0.6824 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.6221 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8145 - f1_score: 0.6914 - loss: 0.6367 - val_accuracy: 0.8454 - val_f1_score: 0.7033 - val_loss: 0.6003 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8228 - f1_score: 0.6815 - loss: 0.6602 - val_accuracy: 0.8299 - val_f1_score: 0.7334 - val_loss: 0.6147 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8355 - f1_score: 0.6956 - loss: 0.6321 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.6190 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8003 - f1_score: 0.6683 - loss: 0.6610 - val_accuracy: 0.8247 - val_f1_score: 0.7456 - val_loss: 0.5934 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7888 - f1_score: 0.6936 - loss: 0.6503 - val_accuracy: 0.8351 - val_f1_score: 0.7325 - val_loss: 0.6090 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8169 - f1_score: 0.6958 - loss: 0.6284 - val_accuracy: 0.8041 - val_f1_score: 0.7468 - val_loss: 0.6569 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8212 - f1_score: 0.6836 - loss: 0.6720 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.6166 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7770 - f1_score: 0.6966 - loss: 0.6489 - val_accuracy: 0.5258 - val_f1_score: 0.6121 - val_loss: 0.8895 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7727 - f1_score: 0.6827 - loss: 0.6954 - val_accuracy: 0.8402 - val_f1_score: 0.7354 - val_loss: 0.6241 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8151 - f1_score: 0.6739 - loss: 0.6795 - val_accuracy: 0.8660 - val_f1_score: 0.6252 - val_loss: 0.6907 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8076 - f1_score: 0.6633 - loss: 0.6783 - val_accuracy: 0.8093 - val_f1_score: 0.7541 - val_loss: 0.6209 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7989 - f1_score: 0.6605 - loss: 0.6581 - val_accuracy: 0.8093 - val_f1_score: 0.7565 - val_loss: 0.5978 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7820 - f1_score: 0.6834 - loss: 0.6558 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6213 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7853 - f1_score: 0.6578 - loss: 0.6537\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7892 - f1_score: 0.6594 - loss: 0.6533 - val_accuracy: 0.8505 - val_f1_score: 0.7419 - val_loss: 0.6033 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8204 - f1_score: 0.6582 - loss: 0.6342 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5974 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8097 - f1_score: 0.7045 - loss: 0.6143 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6028 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7935 - f1_score: 0.6845 - loss: 0.6172 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.5984 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8196 - f1_score: 0.6905 - loss: 0.6383 - val_accuracy: 0.8454 - val_f1_score: 0.7436 - val_loss: 0.6013 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8272 - f1_score: 0.6820 - loss: 0.6385 - val_accuracy: 0.8144 - val_f1_score: 0.7449 - val_loss: 0.6041 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8005 - f1_score: 0.6949 - loss: 0.6084 - val_accuracy: 0.8454 - val_f1_score: 0.7436 - val_loss: 0.5976 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8202 - f1_score: 0.6939 - loss: 0.6179 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6014 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8023 - f1_score: 0.7056 - loss: 0.6182 - val_accuracy: 0.8196 - val_f1_score: 0.7439 - val_loss: 0.6019 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8269 - f1_score: 0.7161 - loss: 0.6130 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6011 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8109 - f1_score: 0.6960 - loss: 0.6398\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8110 - f1_score: 0.6957 - loss: 0.6375 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6028 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8104 - f1_score: 0.6947 - loss: 0.6234 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6021 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7963 - f1_score: 0.6743 - loss: 0.6422 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8159 - f1_score: 0.6917 - loss: 0.6211 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6017 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8279 - f1_score: 0.6948 - loss: 0.6216 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6022 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8077 - f1_score: 0.6884 - loss: 0.6278 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6027 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8294 - f1_score: 0.6925 - loss: 0.6277 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6024 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8098 - f1_score: 0.6812 - loss: 0.6229 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6017 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8240 - f1_score: 0.6978 - loss: 0.6244 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6016 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8320 - f1_score: 0.7089 - loss: 0.6062 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6026 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8252 - f1_score: 0.7185 - loss: 0.6249\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8225 - f1_score: 0.7113 - loss: 0.6241 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - f1_score: 0.6964 - loss: 0.6269 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8138 - f1_score: 0.6894 - loss: 0.6170 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8023 - f1_score: 0.6895 - loss: 0.6204 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8254 - f1_score: 0.6972 - loss: 0.6110 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8151 - f1_score: 0.7023 - loss: 0.6215 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8173 - f1_score: 0.6899 - loss: 0.6317 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7935 - f1_score: 0.6929 - loss: 0.6261 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6019 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8217 - f1_score: 0.6847 - loss: 0.6209 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8394 - f1_score: 0.7107 - loss: 0.6137 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7984 - f1_score: 0.6983 - loss: 0.6346\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7998 - f1_score: 0.6980 - loss: 0.6336 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8059 - f1_score: 0.6772 - loss: 0.6312 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8273 - f1_score: 0.6957 - loss: 0.6222 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8213 - f1_score: 0.6836 - loss: 0.6166 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8075 - f1_score: 0.6943 - loss: 0.6115 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8222 - f1_score: 0.6887 - loss: 0.6363 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8124 - f1_score: 0.6971 - loss: 0.6105 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8416 - f1_score: 0.7121 - loss: 0.6147 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8016 - f1_score: 0.7000 - loss: 0.6140 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8128 - f1_score: 0.7049 - loss: 0.6132 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8155 - f1_score: 0.6903 - loss: 0.6213 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8265 - f1_score: 0.7104 - loss: 0.6225 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8260 - f1_score: 0.7045 - loss: 0.6038 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8268 - f1_score: 0.6913 - loss: 0.6228 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8263 - f1_score: 0.6918 - loss: 0.6146 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8077 - f1_score: 0.7011 - loss: 0.6079 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8226 - f1_score: 0.7203 - loss: 0.6141 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8055 - f1_score: 0.6913 - loss: 0.6104 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8249 - f1_score: 0.6986 - loss: 0.6229 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8077 - f1_score: 0.6993 - loss: 0.6232 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8208 - f1_score: 0.7061 - loss: 0.6108 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8182 - f1_score: 0.6977 - loss: 0.6249 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8091 - f1_score: 0.6808 - loss: 0.6258 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8109 - f1_score: 0.6870 - loss: 0.6306 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8052 - f1_score: 0.7075 - loss: 0.6264 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8305 - f1_score: 0.7039 - loss: 0.6160 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7915 - f1_score: 0.7010 - loss: 0.6075 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8260 - f1_score: 0.7005 - loss: 0.6119 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8342 - f1_score: 0.7043 - loss: 0.6153 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7904 - f1_score: 0.6944 - loss: 0.6152 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8310 - f1_score: 0.6992 - loss: 0.6191 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8235 - f1_score: 0.6997 - loss: 0.6155 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8196 - f1_score: 0.6964 - loss: 0.6100 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8032 - f1_score: 0.6961 - loss: 0.6212 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8005 - f1_score: 0.6871 - loss: 0.6210 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7949 - f1_score: 0.6730 - loss: 0.6448 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8157 - f1_score: 0.7003 - loss: 0.6212 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8274 - f1_score: 0.6953 - loss: 0.6295 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8338 - f1_score: 0.6929 - loss: 0.6100 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8128 - f1_score: 0.6982 - loss: 0.6181 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8247 - f1_score: 0.6843 - loss: 0.6316 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8268 - f1_score: 0.6934 - loss: 0.6263 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8026 - f1_score: 0.6744 - loss: 0.6362 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8144 - f1_score: 0.6990 - loss: 0.6290 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8215 - f1_score: 0.6972 - loss: 0.6071 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8262 - f1_score: 0.7090 - loss: 0.6282 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6020 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6669076885996625, 0.8893709327548807, 0.4444444444444444)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170ms/step - accuracy: 0.7682 - f1_score: 0.5603 - loss: 0.7855 - val_accuracy: 0.8711 - val_f1_score: 0.6717 - val_loss: 0.6667 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8406 - f1_score: 0.5982 - loss: 0.6987 - val_accuracy: 0.8247 - val_f1_score: 0.7197 - val_loss: 0.6229 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8199 - f1_score: 0.6852 - loss: 0.6888 - val_accuracy: 0.7423 - val_f1_score: 0.7229 - val_loss: 0.6579 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8088 - f1_score: 0.6452 - loss: 0.6862 - val_accuracy: 0.8299 - val_f1_score: 0.7259 - val_loss: 0.6322 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7726 - f1_score: 0.6491 - loss: 0.7020 - val_accuracy: 0.8196 - val_f1_score: 0.7389 - val_loss: 0.6177 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7800 - f1_score: 0.6731 - loss: 0.6833 - val_accuracy: 0.8454 - val_f1_score: 0.7248 - val_loss: 0.5972 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8186 - f1_score: 0.6671 - loss: 0.6693 - val_accuracy: 0.8454 - val_f1_score: 0.6986 - val_loss: 0.6191 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8463 - f1_score: 0.6792 - loss: 0.6412 - val_accuracy: 0.8454 - val_f1_score: 0.6986 - val_loss: 0.6819 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7802 - f1_score: 0.6604 - loss: 0.6844 - val_accuracy: 0.8660 - val_f1_score: 0.6137 - val_loss: 0.6522 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8191 - f1_score: 0.6303 - loss: 0.6925 - val_accuracy: 0.7320 - val_f1_score: 0.7273 - val_loss: 0.6320 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7506 - f1_score: 0.6798 - loss: 0.6856 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.6293 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8359 - f1_score: 0.6715 - loss: 0.6617 - val_accuracy: 0.6546 - val_f1_score: 0.6882 - val_loss: 0.6808 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7422 - f1_score: 0.6932 - loss: 0.6540 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.5970 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8133 - f1_score: 0.6611 - loss: 0.6762 - val_accuracy: 0.8351 - val_f1_score: 0.7296 - val_loss: 0.5978 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7973 - f1_score: 0.6681 - loss: 0.6762 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.5888 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8181 - f1_score: 0.7141 - loss: 0.6187 - val_accuracy: 0.8557 - val_f1_score: 0.7491 - val_loss: 0.6092 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7731 - f1_score: 0.6691 - loss: 0.6444 - val_accuracy: 0.8351 - val_f1_score: 0.7403 - val_loss: 0.6035 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8317 - f1_score: 0.6944 - loss: 0.6113 - val_accuracy: 0.7423 - val_f1_score: 0.7358 - val_loss: 0.6394 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7589 - f1_score: 0.6838 - loss: 0.6379 - val_accuracy: 0.8402 - val_f1_score: 0.6994 - val_loss: 0.6161 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8156 - f1_score: 0.6784 - loss: 0.6447 - val_accuracy: 0.8144 - val_f1_score: 0.7475 - val_loss: 0.6093 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8077 - f1_score: 0.7003 - loss: 0.6189 - val_accuracy: 0.8351 - val_f1_score: 0.7130 - val_loss: 0.6166 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8425 - f1_score: 0.6805 - loss: 0.6374 - val_accuracy: 0.6289 - val_f1_score: 0.6746 - val_loss: 0.7833 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7553 - f1_score: 0.6795 - loss: 0.6558 - val_accuracy: 0.8402 - val_f1_score: 0.6860 - val_loss: 0.6117 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8201 - f1_score: 0.6745 - loss: 0.6271 - val_accuracy: 0.8351 - val_f1_score: 0.7425 - val_loss: 0.5955 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7890 - f1_score: 0.6714 - loss: 0.6375 \n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7914 - f1_score: 0.6723 - loss: 0.6374 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6171 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7974 - f1_score: 0.6969 - loss: 0.6312 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6059 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8125 - f1_score: 0.7116 - loss: 0.6252 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6076 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8329 - f1_score: 0.7002 - loss: 0.6030 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6064 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8210 - f1_score: 0.7163 - loss: 0.5959 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6082 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8162 - f1_score: 0.7205 - loss: 0.5966 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6091 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8271 - f1_score: 0.7075 - loss: 0.6048 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6038 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7997 - f1_score: 0.6958 - loss: 0.6089 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6067 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8368 - f1_score: 0.7117 - loss: 0.6079 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6096 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8160 - f1_score: 0.7057 - loss: 0.5933 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6107 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8093 - f1_score: 0.7084 - loss: 0.6152\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8111 - f1_score: 0.7087 - loss: 0.6129 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6061 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8145 - f1_score: 0.7194 - loss: 0.5888 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6067 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.7004 - loss: 0.5939 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6072 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8180 - f1_score: 0.6980 - loss: 0.5919 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6071 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8105 - f1_score: 0.7127 - loss: 0.6026 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6072 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8339 - f1_score: 0.7304 - loss: 0.5917 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6077 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7888 - f1_score: 0.6838 - loss: 0.6064 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6077 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8102 - f1_score: 0.7025 - loss: 0.5942 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7943 - f1_score: 0.6722 - loss: 0.6272 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6077 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8072 - f1_score: 0.6900 - loss: 0.6045 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6080 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8284 - f1_score: 0.7088 - loss: 0.5858\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8260 - f1_score: 0.7072 - loss: 0.5886 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8294 - f1_score: 0.6999 - loss: 0.6149 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8037 - f1_score: 0.6955 - loss: 0.6031 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7960 - f1_score: 0.7085 - loss: 0.5841 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8300 - f1_score: 0.6994 - loss: 0.6086 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8137 - f1_score: 0.6915 - loss: 0.6279 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8207 - f1_score: 0.6973 - loss: 0.6322 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8141 - f1_score: 0.7105 - loss: 0.6061 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8162 - f1_score: 0.7115 - loss: 0.5914 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8129 - f1_score: 0.6945 - loss: 0.6108 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7965 - f1_score: 0.7010 - loss: 0.5972 \n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7976 - f1_score: 0.7010 - loss: 0.5979 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8131 - f1_score: 0.7093 - loss: 0.5840 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7936 - f1_score: 0.6851 - loss: 0.6007 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8040 - f1_score: 0.7032 - loss: 0.5888 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8291 - f1_score: 0.7073 - loss: 0.5931 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7906 - f1_score: 0.6833 - loss: 0.5960 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8050 - f1_score: 0.6950 - loss: 0.6107 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8055 - f1_score: 0.6971 - loss: 0.5990 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7970 - f1_score: 0.6856 - loss: 0.6137 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8029 - f1_score: 0.6939 - loss: 0.5982 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8294 - f1_score: 0.7178 - loss: 0.5849 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8270 - f1_score: 0.7128 - loss: 0.5856 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8082 - f1_score: 0.7071 - loss: 0.5957 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7868 - f1_score: 0.6815 - loss: 0.6340 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8188 - f1_score: 0.7179 - loss: 0.5875 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8154 - f1_score: 0.6992 - loss: 0.6231 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8143 - f1_score: 0.7069 - loss: 0.6181 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7997 - f1_score: 0.6979 - loss: 0.6015 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6078 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7922 - f1_score: 0.6804 - loss: 0.6032 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8066 - f1_score: 0.7017 - loss: 0.6017 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8148 - f1_score: 0.6858 - loss: 0.5998 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8394 - f1_score: 0.7110 - loss: 0.6123 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8023 - f1_score: 0.6896 - loss: 0.6232 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8070 - f1_score: 0.7070 - loss: 0.6063 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8050 - f1_score: 0.7006 - loss: 0.6133 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8227 - f1_score: 0.6976 - loss: 0.6148 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8092 - f1_score: 0.7015 - loss: 0.6013 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8335 - f1_score: 0.7042 - loss: 0.5986 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8268 - f1_score: 0.6984 - loss: 0.6076 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8054 - f1_score: 0.6962 - loss: 0.6126 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8083 - f1_score: 0.7079 - loss: 0.6053 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8090 - f1_score: 0.6917 - loss: 0.6109 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7917 - f1_score: 0.6951 - loss: 0.6191 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8184 - f1_score: 0.6906 - loss: 0.6128 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8047 - f1_score: 0.6988 - loss: 0.6067 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8099 - f1_score: 0.6941 - loss: 0.6073 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8068 - f1_score: 0.7022 - loss: 0.5989 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8267 - f1_score: 0.7072 - loss: 0.6121 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8276 - f1_score: 0.7034 - loss: 0.5965 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7957 - f1_score: 0.6718 - loss: 0.6197 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8056 - f1_score: 0.6953 - loss: 0.6032 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8087 - f1_score: 0.7019 - loss: 0.6029 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.6927 - loss: 0.6121 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7906 - f1_score: 0.6790 - loss: 0.6226 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8275 - f1_score: 0.7122 - loss: 0.6137 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8113 - f1_score: 0.7009 - loss: 0.6041 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6456726319037334, 0.8984881209503239, 0.39285714285714285)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.7456 - f1_score: 0.5303 - loss: 0.7907 - val_accuracy: 0.8505 - val_f1_score: 0.5670 - val_loss: 0.6782 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8145 - f1_score: 0.5978 - loss: 0.7314 - val_accuracy: 0.8351 - val_f1_score: 0.7151 - val_loss: 0.6511 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8270 - f1_score: 0.6495 - loss: 0.6891 - val_accuracy: 0.8041 - val_f1_score: 0.7447 - val_loss: 0.6594 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7889 - f1_score: 0.6644 - loss: 0.6840 - val_accuracy: 0.8557 - val_f1_score: 0.7264 - val_loss: 0.6117 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8180 - f1_score: 0.6603 - loss: 0.6706 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6032 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8112 - f1_score: 0.6852 - loss: 0.6935 - val_accuracy: 0.8454 - val_f1_score: 0.7112 - val_loss: 0.6071 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8144 - f1_score: 0.6926 - loss: 0.6541 - val_accuracy: 0.8144 - val_f1_score: 0.7398 - val_loss: 0.6232 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7891 - f1_score: 0.6678 - loss: 0.6779 - val_accuracy: 0.8402 - val_f1_score: 0.7121 - val_loss: 0.5987 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8096 - f1_score: 0.6676 - loss: 0.6642 - val_accuracy: 0.7629 - val_f1_score: 0.7398 - val_loss: 0.6368 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7680 - f1_score: 0.6902 - loss: 0.6446 - val_accuracy: 0.8454 - val_f1_score: 0.6986 - val_loss: 0.6389 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7873 - f1_score: 0.6727 - loss: 0.6557 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6015 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7960 - f1_score: 0.6557 - loss: 0.6806 - val_accuracy: 0.8505 - val_f1_score: 0.7200 - val_loss: 0.6051 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7946 - f1_score: 0.6464 - loss: 0.6596 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6042 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7961 - f1_score: 0.6620 - loss: 0.6565 - val_accuracy: 0.8454 - val_f1_score: 0.6943 - val_loss: 0.6208 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8362 - f1_score: 0.6544 - loss: 0.6497 - val_accuracy: 0.8299 - val_f1_score: 0.7273 - val_loss: 0.5954 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8090 - f1_score: 0.6867 - loss: 0.6344 - val_accuracy: 0.8351 - val_f1_score: 0.7489 - val_loss: 0.5958 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8091 - f1_score: 0.6816 - loss: 0.6392 - val_accuracy: 0.8299 - val_f1_score: 0.7574 - val_loss: 0.6129 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8258 - f1_score: 0.6815 - loss: 0.6370 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6402 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8314 - f1_score: 0.6787 - loss: 0.6489 - val_accuracy: 0.7423 - val_f1_score: 0.7303 - val_loss: 0.6427 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7616 - f1_score: 0.6847 - loss: 0.6659 - val_accuracy: 0.8351 - val_f1_score: 0.7215 - val_loss: 0.5983 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8135 - f1_score: 0.6947 - loss: 0.6279 - val_accuracy: 0.8505 - val_f1_score: 0.7354 - val_loss: 0.5993 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8278 - f1_score: 0.7009 - loss: 0.6440 - val_accuracy: 0.7784 - val_f1_score: 0.7289 - val_loss: 0.6878 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7780 - f1_score: 0.6951 - loss: 0.6497 - val_accuracy: 0.7938 - val_f1_score: 0.7543 - val_loss: 0.6355 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7929 - f1_score: 0.6769 - loss: 0.6565 - val_accuracy: 0.8351 - val_f1_score: 0.7130 - val_loss: 0.6303 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8153 - f1_score: 0.6748 - loss: 0.6493 \n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8152 - f1_score: 0.6753 - loss: 0.6492 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6152 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8129 - f1_score: 0.6807 - loss: 0.6292 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6036 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8011 - f1_score: 0.6856 - loss: 0.6423 - val_accuracy: 0.8402 - val_f1_score: 0.7658 - val_loss: 0.6092 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7922 - f1_score: 0.6676 - loss: 0.6462 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6098 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8122 - f1_score: 0.6747 - loss: 0.6195 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6089 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7866 - f1_score: 0.6802 - loss: 0.6106 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6026 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8025 - f1_score: 0.6895 - loss: 0.6195 - val_accuracy: 0.8351 - val_f1_score: 0.7667 - val_loss: 0.6063 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7982 - f1_score: 0.6929 - loss: 0.6220 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6059 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8249 - f1_score: 0.6957 - loss: 0.6181 - val_accuracy: 0.8351 - val_f1_score: 0.7667 - val_loss: 0.6045 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7838 - f1_score: 0.6660 - loss: 0.6203 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6086 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8225 - f1_score: 0.6875 - loss: 0.6171\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8222 - f1_score: 0.6878 - loss: 0.6171 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6044 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7834 - f1_score: 0.6829 - loss: 0.6288 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6049 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8070 - f1_score: 0.6972 - loss: 0.6200 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6052 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8340 - f1_score: 0.6958 - loss: 0.6157 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6060 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7995 - f1_score: 0.7133 - loss: 0.6129 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6059 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8222 - f1_score: 0.6839 - loss: 0.6194 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6059 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8151 - f1_score: 0.6903 - loss: 0.5977 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6054 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8335 - f1_score: 0.7179 - loss: 0.5966 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6056 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8154 - f1_score: 0.6911 - loss: 0.6235 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6063 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8302 - f1_score: 0.6940 - loss: 0.6288 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.6057 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7807 - f1_score: 0.6949 - loss: 0.6057\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7881 - f1_score: 0.6945 - loss: 0.6081 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8022 - f1_score: 0.6917 - loss: 0.6179 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8076 - f1_score: 0.7006 - loss: 0.6026 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8009 - f1_score: 0.6855 - loss: 0.6024 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8126 - f1_score: 0.6989 - loss: 0.6195 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8131 - f1_score: 0.7018 - loss: 0.6006 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8281 - f1_score: 0.7209 - loss: 0.6009 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8513 - f1_score: 0.7285 - loss: 0.6038 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8208 - f1_score: 0.6987 - loss: 0.6226 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8324 - f1_score: 0.6999 - loss: 0.5999 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8126 - f1_score: 0.6878 - loss: 0.6186\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8127 - f1_score: 0.6886 - loss: 0.6182 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8041 - f1_score: 0.6907 - loss: 0.6158 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8065 - f1_score: 0.7033 - loss: 0.6126 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8101 - f1_score: 0.7000 - loss: 0.6139 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8196 - f1_score: 0.6964 - loss: 0.6153 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8112 - f1_score: 0.7040 - loss: 0.6093 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8303 - f1_score: 0.7185 - loss: 0.6101 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8198 - f1_score: 0.7065 - loss: 0.6079 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8120 - f1_score: 0.6916 - loss: 0.6151 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8171 - f1_score: 0.6957 - loss: 0.6030 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8280 - f1_score: 0.7103 - loss: 0.6026 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8260 - f1_score: 0.7098 - loss: 0.6203 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8280 - f1_score: 0.7083 - loss: 0.5978 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8021 - f1_score: 0.6973 - loss: 0.6136 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7938 - f1_score: 0.6856 - loss: 0.6161 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8324 - f1_score: 0.7118 - loss: 0.6008 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8036 - f1_score: 0.6976 - loss: 0.6129 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8059 - f1_score: 0.6865 - loss: 0.6254 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8405 - f1_score: 0.7066 - loss: 0.6249 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7894 - f1_score: 0.6855 - loss: 0.6098 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8107 - f1_score: 0.7110 - loss: 0.6222 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8166 - f1_score: 0.6936 - loss: 0.6158 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8140 - f1_score: 0.6804 - loss: 0.6376 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7948 - f1_score: 0.6999 - loss: 0.5958 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8166 - f1_score: 0.6941 - loss: 0.5868 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8282 - f1_score: 0.7141 - loss: 0.6055 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7952 - f1_score: 0.6995 - loss: 0.6353 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7810 - f1_score: 0.6810 - loss: 0.6378 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7930 - f1_score: 0.7000 - loss: 0.6234 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8245 - f1_score: 0.7096 - loss: 0.6046 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8106 - f1_score: 0.6875 - loss: 0.6072 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7988 - f1_score: 0.6924 - loss: 0.6141 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8156 - f1_score: 0.6969 - loss: 0.6254 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8011 - f1_score: 0.6905 - loss: 0.6217 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8220 - f1_score: 0.6806 - loss: 0.6275 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7908 - f1_score: 0.6789 - loss: 0.6129 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7996 - f1_score: 0.6842 - loss: 0.6199 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8122 - f1_score: 0.6921 - loss: 0.6282 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8100 - f1_score: 0.7061 - loss: 0.6070 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8192 - f1_score: 0.7031 - loss: 0.6072 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8182 - f1_score: 0.6993 - loss: 0.6266 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8060 - f1_score: 0.6952 - loss: 0.6159 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8267 - f1_score: 0.7074 - loss: 0.6132 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8215 - f1_score: 0.7018 - loss: 0.6123 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8149 - f1_score: 0.6867 - loss: 0.6185 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7949 - f1_score: 0.6961 - loss: 0.6086 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x792a9e891a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6567843426106171, 0.9039301310043668, 0.40963855421686746)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - accuracy: 0.7382 - f1_score: 0.5169 - loss: 0.8158 - val_accuracy: 0.8763 - val_f1_score: 0.6233 - val_loss: 0.6507 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8191 - f1_score: 0.6091 - loss: 0.7056 - val_accuracy: 0.8351 - val_f1_score: 0.7337 - val_loss: 0.6258 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7898 - f1_score: 0.6659 - loss: 0.6697 - val_accuracy: 0.8505 - val_f1_score: 0.7104 - val_loss: 0.6109 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8099 - f1_score: 0.6609 - loss: 0.6804 - val_accuracy: 0.7732 - val_f1_score: 0.7248 - val_loss: 0.6271 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7731 - f1_score: 0.6572 - loss: 0.6771 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.5988 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8148 - f1_score: 0.6772 - loss: 0.6684 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6231 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8159 - f1_score: 0.6571 - loss: 0.6677 - val_accuracy: 0.8454 - val_f1_score: 0.7112 - val_loss: 0.6109 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8209 - f1_score: 0.6606 - loss: 0.6573 - val_accuracy: 0.7784 - val_f1_score: 0.7395 - val_loss: 0.6457 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7562 - f1_score: 0.6792 - loss: 0.6663 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6074 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8142 - f1_score: 0.6789 - loss: 0.6538 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6273 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8340 - f1_score: 0.6826 - loss: 0.6393 - val_accuracy: 0.8351 - val_f1_score: 0.7044 - val_loss: 0.6539 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8137 - f1_score: 0.6777 - loss: 0.6717 - val_accuracy: 0.7835 - val_f1_score: 0.7428 - val_loss: 0.6206 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7725 - f1_score: 0.6707 - loss: 0.6630 - val_accuracy: 0.8402 - val_f1_score: 0.7169 - val_loss: 0.5996 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8184 - f1_score: 0.6570 - loss: 0.7070 - val_accuracy: 0.8041 - val_f1_score: 0.7499 - val_loss: 0.6128 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8056 - f1_score: 0.7042 - loss: 0.6355\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8037 - f1_score: 0.6975 - loss: 0.6399 - val_accuracy: 0.8196 - val_f1_score: 0.7465 - val_loss: 0.6255 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8144 - f1_score: 0.7012 - loss: 0.6367 - val_accuracy: 0.8299 - val_f1_score: 0.7395 - val_loss: 0.6047 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7880 - f1_score: 0.6705 - loss: 0.6395 - val_accuracy: 0.8247 - val_f1_score: 0.7403 - val_loss: 0.6084 - learning_rate: 1.0000e-03\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8081 - f1_score: 0.6713 - loss: 0.6298 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6091 - learning_rate: 1.0000e-03\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7963 - f1_score: 0.6840 - loss: 0.6307 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8098 - f1_score: 0.6823 - loss: 0.6286 - val_accuracy: 0.8402 - val_f1_score: 0.7404 - val_loss: 0.6047 - learning_rate: 1.0000e-03\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8088 - f1_score: 0.6658 - loss: 0.6330 - val_accuracy: 0.8351 - val_f1_score: 0.7363 - val_loss: 0.6072 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7971 - f1_score: 0.6636 - loss: 0.6442 - val_accuracy: 0.8505 - val_f1_score: 0.7386 - val_loss: 0.6045 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8294 - f1_score: 0.6969 - loss: 0.6151 - val_accuracy: 0.8196 - val_f1_score: 0.7353 - val_loss: 0.6058 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8207 - f1_score: 0.6811 - loss: 0.6342 - val_accuracy: 0.8505 - val_f1_score: 0.7386 - val_loss: 0.6035 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8247 - f1_score: 0.6682 - loss: 0.6350\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8212 - f1_score: 0.6710 - loss: 0.6347 - val_accuracy: 0.8402 - val_f1_score: 0.7354 - val_loss: 0.6040 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8153 - f1_score: 0.6818 - loss: 0.6083 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6040 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7985 - f1_score: 0.6686 - loss: 0.6226 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7993 - f1_score: 0.6765 - loss: 0.6432 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6040 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8136 - f1_score: 0.6864 - loss: 0.6350 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6035 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8054 - f1_score: 0.6833 - loss: 0.6242 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6029 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8212 - f1_score: 0.7053 - loss: 0.6214 - val_accuracy: 0.8351 - val_f1_score: 0.7363 - val_loss: 0.6028 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7890 - f1_score: 0.6620 - loss: 0.6364 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8150 - f1_score: 0.6764 - loss: 0.6330 - val_accuracy: 0.8402 - val_f1_score: 0.7354 - val_loss: 0.6036 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8105 - f1_score: 0.6681 - loss: 0.6649 - val_accuracy: 0.8351 - val_f1_score: 0.7363 - val_loss: 0.6034 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8016 - f1_score: 0.6588 - loss: 0.6414\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8021 - f1_score: 0.6606 - loss: 0.6403 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6027 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8151 - f1_score: 0.6953 - loss: 0.6268 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6028 - learning_rate: 1.0000e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7907 - f1_score: 0.6759 - loss: 0.6408 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6029 - learning_rate: 1.0000e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8172 - f1_score: 0.6894 - loss: 0.6246 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6029 - learning_rate: 1.0000e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8148 - f1_score: 0.6890 - loss: 0.6375 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6029 - learning_rate: 1.0000e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8128 - f1_score: 0.6825 - loss: 0.6265 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8120 - f1_score: 0.6865 - loss: 0.6299 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8005 - f1_score: 0.6748 - loss: 0.6239 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6029 - learning_rate: 1.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8081 - f1_score: 0.6820 - loss: 0.6252 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8019 - f1_score: 0.6951 - loss: 0.6179 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8098 - f1_score: 0.6980 - loss: 0.6264\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8098 - f1_score: 0.6969 - loss: 0.6265 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8027 - f1_score: 0.6900 - loss: 0.6077 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8348 - f1_score: 0.6988 - loss: 0.6288 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7901 - f1_score: 0.6874 - loss: 0.6159 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8004 - f1_score: 0.6689 - loss: 0.6216 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8098 - f1_score: 0.6880 - loss: 0.6152 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8303 - f1_score: 0.6979 - loss: 0.6199 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8055 - f1_score: 0.6781 - loss: 0.6253 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8150 - f1_score: 0.6960 - loss: 0.6234 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8217 - f1_score: 0.6930 - loss: 0.6253 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8051 - f1_score: 0.6834 - loss: 0.6301 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8079 - f1_score: 0.6720 - loss: 0.6400 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8080 - f1_score: 0.6826 - loss: 0.6143 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8393 - f1_score: 0.6633 - loss: 0.6509 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7911 - f1_score: 0.6691 - loss: 0.6110 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8321 - f1_score: 0.6727 - loss: 0.6318 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7978 - f1_score: 0.6785 - loss: 0.6215 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8093 - f1_score: 0.6833 - loss: 0.6234 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8212 - f1_score: 0.6850 - loss: 0.6312 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8179 - f1_score: 0.6542 - loss: 0.6536 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8270 - f1_score: 0.6878 - loss: 0.6458 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8226 - f1_score: 0.6917 - loss: 0.6343 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8023 - f1_score: 0.6869 - loss: 0.6278 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8005 - f1_score: 0.6821 - loss: 0.6380 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8114 - f1_score: 0.6918 - loss: 0.6302 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8121 - f1_score: 0.6786 - loss: 0.6321 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8327 - f1_score: 0.6926 - loss: 0.6421 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8146 - f1_score: 0.6725 - loss: 0.6331 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8072 - f1_score: 0.6975 - loss: 0.6228 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8041 - f1_score: 0.6847 - loss: 0.6130 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8026 - f1_score: 0.6524 - loss: 0.6330 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7788 - f1_score: 0.6816 - loss: 0.6128 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7975 - f1_score: 0.6706 - loss: 0.6309 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8065 - f1_score: 0.6692 - loss: 0.6442 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8150 - f1_score: 0.6899 - loss: 0.6270 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8245 - f1_score: 0.6919 - loss: 0.6193 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8371 - f1_score: 0.6820 - loss: 0.6227 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8212 - f1_score: 0.6948 - loss: 0.6242 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8145 - f1_score: 0.6768 - loss: 0.6160 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7905 - f1_score: 0.6882 - loss: 0.6253 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8272 - f1_score: 0.6833 - loss: 0.6256 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8060 - f1_score: 0.7015 - loss: 0.6218 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8113 - f1_score: 0.6793 - loss: 0.6345 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8228 - f1_score: 0.7010 - loss: 0.6223 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8212 - f1_score: 0.6824 - loss: 0.6219 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8021 - f1_score: 0.6778 - loss: 0.6455 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8027 - f1_score: 0.6941 - loss: 0.6010 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8103 - f1_score: 0.6869 - loss: 0.6151 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7897 - f1_score: 0.6651 - loss: 0.6344 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8105 - f1_score: 0.6805 - loss: 0.6346 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7979 - f1_score: 0.6811 - loss: 0.6260 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8121 - f1_score: 0.6829 - loss: 0.6298 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8081 - f1_score: 0.6808 - loss: 0.6359 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8017 - f1_score: 0.6862 - loss: 0.6046 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8211 - f1_score: 0.6914 - loss: 0.6189 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7915 - f1_score: 0.6704 - loss: 0.6267 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x792a9efcde40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.667784896332543, 0.8937093275488069, 0.4418604651162791)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.8521 - f1_score: 0.5231 - loss: 0.7562 - val_accuracy: 0.8763 - val_f1_score: 0.6711 - val_loss: 0.6895 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8433 - f1_score: 0.6010 - loss: 0.7232 - val_accuracy: 0.8196 - val_f1_score: 0.7184 - val_loss: 0.6468 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8003 - f1_score: 0.6475 - loss: 0.6922 - val_accuracy: 0.7216 - val_f1_score: 0.7170 - val_loss: 0.6597 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8097 - f1_score: 0.6644 - loss: 0.6929 - val_accuracy: 0.7371 - val_f1_score: 0.7112 - val_loss: 0.6542 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7647 - f1_score: 0.6615 - loss: 0.6697 - val_accuracy: 0.8505 - val_f1_score: 0.7065 - val_loss: 0.6070 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8193 - f1_score: 0.6741 - loss: 0.6688 - val_accuracy: 0.8402 - val_f1_score: 0.7035 - val_loss: 0.6177 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8275 - f1_score: 0.6698 - loss: 0.6827 - val_accuracy: 0.8505 - val_f1_score: 0.7188 - val_loss: 0.6575 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8083 - f1_score: 0.6926 - loss: 0.6560 - val_accuracy: 0.7010 - val_f1_score: 0.7078 - val_loss: 0.6661 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7817 - f1_score: 0.6748 - loss: 0.6716 - val_accuracy: 0.8454 - val_f1_score: 0.7074 - val_loss: 0.6144 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8203 - f1_score: 0.6684 - loss: 0.6579 - val_accuracy: 0.8093 - val_f1_score: 0.7330 - val_loss: 0.6030 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7922 - f1_score: 0.6934 - loss: 0.6943 - val_accuracy: 0.7835 - val_f1_score: 0.7437 - val_loss: 0.6302 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8114 - f1_score: 0.6608 - loss: 0.6770 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.5900 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.6775 - loss: 0.6538 - val_accuracy: 0.7990 - val_f1_score: 0.7533 - val_loss: 0.6100 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7715 - f1_score: 0.6774 - loss: 0.6579 - val_accuracy: 0.8402 - val_f1_score: 0.7121 - val_loss: 0.5994 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7857 - f1_score: 0.6626 - loss: 0.6491 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6074 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8361 - f1_score: 0.6900 - loss: 0.6531 - val_accuracy: 0.8196 - val_f1_score: 0.7389 - val_loss: 0.6098 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8018 - f1_score: 0.7066 - loss: 0.6411 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.6092 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8126 - f1_score: 0.6800 - loss: 0.6194 - val_accuracy: 0.8247 - val_f1_score: 0.7343 - val_loss: 0.6240 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8190 - f1_score: 0.6696 - loss: 0.6649 - val_accuracy: 0.8351 - val_f1_score: 0.7264 - val_loss: 0.6172 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7735 - f1_score: 0.6858 - loss: 0.6470 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5938 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8300 - f1_score: 0.6820 - loss: 0.6348 - val_accuracy: 0.8196 - val_f1_score: 0.7516 - val_loss: 0.6347 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8065 - f1_score: 0.6782 - loss: 0.6196\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8032 - f1_score: 0.6805 - loss: 0.6230 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6078 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8062 - f1_score: 0.6818 - loss: 0.6126 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6021 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8042 - f1_score: 0.7083 - loss: 0.6064 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6046 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8191 - f1_score: 0.6994 - loss: 0.6206 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6021 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8187 - f1_score: 0.7097 - loss: 0.6074 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6041 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8078 - f1_score: 0.6900 - loss: 0.6230 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6038 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8003 - f1_score: 0.6884 - loss: 0.6210 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6017 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8059 - f1_score: 0.6939 - loss: 0.6011 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6038 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8177 - f1_score: 0.6962 - loss: 0.6058 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6042 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7846 - f1_score: 0.6947 - loss: 0.6244 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6063 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7936 - f1_score: 0.6828 - loss: 0.6193\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7937 - f1_score: 0.6870 - loss: 0.6187 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6034 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8037 - f1_score: 0.6852 - loss: 0.6236 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6033 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7980 - f1_score: 0.6957 - loss: 0.6176 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8111 - f1_score: 0.6816 - loss: 0.6110 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6036 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8261 - f1_score: 0.7143 - loss: 0.5935 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6032 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7925 - f1_score: 0.7071 - loss: 0.5870 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6041 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7929 - f1_score: 0.6983 - loss: 0.6179 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6049 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8012 - f1_score: 0.7093 - loss: 0.5979 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6054 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8124 - f1_score: 0.7097 - loss: 0.6073 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8072 - f1_score: 0.6936 - loss: 0.6225 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6050 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7992 - f1_score: 0.6897 - loss: 0.6120\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7995 - f1_score: 0.6902 - loss: 0.6121 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6054 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8065 - f1_score: 0.6926 - loss: 0.6158 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6054 - learning_rate: 1.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8007 - f1_score: 0.7178 - loss: 0.5891 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6054 - learning_rate: 1.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7990 - f1_score: 0.6939 - loss: 0.6109 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6054 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7941 - f1_score: 0.6979 - loss: 0.6019 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8108 - f1_score: 0.6992 - loss: 0.6112 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8134 - f1_score: 0.7082 - loss: 0.6156 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8159 - f1_score: 0.7055 - loss: 0.5915 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8012 - f1_score: 0.6750 - loss: 0.6369 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7968 - f1_score: 0.6856 - loss: 0.6154 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8136 - f1_score: 0.7089 - loss: 0.6094\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8132 - f1_score: 0.7084 - loss: 0.6095 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8170 - f1_score: 0.7035 - loss: 0.5869 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7934 - f1_score: 0.6694 - loss: 0.6405 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8129 - f1_score: 0.6976 - loss: 0.6162 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8106 - f1_score: 0.7091 - loss: 0.6149 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7971 - f1_score: 0.6897 - loss: 0.6190 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8059 - f1_score: 0.6926 - loss: 0.6234 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7980 - f1_score: 0.6890 - loss: 0.6011 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7941 - f1_score: 0.6985 - loss: 0.6192 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8146 - f1_score: 0.7028 - loss: 0.5922 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8064 - f1_score: 0.7050 - loss: 0.6150 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7886 - f1_score: 0.6967 - loss: 0.6033 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7922 - f1_score: 0.7064 - loss: 0.6119 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8042 - f1_score: 0.6858 - loss: 0.6186 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7915 - f1_score: 0.6812 - loss: 0.6272 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7955 - f1_score: 0.6942 - loss: 0.6127 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8109 - f1_score: 0.7031 - loss: 0.6046 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8032 - f1_score: 0.6974 - loss: 0.6321 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8053 - f1_score: 0.6940 - loss: 0.6200 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8075 - f1_score: 0.6991 - loss: 0.6126 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8010 - f1_score: 0.6937 - loss: 0.6194 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8017 - f1_score: 0.7040 - loss: 0.6182 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7911 - f1_score: 0.6994 - loss: 0.6049 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8058 - f1_score: 0.7127 - loss: 0.5903 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8035 - f1_score: 0.6777 - loss: 0.6148 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7908 - f1_score: 0.6972 - loss: 0.5965 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8070 - f1_score: 0.6838 - loss: 0.6265 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7921 - f1_score: 0.6974 - loss: 0.6155 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7919 - f1_score: 0.6970 - loss: 0.6223 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7926 - f1_score: 0.7082 - loss: 0.5951 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8216 - f1_score: 0.7044 - loss: 0.6065 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7706 - f1_score: 0.7039 - loss: 0.5990 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7836 - f1_score: 0.6834 - loss: 0.6124 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8123 - f1_score: 0.7038 - loss: 0.6034 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8232 - f1_score: 0.7187 - loss: 0.5927 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7791 - f1_score: 0.6647 - loss: 0.6530 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7972 - f1_score: 0.6909 - loss: 0.5915 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8160 - f1_score: 0.6887 - loss: 0.6035 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8208 - f1_score: 0.7079 - loss: 0.6024 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8033 - f1_score: 0.6910 - loss: 0.6149 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7979 - f1_score: 0.6867 - loss: 0.6068 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8050 - f1_score: 0.6817 - loss: 0.6269 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8038 - f1_score: 0.6768 - loss: 0.6370 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7804 - f1_score: 0.7000 - loss: 0.6058 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7733 - f1_score: 0.6784 - loss: 0.6233 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8067 - f1_score: 0.7060 - loss: 0.6080 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7940 - f1_score: 0.6920 - loss: 0.6201 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8034 - f1_score: 0.6989 - loss: 0.6105 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7877 - f1_score: 0.7031 - loss: 0.6137 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6051 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6648049118637354, 0.8932461873638344, 0.43636363636363634)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - accuracy: 0.8080 - f1_score: 0.5615 - loss: 0.7871 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.7350 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8638 - f1_score: 0.5624 - loss: 0.7286 - val_accuracy: 0.4330 - val_f1_score: 0.5504 - val_loss: 0.7764 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7277 - f1_score: 0.6525 - loss: 0.7202 - val_accuracy: 0.8557 - val_f1_score: 0.6922 - val_loss: 0.6270 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8080 - f1_score: 0.6334 - loss: 0.6796 - val_accuracy: 0.8454 - val_f1_score: 0.7148 - val_loss: 0.6347 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7717 - f1_score: 0.6653 - loss: 0.6913 - val_accuracy: 0.8299 - val_f1_score: 0.7345 - val_loss: 0.6836 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8373 - f1_score: 0.6807 - loss: 0.6964 - val_accuracy: 0.8454 - val_f1_score: 0.7100 - val_loss: 0.6146 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8039 - f1_score: 0.6600 - loss: 0.6797 - val_accuracy: 0.7990 - val_f1_score: 0.7433 - val_loss: 0.6726 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7986 - f1_score: 0.6642 - loss: 0.6764 - val_accuracy: 0.8505 - val_f1_score: 0.7065 - val_loss: 0.6319 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7946 - f1_score: 0.6505 - loss: 0.6703 - val_accuracy: 0.8454 - val_f1_score: 0.7074 - val_loss: 0.6353 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8095 - f1_score: 0.6417 - loss: 0.6733 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6113 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8306 - f1_score: 0.6784 - loss: 0.6585 - val_accuracy: 0.7784 - val_f1_score: 0.7365 - val_loss: 0.6186 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7683 - f1_score: 0.6724 - loss: 0.6519 - val_accuracy: 0.8196 - val_f1_score: 0.7412 - val_loss: 0.6383 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8027 - f1_score: 0.6816 - loss: 0.6491 - val_accuracy: 0.8454 - val_f1_score: 0.7328 - val_loss: 0.6671 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8259 - f1_score: 0.6773 - loss: 0.6704 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.6091 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8060 - f1_score: 0.6666 - loss: 0.6605 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.6054 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8060 - f1_score: 0.6635 - loss: 0.6788 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6006 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7965 - f1_score: 0.6758 - loss: 0.6438 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6375 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8012 - f1_score: 0.6775 - loss: 0.6506 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6084 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8082 - f1_score: 0.6900 - loss: 0.6468 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6174 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8328 - f1_score: 0.7008 - loss: 0.6267 - val_accuracy: 0.8660 - val_f1_score: 0.6958 - val_loss: 0.6361 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8161 - f1_score: 0.6682 - loss: 0.6888 - val_accuracy: 0.8505 - val_f1_score: 0.7113 - val_loss: 0.6063 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8319 - f1_score: 0.6733 - loss: 0.6873 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6066 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7901 - f1_score: 0.6648 - loss: 0.6757 - val_accuracy: 0.7423 - val_f1_score: 0.7254 - val_loss: 0.6322 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7788 - f1_score: 0.6795 - loss: 0.6807 - val_accuracy: 0.8247 - val_f1_score: 0.7456 - val_loss: 0.5925 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7915 - f1_score: 0.6942 - loss: 0.6554 - val_accuracy: 0.8557 - val_f1_score: 0.6926 - val_loss: 0.6246 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8177 - f1_score: 0.6824 - loss: 0.6385 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.5977 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8292 - f1_score: 0.6960 - loss: 0.6199 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6001 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8070 - f1_score: 0.6846 - loss: 0.6089 - val_accuracy: 0.7526 - val_f1_score: 0.7406 - val_loss: 0.6386 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7795 - f1_score: 0.6770 - loss: 0.6393 - val_accuracy: 0.8454 - val_f1_score: 0.7421 - val_loss: 0.6022 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8112 - f1_score: 0.6941 - loss: 0.6246 - val_accuracy: 0.8505 - val_f1_score: 0.7237 - val_loss: 0.5976 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8069 - f1_score: 0.6779 - loss: 0.6268 - val_accuracy: 0.8299 - val_f1_score: 0.7574 - val_loss: 0.6122 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8073 - f1_score: 0.6881 - loss: 0.6297 - val_accuracy: 0.8454 - val_f1_score: 0.7574 - val_loss: 0.6244 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8165 - f1_score: 0.6940 - loss: 0.6268 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6051 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7839 - f1_score: 0.6992 - loss: 0.6080\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7879 - f1_score: 0.6990 - loss: 0.6109 - val_accuracy: 0.8247 - val_f1_score: 0.7264 - val_loss: 0.6038 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8328 - f1_score: 0.6817 - loss: 0.6185 - val_accuracy: 0.8351 - val_f1_score: 0.7616 - val_loss: 0.6073 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8129 - f1_score: 0.6772 - loss: 0.6252 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6100 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8210 - f1_score: 0.6926 - loss: 0.6098 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6062 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8360 - f1_score: 0.7042 - loss: 0.6139 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6068 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8172 - f1_score: 0.7127 - loss: 0.6000 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6110 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8371 - f1_score: 0.7090 - loss: 0.6028 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6083 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8132 - f1_score: 0.7040 - loss: 0.6335 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6100 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8088 - f1_score: 0.6897 - loss: 0.6437 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6123 - learning_rate: 1.0000e-03\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8431 - f1_score: 0.6985 - loss: 0.6223 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6116 - learning_rate: 1.0000e-03\n",
            "Epoch 44/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8260 - f1_score: 0.7081 - loss: 0.5938\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8245 - f1_score: 0.7065 - loss: 0.5965 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6131 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8228 - f1_score: 0.7054 - loss: 0.6035 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6135 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8201 - f1_score: 0.6934 - loss: 0.5933 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6131 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8116 - f1_score: 0.6939 - loss: 0.6250 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6133 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8249 - f1_score: 0.7001 - loss: 0.6086 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6131 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8024 - f1_score: 0.6747 - loss: 0.6349 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6133 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8081 - f1_score: 0.6880 - loss: 0.6067 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6127 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8220 - f1_score: 0.6843 - loss: 0.6239 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6130 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8265 - f1_score: 0.7150 - loss: 0.6117 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8349 - f1_score: 0.7056 - loss: 0.6176 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8207 - f1_score: 0.7053 - loss: 0.6114\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8204 - f1_score: 0.7047 - loss: 0.6113 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8243 - f1_score: 0.6918 - loss: 0.6361 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8235 - f1_score: 0.7192 - loss: 0.5889 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8176 - f1_score: 0.6884 - loss: 0.6245 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8090 - f1_score: 0.6768 - loss: 0.6240 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8046 - f1_score: 0.6809 - loss: 0.6105 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8271 - f1_score: 0.7046 - loss: 0.6026 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8263 - f1_score: 0.6922 - loss: 0.6371 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8278 - f1_score: 0.7168 - loss: 0.6125 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7990 - f1_score: 0.6981 - loss: 0.6116 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8127 - f1_score: 0.6922 - loss: 0.6135\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8138 - f1_score: 0.6928 - loss: 0.6130 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8091 - f1_score: 0.6703 - loss: 0.6263 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8082 - f1_score: 0.6901 - loss: 0.6116 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8161 - f1_score: 0.6888 - loss: 0.6139 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8130 - f1_score: 0.6879 - loss: 0.6074 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8351 - f1_score: 0.7066 - loss: 0.5851 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7952 - f1_score: 0.7048 - loss: 0.5935 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8319 - f1_score: 0.7114 - loss: 0.6078 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7945 - f1_score: 0.6762 - loss: 0.6234 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8205 - f1_score: 0.7134 - loss: 0.5962 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8048 - f1_score: 0.6876 - loss: 0.6212 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8117 - f1_score: 0.7159 - loss: 0.5869 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6124 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8243 - f1_score: 0.7000 - loss: 0.6130 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8181 - f1_score: 0.6847 - loss: 0.6243 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8283 - f1_score: 0.6897 - loss: 0.5990 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8164 - f1_score: 0.6925 - loss: 0.6266 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8135 - f1_score: 0.6965 - loss: 0.6118 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8143 - f1_score: 0.6869 - loss: 0.6102 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8401 - f1_score: 0.7197 - loss: 0.6015 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8344 - f1_score: 0.6933 - loss: 0.5985 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8357 - f1_score: 0.6998 - loss: 0.6044 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8261 - f1_score: 0.7051 - loss: 0.5833 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8263 - f1_score: 0.7026 - loss: 0.6165 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8199 - f1_score: 0.6938 - loss: 0.6040 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8217 - f1_score: 0.7179 - loss: 0.6022 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8338 - f1_score: 0.7105 - loss: 0.6164 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8233 - f1_score: 0.7044 - loss: 0.6172 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7958 - f1_score: 0.6885 - loss: 0.6408 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8222 - f1_score: 0.6935 - loss: 0.6258 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8129 - f1_score: 0.6863 - loss: 0.6126 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8368 - f1_score: 0.7048 - loss: 0.6175 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8123 - f1_score: 0.6846 - loss: 0.6294 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.6783 - loss: 0.6200 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8188 - f1_score: 0.7055 - loss: 0.6082 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8089 - f1_score: 0.6930 - loss: 0.6186 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8098 - f1_score: 0.6928 - loss: 0.6150 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8168 - f1_score: 0.6896 - loss: 0.6240 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6125 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6609088079676315, 0.8932461873638344, 0.42857142857142855)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.8255 - f1_score: 0.5202 - loss: 0.7934 - val_accuracy: 0.8660 - val_f1_score: 0.6252 - val_loss: 0.6695 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8619 - f1_score: 0.5829 - loss: 0.7239 - val_accuracy: 0.8711 - val_f1_score: 0.6812 - val_loss: 0.6390 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8530 - f1_score: 0.6192 - loss: 0.7027 - val_accuracy: 0.8557 - val_f1_score: 0.7180 - val_loss: 0.6155 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8098 - f1_score: 0.6445 - loss: 0.6858 - val_accuracy: 0.8454 - val_f1_score: 0.6804 - val_loss: 0.6158 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8100 - f1_score: 0.6533 - loss: 0.6979 - val_accuracy: 0.7938 - val_f1_score: 0.7416 - val_loss: 0.6190 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8283 - f1_score: 0.6666 - loss: 0.6653 - val_accuracy: 0.8041 - val_f1_score: 0.7499 - val_loss: 0.6337 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7703 - f1_score: 0.6607 - loss: 0.6859 - val_accuracy: 0.8402 - val_f1_score: 0.7035 - val_loss: 0.6100 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8669 - f1_score: 0.6869 - loss: 0.6561 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.5999 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7977 - f1_score: 0.6703 - loss: 0.6585 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.6042 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7723 - f1_score: 0.6748 - loss: 0.6724 - val_accuracy: 0.8454 - val_f1_score: 0.6896 - val_loss: 0.6178 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8395 - f1_score: 0.6770 - loss: 0.6534 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.6053 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8188 - f1_score: 0.6889 - loss: 0.6368 - val_accuracy: 0.8505 - val_f1_score: 0.7200 - val_loss: 0.5922 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8175 - f1_score: 0.6837 - loss: 0.6553 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.5925 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8127 - f1_score: 0.6750 - loss: 0.6508 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.6063 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8111 - f1_score: 0.6881 - loss: 0.6312 - val_accuracy: 0.8402 - val_f1_score: 0.7206 - val_loss: 0.5926 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8065 - f1_score: 0.6855 - loss: 0.6434 - val_accuracy: 0.8402 - val_f1_score: 0.7083 - val_loss: 0.6060 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8322 - f1_score: 0.6993 - loss: 0.6319 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6055 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7990 - f1_score: 0.6837 - loss: 0.6657 - val_accuracy: 0.8351 - val_f1_score: 0.7387 - val_loss: 0.5947 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8036 - f1_score: 0.7020 - loss: 0.6319 - val_accuracy: 0.8299 - val_f1_score: 0.7304 - val_loss: 0.6144 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8004 - f1_score: 0.6597 - loss: 0.6571 - val_accuracy: 0.8093 - val_f1_score: 0.7382 - val_loss: 0.6275 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7792 - f1_score: 0.6963 - loss: 0.6417 - val_accuracy: 0.8454 - val_f1_score: 0.7471 - val_loss: 0.5937 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7910 - f1_score: 0.7021 - loss: 0.6502\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7924 - f1_score: 0.7010 - loss: 0.6497 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.5970 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7913 - f1_score: 0.7014 - loss: 0.6392 - val_accuracy: 0.8402 - val_f1_score: 0.7429 - val_loss: 0.5995 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8223 - f1_score: 0.7003 - loss: 0.6190 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6044 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8037 - f1_score: 0.6876 - loss: 0.6371 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6049 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7907 - f1_score: 0.6958 - loss: 0.6151 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8107 - f1_score: 0.6930 - loss: 0.6105 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6059 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8001 - f1_score: 0.6715 - loss: 0.6377 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6026 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8077 - f1_score: 0.6815 - loss: 0.6192 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6054 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8141 - f1_score: 0.6965 - loss: 0.6118 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6036 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7902 - f1_score: 0.6944 - loss: 0.6340 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6038 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8212 - f1_score: 0.7100 - loss: 0.6154\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8202 - f1_score: 0.7060 - loss: 0.6177 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6088 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7753 - f1_score: 0.7097 - loss: 0.6147 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6088 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7910 - f1_score: 0.7032 - loss: 0.6223 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6074 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7867 - f1_score: 0.6771 - loss: 0.6221 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6072 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8079 - f1_score: 0.7133 - loss: 0.5991 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6067 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8168 - f1_score: 0.7170 - loss: 0.6138 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6060 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8097 - f1_score: 0.6928 - loss: 0.6342 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6064 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7689 - f1_score: 0.6869 - loss: 0.6544 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6063 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8149 - f1_score: 0.7098 - loss: 0.5978 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6056 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8073 - f1_score: 0.7015 - loss: 0.6300 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6066 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8200 - f1_score: 0.6904 - loss: 0.6001\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8162 - f1_score: 0.6926 - loss: 0.6046 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6063 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8060 - f1_score: 0.7016 - loss: 0.6103 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6063 - learning_rate: 1.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8117 - f1_score: 0.6772 - loss: 0.6348 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6063 - learning_rate: 1.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7915 - f1_score: 0.6958 - loss: 0.6179 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8107 - f1_score: 0.7102 - loss: 0.6144 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8166 - f1_score: 0.6954 - loss: 0.6291 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7925 - f1_score: 0.6998 - loss: 0.6132 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7831 - f1_score: 0.7070 - loss: 0.5962 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8044 - f1_score: 0.7094 - loss: 0.6167 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8063 - f1_score: 0.6873 - loss: 0.6282 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8329 - f1_score: 0.7191 - loss: 0.6133\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8254 - f1_score: 0.7146 - loss: 0.6134 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7982 - f1_score: 0.7041 - loss: 0.6404 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8008 - f1_score: 0.6966 - loss: 0.6117 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8134 - f1_score: 0.6995 - loss: 0.6161 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8084 - f1_score: 0.7039 - loss: 0.6236 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7865 - f1_score: 0.6852 - loss: 0.6282 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.7045 - loss: 0.6132 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7883 - f1_score: 0.7044 - loss: 0.6444 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8132 - f1_score: 0.7070 - loss: 0.6221 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8022 - f1_score: 0.7136 - loss: 0.6046 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8089 - f1_score: 0.7155 - loss: 0.6168 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7892 - f1_score: 0.7003 - loss: 0.6164 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7896 - f1_score: 0.6891 - loss: 0.6291 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7921 - f1_score: 0.7000 - loss: 0.6225 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7972 - f1_score: 0.6885 - loss: 0.6112 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7971 - f1_score: 0.7026 - loss: 0.6147 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7934 - f1_score: 0.7109 - loss: 0.6170 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7992 - f1_score: 0.7194 - loss: 0.5914 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8249 - f1_score: 0.7216 - loss: 0.6098 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8260 - f1_score: 0.6955 - loss: 0.6130 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7987 - f1_score: 0.6960 - loss: 0.6285 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7999 - f1_score: 0.7009 - loss: 0.6165 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7892 - f1_score: 0.6744 - loss: 0.6255 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8003 - f1_score: 0.6942 - loss: 0.6271 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7889 - f1_score: 0.6947 - loss: 0.6167 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8036 - f1_score: 0.6927 - loss: 0.6306 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7944 - f1_score: 0.7032 - loss: 0.6177 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7940 - f1_score: 0.6798 - loss: 0.6289 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7978 - f1_score: 0.6897 - loss: 0.6462 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7902 - f1_score: 0.6853 - loss: 0.6174 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7955 - f1_score: 0.6881 - loss: 0.6165 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6061 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7820 - f1_score: 0.6904 - loss: 0.6308 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7972 - f1_score: 0.7011 - loss: 0.6226 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8057 - f1_score: 0.7004 - loss: 0.6096 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7848 - f1_score: 0.6885 - loss: 0.6237 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8043 - f1_score: 0.7098 - loss: 0.6036 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7916 - f1_score: 0.6868 - loss: 0.6030 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8004 - f1_score: 0.6853 - loss: 0.6256 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8239 - f1_score: 0.7218 - loss: 0.6127 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8077 - f1_score: 0.7029 - loss: 0.6120 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7936 - f1_score: 0.6919 - loss: 0.6231 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7995 - f1_score: 0.6916 - loss: 0.6107 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7934 - f1_score: 0.7189 - loss: 0.6050 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7963 - f1_score: 0.6911 - loss: 0.6154 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8112 - f1_score: 0.7181 - loss: 0.6087 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7989 - f1_score: 0.6855 - loss: 0.6169 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7999 - f1_score: 0.7130 - loss: 0.6038 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8062 - f1_score: 0.6984 - loss: 0.6308 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7963 - f1_score: 0.6886 - loss: 0.6260 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6062 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.669134757774487, 0.896551724137931, 0.44171779141104295)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - accuracy: 0.7128 - f1_score: 0.5752 - loss: 0.7760 - val_accuracy: 0.8763 - val_f1_score: 0.6453 - val_loss: 0.6910 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8355 - f1_score: 0.6181 - loss: 0.7152 - val_accuracy: 0.8454 - val_f1_score: 0.7183 - val_loss: 0.6493 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8232 - f1_score: 0.6363 - loss: 0.6974 - val_accuracy: 0.8505 - val_f1_score: 0.7188 - val_loss: 0.6239 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8363 - f1_score: 0.6707 - loss: 0.6613 - val_accuracy: 0.8505 - val_f1_score: 0.7065 - val_loss: 0.6200 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8583 - f1_score: 0.6726 - loss: 0.6712 - val_accuracy: 0.8454 - val_f1_score: 0.7436 - val_loss: 0.6067 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8014 - f1_score: 0.6746 - loss: 0.6738 - val_accuracy: 0.8247 - val_f1_score: 0.7343 - val_loss: 0.6006 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7899 - f1_score: 0.6694 - loss: 0.6803 - val_accuracy: 0.8557 - val_f1_score: 0.6589 - val_loss: 0.6587 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8257 - f1_score: 0.6388 - loss: 0.6734 - val_accuracy: 0.8454 - val_f1_score: 0.6943 - val_loss: 0.6109 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8125 - f1_score: 0.6864 - loss: 0.6387 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.6516 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8156 - f1_score: 0.6909 - loss: 0.6429 - val_accuracy: 0.8196 - val_f1_score: 0.7439 - val_loss: 0.6180 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8186 - f1_score: 0.6848 - loss: 0.6482 - val_accuracy: 0.8144 - val_f1_score: 0.7551 - val_loss: 0.6286 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8146 - f1_score: 0.6778 - loss: 0.6618 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5968 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8162 - f1_score: 0.6699 - loss: 0.6443 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6169 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7910 - f1_score: 0.6807 - loss: 0.6530 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.5973 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7948 - f1_score: 0.6705 - loss: 0.6591 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6065 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8290 - f1_score: 0.6878 - loss: 0.6404 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5968 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8214 - f1_score: 0.6728 - loss: 0.6585 - val_accuracy: 0.8041 - val_f1_score: 0.7520 - val_loss: 0.6268 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7898 - f1_score: 0.6983 - loss: 0.6346 - val_accuracy: 0.8351 - val_f1_score: 0.7358 - val_loss: 0.5922 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8220 - f1_score: 0.6945 - loss: 0.6453 - val_accuracy: 0.8351 - val_f1_score: 0.7092 - val_loss: 0.5962 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8380 - f1_score: 0.6740 - loss: 0.6478 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5945 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8019 - f1_score: 0.6531 - loss: 0.6581 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6159 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8142 - f1_score: 0.6813 - loss: 0.6351 - val_accuracy: 0.8041 - val_f1_score: 0.7468 - val_loss: 0.6792 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7877 - f1_score: 0.7002 - loss: 0.6368 - val_accuracy: 0.8196 - val_f1_score: 0.7516 - val_loss: 0.6632 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8125 - f1_score: 0.6936 - loss: 0.6495 - val_accuracy: 0.8299 - val_f1_score: 0.7345 - val_loss: 0.6346 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8391 - f1_score: 0.6916 - loss: 0.6259 - val_accuracy: 0.8299 - val_f1_score: 0.7574 - val_loss: 0.6112 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8070 - f1_score: 0.7076 - loss: 0.6457 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6222 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7938 - f1_score: 0.6903 - loss: 0.6210 - val_accuracy: 0.8299 - val_f1_score: 0.7191 - val_loss: 0.6190 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8086 - f1_score: 0.6928 - loss: 0.6217\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8092 - f1_score: 0.6934 - loss: 0.6223 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6043 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8255 - f1_score: 0.6858 - loss: 0.6300 - val_accuracy: 0.8351 - val_f1_score: 0.7489 - val_loss: 0.6170 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8118 - f1_score: 0.6936 - loss: 0.6175 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6101 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8152 - f1_score: 0.7117 - loss: 0.6011 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6170 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8122 - f1_score: 0.6919 - loss: 0.6076 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6133 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8149 - f1_score: 0.7055 - loss: 0.6095 - val_accuracy: 0.8299 - val_f1_score: 0.7574 - val_loss: 0.6152 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8335 - f1_score: 0.7185 - loss: 0.5872 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6154 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8272 - f1_score: 0.7097 - loss: 0.6105 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6166 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8049 - f1_score: 0.6910 - loss: 0.6103 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6183 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8132 - f1_score: 0.6792 - loss: 0.6071 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6141 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8065 - f1_score: 0.6892 - loss: 0.6091\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8076 - f1_score: 0.6895 - loss: 0.6090 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6180 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7949 - f1_score: 0.6912 - loss: 0.6048 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6176 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7997 - f1_score: 0.6865 - loss: 0.6225 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6170 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8013 - f1_score: 0.7109 - loss: 0.6044 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6154 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8321 - f1_score: 0.7176 - loss: 0.5984 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8110 - f1_score: 0.7004 - loss: 0.6037 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6158 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8214 - f1_score: 0.6990 - loss: 0.6013 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6159 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8241 - f1_score: 0.7107 - loss: 0.5833 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6164 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8159 - f1_score: 0.6990 - loss: 0.5982 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6167 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8106 - f1_score: 0.7040 - loss: 0.5963 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6172 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8216 - f1_score: 0.7130 - loss: 0.6021\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8205 - f1_score: 0.7111 - loss: 0.6027 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6159 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8268 - f1_score: 0.7082 - loss: 0.6065 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6159 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8117 - f1_score: 0.6928 - loss: 0.6046 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6159 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7999 - f1_score: 0.6891 - loss: 0.6107 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6160 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8011 - f1_score: 0.6831 - loss: 0.6008 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6160 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8284 - f1_score: 0.7018 - loss: 0.5936 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6161 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8089 - f1_score: 0.6999 - loss: 0.6096 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6161 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8328 - f1_score: 0.7189 - loss: 0.5821 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6160 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8196 - f1_score: 0.6914 - loss: 0.6058 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6161 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8106 - f1_score: 0.6873 - loss: 0.6052 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8520 - f1_score: 0.7350 - loss: 0.5960 \n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8435 - f1_score: 0.7269 - loss: 0.5974 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8081 - f1_score: 0.6901 - loss: 0.6172 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8092 - f1_score: 0.7019 - loss: 0.6111 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8107 - f1_score: 0.7093 - loss: 0.5909 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8198 - f1_score: 0.7132 - loss: 0.5939 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8178 - f1_score: 0.7191 - loss: 0.5927 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8239 - f1_score: 0.7135 - loss: 0.5887 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7993 - f1_score: 0.6822 - loss: 0.6157 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8218 - f1_score: 0.6941 - loss: 0.6185 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8159 - f1_score: 0.6978 - loss: 0.6006 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8149 - f1_score: 0.7094 - loss: 0.5824 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8240 - f1_score: 0.7024 - loss: 0.5917 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7986 - f1_score: 0.6967 - loss: 0.6113 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8254 - f1_score: 0.6969 - loss: 0.6031 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8149 - f1_score: 0.6997 - loss: 0.5994 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8155 - f1_score: 0.6930 - loss: 0.6124 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8160 - f1_score: 0.6777 - loss: 0.6239 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8229 - f1_score: 0.7060 - loss: 0.5883 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8039 - f1_score: 0.7010 - loss: 0.5941 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8173 - f1_score: 0.6911 - loss: 0.6165 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8093 - f1_score: 0.6925 - loss: 0.6018 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7930 - f1_score: 0.7027 - loss: 0.6140 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8258 - f1_score: 0.7096 - loss: 0.6102 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8097 - f1_score: 0.6926 - loss: 0.6103 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8178 - f1_score: 0.7045 - loss: 0.6225 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6161 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8139 - f1_score: 0.6986 - loss: 0.6092 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8272 - f1_score: 0.7121 - loss: 0.6048 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8203 - f1_score: 0.7162 - loss: 0.6090 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8066 - f1_score: 0.6926 - loss: 0.6069 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8216 - f1_score: 0.7051 - loss: 0.5983 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8308 - f1_score: 0.7072 - loss: 0.6136 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8198 - f1_score: 0.7085 - loss: 0.6076 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8022 - f1_score: 0.6965 - loss: 0.6084 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8049 - f1_score: 0.7244 - loss: 0.5990 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8154 - f1_score: 0.6990 - loss: 0.6145 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8193 - f1_score: 0.7055 - loss: 0.5990 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8137 - f1_score: 0.7036 - loss: 0.6072 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8245 - f1_score: 0.6890 - loss: 0.5995 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8261 - f1_score: 0.7108 - loss: 0.6094 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8219 - f1_score: 0.7015 - loss: 0.5943 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8133 - f1_score: 0.6973 - loss: 0.6090 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8132 - f1_score: 0.6982 - loss: 0.6030 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8239 - f1_score: 0.6992 - loss: 0.6020 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6160 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6541125541125541, 0.8961038961038961, 0.4121212121212121)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_12', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - accuracy: 0.7509 - f1_score: 0.5150 - loss: 0.7990 - val_accuracy: 0.8711 - val_f1_score: 0.6665 - val_loss: 0.7031 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8244 - f1_score: 0.5909 - loss: 0.7291 - val_accuracy: 0.8711 - val_f1_score: 0.7075 - val_loss: 0.6981 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8422 - f1_score: 0.6484 - loss: 0.6834 - val_accuracy: 0.8763 - val_f1_score: 0.6851 - val_loss: 0.6727 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8208 - f1_score: 0.6398 - loss: 0.6915 - val_accuracy: 0.8711 - val_f1_score: 0.7169 - val_loss: 0.6184 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8144 - f1_score: 0.6380 - loss: 0.6596 - val_accuracy: 0.7526 - val_f1_score: 0.7188 - val_loss: 0.6400 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8216 - f1_score: 0.6750 - loss: 0.6541 - val_accuracy: 0.7784 - val_f1_score: 0.7343 - val_loss: 0.6413 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7553 - f1_score: 0.6756 - loss: 0.6981 - val_accuracy: 0.8351 - val_f1_score: 0.7325 - val_loss: 0.6057 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8214 - f1_score: 0.6855 - loss: 0.6676 - val_accuracy: 0.8041 - val_f1_score: 0.7475 - val_loss: 0.6056 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8035 - f1_score: 0.6729 - loss: 0.6718 - val_accuracy: 0.8299 - val_f1_score: 0.7191 - val_loss: 0.6005 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8088 - f1_score: 0.6761 - loss: 0.6497 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.6041 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8474 - f1_score: 0.6815 - loss: 0.6425 - val_accuracy: 0.8093 - val_f1_score: 0.7408 - val_loss: 0.6022 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8001 - f1_score: 0.6862 - loss: 0.6466 - val_accuracy: 0.8608 - val_f1_score: 0.6778 - val_loss: 0.6527 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8418 - f1_score: 0.6319 - loss: 0.6612 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.6112 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8415 - f1_score: 0.6898 - loss: 0.6483 - val_accuracy: 0.7938 - val_f1_score: 0.7491 - val_loss: 0.6365 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7883 - f1_score: 0.6829 - loss: 0.6736 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.5956 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7914 - f1_score: 0.6619 - loss: 0.6653 - val_accuracy: 0.8454 - val_f1_score: 0.7033 - val_loss: 0.6102 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8009 - f1_score: 0.6746 - loss: 0.6569 - val_accuracy: 0.8196 - val_f1_score: 0.7485 - val_loss: 0.6877 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7388 - f1_score: 0.6800 - loss: 0.6808 - val_accuracy: 0.8505 - val_f1_score: 0.7025 - val_loss: 0.5940 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8161 - f1_score: 0.6643 - loss: 0.6611 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6047 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8329 - f1_score: 0.6733 - loss: 0.6525 - val_accuracy: 0.8196 - val_f1_score: 0.7255 - val_loss: 0.6543 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8104 - f1_score: 0.6934 - loss: 0.6507 - val_accuracy: 0.8093 - val_f1_score: 0.7357 - val_loss: 0.6080 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8467 - f1_score: 0.6890 - loss: 0.6274 - val_accuracy: 0.8144 - val_f1_score: 0.7551 - val_loss: 0.6004 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7983 - f1_score: 0.6848 - loss: 0.6425 - val_accuracy: 0.8093 - val_f1_score: 0.7330 - val_loss: 0.5988 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8155 - f1_score: 0.6655 - loss: 0.6728 - val_accuracy: 0.8351 - val_f1_score: 0.7378 - val_loss: 0.5935 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7862 - f1_score: 0.6769 - loss: 0.6511 - val_accuracy: 0.8505 - val_f1_score: 0.7419 - val_loss: 0.5889 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8453 - f1_score: 0.6945 - loss: 0.6327 - val_accuracy: 0.8144 - val_f1_score: 0.7551 - val_loss: 0.5992 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8158 - f1_score: 0.7010 - loss: 0.6364 - val_accuracy: 0.8196 - val_f1_score: 0.7541 - val_loss: 0.5858 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7760 - f1_score: 0.7052 - loss: 0.6411 - val_accuracy: 0.8093 - val_f1_score: 0.7408 - val_loss: 0.6091 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8190 - f1_score: 0.6998 - loss: 0.6331 - val_accuracy: 0.8196 - val_f1_score: 0.7516 - val_loss: 0.6384 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8078 - f1_score: 0.6807 - loss: 0.6316 - val_accuracy: 0.8247 - val_f1_score: 0.7481 - val_loss: 0.6069 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8266 - f1_score: 0.6950 - loss: 0.6163 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6002 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8055 - f1_score: 0.6696 - loss: 0.6444 - val_accuracy: 0.8144 - val_f1_score: 0.7293 - val_loss: 0.5938 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8052 - f1_score: 0.6886 - loss: 0.6440 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.6220 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8206 - f1_score: 0.6615 - loss: 0.6457 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.5830 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7867 - f1_score: 0.6712 - loss: 0.6408 - val_accuracy: 0.8351 - val_f1_score: 0.7232 - val_loss: 0.6562 - learning_rate: 0.0100\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8155 - f1_score: 0.6664 - loss: 0.6541 - val_accuracy: 0.8402 - val_f1_score: 0.7188 - val_loss: 0.6021 - learning_rate: 0.0100\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8415 - f1_score: 0.6900 - loss: 0.6268 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6189 - learning_rate: 0.0100\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8097 - f1_score: 0.6860 - loss: 0.6413 - val_accuracy: 0.7887 - val_f1_score: 0.7243 - val_loss: 0.6240 - learning_rate: 0.0100\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7951 - f1_score: 0.7056 - loss: 0.6167 - val_accuracy: 0.8454 - val_f1_score: 0.7524 - val_loss: 0.6345 - learning_rate: 0.0100\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8024 - f1_score: 0.6842 - loss: 0.6473 - val_accuracy: 0.8351 - val_f1_score: 0.7565 - val_loss: 0.6097 - learning_rate: 0.0100\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8240 - f1_score: 0.7147 - loss: 0.6134 - val_accuracy: 0.8505 - val_f1_score: 0.7419 - val_loss: 0.6066 - learning_rate: 0.0100\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8151 - f1_score: 0.6891 - loss: 0.6127 - val_accuracy: 0.8505 - val_f1_score: 0.7642 - val_loss: 0.6058 - learning_rate: 0.0100\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8029 - f1_score: 0.6832 - loss: 0.6130 - val_accuracy: 0.8454 - val_f1_score: 0.7421 - val_loss: 0.5985 - learning_rate: 0.0100\n",
            "Epoch 44/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7965 - f1_score: 0.6937 - loss: 0.6090 \n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7978 - f1_score: 0.6937 - loss: 0.6098 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6190 - learning_rate: 0.0100\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8068 - f1_score: 0.6993 - loss: 0.5998 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6091 - learning_rate: 1.0000e-03\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8119 - f1_score: 0.7005 - loss: 0.5890 - val_accuracy: 0.8505 - val_f1_score: 0.7591 - val_loss: 0.6109 - learning_rate: 1.0000e-03\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8415 - f1_score: 0.7100 - loss: 0.5903 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6119 - learning_rate: 1.0000e-03\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8279 - f1_score: 0.6902 - loss: 0.5919 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6113 - learning_rate: 1.0000e-03\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8020 - f1_score: 0.6844 - loss: 0.5903 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6120 - learning_rate: 1.0000e-03\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8374 - f1_score: 0.7044 - loss: 0.5940 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6119 - learning_rate: 1.0000e-03\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8390 - f1_score: 0.7133 - loss: 0.5725 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6110 - learning_rate: 1.0000e-03\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8419 - f1_score: 0.7071 - loss: 0.5749 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6113 - learning_rate: 1.0000e-03\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8405 - f1_score: 0.7212 - loss: 0.6067 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6096 - learning_rate: 1.0000e-03\n",
            "Epoch 54/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8458 - f1_score: 0.7015 - loss: 0.5781\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8440 - f1_score: 0.7005 - loss: 0.5803 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6091 - learning_rate: 1.0000e-03\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8307 - f1_score: 0.6920 - loss: 0.5944 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6089 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8244 - f1_score: 0.6832 - loss: 0.6110 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6093 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8304 - f1_score: 0.6994 - loss: 0.5931 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6092 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8262 - f1_score: 0.7036 - loss: 0.5914 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6092 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8216 - f1_score: 0.7002 - loss: 0.5645 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6096 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8195 - f1_score: 0.6920 - loss: 0.6099 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6104 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8367 - f1_score: 0.6888 - loss: 0.6135 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6108 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8110 - f1_score: 0.7037 - loss: 0.6020 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6100 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8288 - f1_score: 0.6885 - loss: 0.5798 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6108 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8080 - f1_score: 0.6960 - loss: 0.6038\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8090 - f1_score: 0.6959 - loss: 0.6031 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6106 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8149 - f1_score: 0.6855 - loss: 0.6022 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6106 - learning_rate: 1.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8069 - f1_score: 0.6896 - loss: 0.5865 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6106 - learning_rate: 1.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8303 - f1_score: 0.7004 - loss: 0.5762 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8178 - f1_score: 0.7013 - loss: 0.5911 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8483 - f1_score: 0.6970 - loss: 0.5932 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6106 - learning_rate: 1.0000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8174 - f1_score: 0.6877 - loss: 0.6191 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8098 - f1_score: 0.6714 - loss: 0.5953 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8246 - f1_score: 0.6791 - loss: 0.6145 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8251 - f1_score: 0.6996 - loss: 0.5856 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8088 - f1_score: 0.7058 - loss: 0.6043\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8107 - f1_score: 0.7039 - loss: 0.6013 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8424 - f1_score: 0.7039 - loss: 0.5846 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8215 - f1_score: 0.7057 - loss: 0.5908 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8079 - f1_score: 0.7002 - loss: 0.6050 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8282 - f1_score: 0.7080 - loss: 0.5833 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8060 - f1_score: 0.6809 - loss: 0.6055 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8155 - f1_score: 0.6858 - loss: 0.6006 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8313 - f1_score: 0.6950 - loss: 0.5990 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8332 - f1_score: 0.7007 - loss: 0.6025 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8136 - f1_score: 0.6931 - loss: 0.6106 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8070 - f1_score: 0.6881 - loss: 0.6034 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8093 - f1_score: 0.6697 - loss: 0.6086 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8125 - f1_score: 0.7158 - loss: 0.5844 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8197 - f1_score: 0.7210 - loss: 0.5889 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8027 - f1_score: 0.6937 - loss: 0.5900 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8116 - f1_score: 0.6924 - loss: 0.6152 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8111 - f1_score: 0.7068 - loss: 0.5823 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8235 - f1_score: 0.7055 - loss: 0.5859 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8322 - f1_score: 0.6995 - loss: 0.5791 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8285 - f1_score: 0.6925 - loss: 0.5836 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8195 - f1_score: 0.6896 - loss: 0.5966 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8201 - f1_score: 0.6886 - loss: 0.5921 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8238 - f1_score: 0.7008 - loss: 0.5883 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8074 - f1_score: 0.6895 - loss: 0.5901 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8135 - f1_score: 0.6905 - loss: 0.5811 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8078 - f1_score: 0.6963 - loss: 0.5855 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8092 - f1_score: 0.7123 - loss: 0.5965 - val_accuracy: 0.8557 - val_f1_score: 0.7634 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6442278841010789, 0.8932461873638344, 0.39520958083832336)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_13', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - accuracy: 0.7350 - f1_score: 0.5027 - loss: 0.8014 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6639 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8052 - f1_score: 0.5413 - loss: 0.7369 - val_accuracy: 0.8814 - val_f1_score: 0.6845 - val_loss: 0.6782 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8114 - f1_score: 0.6470 - loss: 0.6902 - val_accuracy: 0.8247 - val_f1_score: 0.7303 - val_loss: 0.6178 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8171 - f1_score: 0.6727 - loss: 0.6850 - val_accuracy: 0.8144 - val_f1_score: 0.7243 - val_loss: 0.6259 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8166 - f1_score: 0.6602 - loss: 0.6685 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6427 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7931 - f1_score: 0.6614 - loss: 0.6942 - val_accuracy: 0.7680 - val_f1_score: 0.7417 - val_loss: 0.6707 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7766 - f1_score: 0.6794 - loss: 0.6677 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6149 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7925 - f1_score: 0.6713 - loss: 0.6562 - val_accuracy: 0.8402 - val_f1_score: 0.7287 - val_loss: 0.6181 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7920 - f1_score: 0.6765 - loss: 0.6685 - val_accuracy: 0.8351 - val_f1_score: 0.7296 - val_loss: 0.6117 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7897 - f1_score: 0.6653 - loss: 0.6858 - val_accuracy: 0.8557 - val_f1_score: 0.7016 - val_loss: 0.6071 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8372 - f1_score: 0.6685 - loss: 0.6503 - val_accuracy: 0.8299 - val_f1_score: 0.7334 - val_loss: 0.6401 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7990 - f1_score: 0.6881 - loss: 0.6774 - val_accuracy: 0.7835 - val_f1_score: 0.7332 - val_loss: 0.6143 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8037 - f1_score: 0.6817 - loss: 0.6431 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.6096 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8356 - f1_score: 0.6969 - loss: 0.6528 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.5987 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8120 - f1_score: 0.6860 - loss: 0.6155 - val_accuracy: 0.8247 - val_f1_score: 0.7233 - val_loss: 0.6129 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8363 - f1_score: 0.6905 - loss: 0.6575 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.5975 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7863 - f1_score: 0.6780 - loss: 0.6486 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.6055 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8157 - f1_score: 0.6610 - loss: 0.6735 - val_accuracy: 0.8351 - val_f1_score: 0.7387 - val_loss: 0.5992 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8157 - f1_score: 0.6973 - loss: 0.6432 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.6443 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8138 - f1_score: 0.6748 - loss: 0.6554 - val_accuracy: 0.7835 - val_f1_score: 0.7428 - val_loss: 0.6334 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7537 - f1_score: 0.6719 - loss: 0.6614 - val_accuracy: 0.8144 - val_f1_score: 0.7575 - val_loss: 0.6154 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7600 - f1_score: 0.6869 - loss: 0.6445 - val_accuracy: 0.7887 - val_f1_score: 0.7545 - val_loss: 0.6220 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7686 - f1_score: 0.6887 - loss: 0.6425 - val_accuracy: 0.8402 - val_f1_score: 0.7206 - val_loss: 0.5973 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8196 - f1_score: 0.6956 - loss: 0.6378 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.6097 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8066 - f1_score: 0.6833 - loss: 0.6233 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.6091 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7908 - f1_score: 0.6885 - loss: 0.6207 - val_accuracy: 0.8454 - val_f1_score: 0.7436 - val_loss: 0.6287 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8321 - f1_score: 0.6869 - loss: 0.6204 - val_accuracy: 0.8402 - val_f1_score: 0.7083 - val_loss: 0.6117 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8027 - f1_score: 0.6652 - loss: 0.6254 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.6068 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8122 - f1_score: 0.6757 - loss: 0.6289 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.6067 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8007 - f1_score: 0.6846 - loss: 0.6105 - val_accuracy: 0.8402 - val_f1_score: 0.7472 - val_loss: 0.6023 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8159 - f1_score: 0.6939 - loss: 0.6325 - val_accuracy: 0.8351 - val_f1_score: 0.7337 - val_loss: 0.6146 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8263 - f1_score: 0.6899 - loss: 0.6303 - val_accuracy: 0.8041 - val_f1_score: 0.7596 - val_loss: 0.6183 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8029 - f1_score: 0.7034 - loss: 0.6534 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.5908 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7593 - f1_score: 0.6793 - loss: 0.6652 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5982 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8282 - f1_score: 0.6957 - loss: 0.6309 - val_accuracy: 0.8299 - val_f1_score: 0.7395 - val_loss: 0.6313 - learning_rate: 0.0100\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8263 - f1_score: 0.6338 - loss: 0.6920 - val_accuracy: 0.8402 - val_f1_score: 0.7305 - val_loss: 0.6393 - learning_rate: 0.0100\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7855 - f1_score: 0.6811 - loss: 0.6428 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6371 - learning_rate: 0.0100\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7957 - f1_score: 0.6955 - loss: 0.6557 - val_accuracy: 0.8402 - val_f1_score: 0.6905 - val_loss: 0.6269 - learning_rate: 0.0100\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8330 - f1_score: 0.6795 - loss: 0.6390 - val_accuracy: 0.8196 - val_f1_score: 0.7546 - val_loss: 0.6406 - learning_rate: 0.0100\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8187 - f1_score: 0.6991 - loss: 0.6284 - val_accuracy: 0.6959 - val_f1_score: 0.7092 - val_loss: 0.6821 - learning_rate: 0.0100\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7749 - f1_score: 0.6919 - loss: 0.6594 - val_accuracy: 0.8041 - val_f1_score: 0.7543 - val_loss: 0.6071 - learning_rate: 0.0100\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7896 - f1_score: 0.6806 - loss: 0.6362 - val_accuracy: 0.8557 - val_f1_score: 0.7411 - val_loss: 0.6148 - learning_rate: 0.0100\n",
            "Epoch 43/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8116 - f1_score: 0.6936 - loss: 0.6505 \n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8113 - f1_score: 0.6939 - loss: 0.6493 - val_accuracy: 0.8247 - val_f1_score: 0.7555 - val_loss: 0.6070 - learning_rate: 0.0100\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7851 - f1_score: 0.6885 - loss: 0.6334 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6079 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8214 - f1_score: 0.7084 - loss: 0.6069 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6113 - learning_rate: 1.0000e-03\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8194 - f1_score: 0.6843 - loss: 0.6160 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6094 - learning_rate: 1.0000e-03\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8199 - f1_score: 0.7015 - loss: 0.5968 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6118 - learning_rate: 1.0000e-03\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8272 - f1_score: 0.7051 - loss: 0.6038 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6132 - learning_rate: 1.0000e-03\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8294 - f1_score: 0.7048 - loss: 0.5988 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6114 - learning_rate: 1.0000e-03\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7976 - f1_score: 0.6912 - loss: 0.6161 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6153 - learning_rate: 1.0000e-03\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7941 - f1_score: 0.6801 - loss: 0.6201 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6140 - learning_rate: 1.0000e-03\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8108 - f1_score: 0.6801 - loss: 0.6249 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6143 - learning_rate: 1.0000e-03\n",
            "Epoch 53/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8108 - f1_score: 0.7026 - loss: 0.6003\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8106 - f1_score: 0.7018 - loss: 0.6008 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6176 - learning_rate: 1.0000e-03\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8211 - f1_score: 0.7079 - loss: 0.5906 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6176 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8387 - f1_score: 0.6947 - loss: 0.6116 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6166 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8309 - f1_score: 0.7150 - loss: 0.5988 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6167 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8188 - f1_score: 0.6989 - loss: 0.6023 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6168 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8017 - f1_score: 0.6893 - loss: 0.6118 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8193 - f1_score: 0.6809 - loss: 0.6163 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6163 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8425 - f1_score: 0.7083 - loss: 0.6024 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6173 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8100 - f1_score: 0.6873 - loss: 0.6161 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6171 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7923 - f1_score: 0.6808 - loss: 0.5946 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8206 - f1_score: 0.6924 - loss: 0.6268 \n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8201 - f1_score: 0.6928 - loss: 0.6250 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8176 - f1_score: 0.6903 - loss: 0.5980 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8215 - f1_score: 0.6954 - loss: 0.5989 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7887 - f1_score: 0.6819 - loss: 0.6117 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8113 - f1_score: 0.6884 - loss: 0.6166 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8175 - f1_score: 0.7067 - loss: 0.6016 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8168 - f1_score: 0.7078 - loss: 0.5925 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8168 - f1_score: 0.6974 - loss: 0.5935 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6165 - learning_rate: 1.0000e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8224 - f1_score: 0.7140 - loss: 0.5940 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8237 - f1_score: 0.6967 - loss: 0.5901 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8265 - f1_score: 0.6925 - loss: 0.6106\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8252 - f1_score: 0.6930 - loss: 0.6098 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8182 - f1_score: 0.7048 - loss: 0.6020 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8169 - f1_score: 0.6916 - loss: 0.6209 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8003 - f1_score: 0.6841 - loss: 0.5929 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8064 - f1_score: 0.6934 - loss: 0.6032 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8306 - f1_score: 0.7034 - loss: 0.6122 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7966 - f1_score: 0.6950 - loss: 0.6085 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8092 - f1_score: 0.6881 - loss: 0.6169 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8324 - f1_score: 0.7218 - loss: 0.5699 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8093 - f1_score: 0.6900 - loss: 0.6282 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8312 - f1_score: 0.7072 - loss: 0.5986 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8192 - f1_score: 0.6866 - loss: 0.6018 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8155 - f1_score: 0.7048 - loss: 0.5934 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8254 - f1_score: 0.7078 - loss: 0.6049 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8229 - f1_score: 0.6875 - loss: 0.6194 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8264 - f1_score: 0.7091 - loss: 0.6007 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8350 - f1_score: 0.6995 - loss: 0.6165 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8102 - f1_score: 0.6880 - loss: 0.6270 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8128 - f1_score: 0.7018 - loss: 0.5918 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8040 - f1_score: 0.6680 - loss: 0.6234 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8229 - f1_score: 0.6970 - loss: 0.5833 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8299 - f1_score: 0.7224 - loss: 0.5731 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8243 - f1_score: 0.7086 - loss: 0.6132 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8122 - f1_score: 0.6720 - loss: 0.6232 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7899 - f1_score: 0.6766 - loss: 0.6174 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8154 - f1_score: 0.6987 - loss: 0.6096 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7965 - f1_score: 0.6946 - loss: 0.6132 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8058 - f1_score: 0.6990 - loss: 0.6024 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6164 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6750181554103123, 0.8932461873638344, 0.4567901234567901)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_14', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.8058 - f1_score: 0.5732 - loss: 0.7824 - val_accuracy: 0.8454 - val_f1_score: 0.7051 - val_loss: 0.6903 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8318 - f1_score: 0.6468 - loss: 0.7128 - val_accuracy: 0.8711 - val_f1_score: 0.6565 - val_loss: 0.6374 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8167 - f1_score: 0.6263 - loss: 0.6997 - val_accuracy: 0.7990 - val_f1_score: 0.7457 - val_loss: 0.6360 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7928 - f1_score: 0.6694 - loss: 0.6688 - val_accuracy: 0.8608 - val_f1_score: 0.6581 - val_loss: 0.7045 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8347 - f1_score: 0.6551 - loss: 0.7044 - val_accuracy: 0.7010 - val_f1_score: 0.7063 - val_loss: 0.7244 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7724 - f1_score: 0.6824 - loss: 0.6964 - val_accuracy: 0.8351 - val_f1_score: 0.7489 - val_loss: 0.6248 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7710 - f1_score: 0.6776 - loss: 0.6647 - val_accuracy: 0.7887 - val_f1_score: 0.7449 - val_loss: 0.6225 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7778 - f1_score: 0.6898 - loss: 0.6528 - val_accuracy: 0.8557 - val_f1_score: 0.7191 - val_loss: 0.6336 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8107 - f1_score: 0.6713 - loss: 0.6487 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6103 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7899 - f1_score: 0.6760 - loss: 0.6514 - val_accuracy: 0.8505 - val_f1_score: 0.7305 - val_loss: 0.6230 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8103 - f1_score: 0.6720 - loss: 0.6529 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6153 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7998 - f1_score: 0.6768 - loss: 0.6660 - val_accuracy: 0.7268 - val_f1_score: 0.7248 - val_loss: 0.6599 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7987 - f1_score: 0.6809 - loss: 0.6648 - val_accuracy: 0.8505 - val_f1_score: 0.7113 - val_loss: 0.6006 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8423 - f1_score: 0.6796 - loss: 0.6562 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6140 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8058 - f1_score: 0.6712 - loss: 0.6434 - val_accuracy: 0.8144 - val_f1_score: 0.7551 - val_loss: 0.6295 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8379 - f1_score: 0.6897 - loss: 0.6525 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6072 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8371 - f1_score: 0.6897 - loss: 0.6457 - val_accuracy: 0.8505 - val_f1_score: 0.7305 - val_loss: 0.5935 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8114 - f1_score: 0.6606 - loss: 0.6673 - val_accuracy: 0.8299 - val_f1_score: 0.7625 - val_loss: 0.6356 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7993 - f1_score: 0.6923 - loss: 0.6371 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6037 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8191 - f1_score: 0.6759 - loss: 0.6666 - val_accuracy: 0.7732 - val_f1_score: 0.7482 - val_loss: 0.6193 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8022 - f1_score: 0.6865 - loss: 0.6425 - val_accuracy: 0.8041 - val_f1_score: 0.7523 - val_loss: 0.6030 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7843 - f1_score: 0.7000 - loss: 0.6373 - val_accuracy: 0.7887 - val_f1_score: 0.7449 - val_loss: 0.6314 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7844 - f1_score: 0.6864 - loss: 0.6564 - val_accuracy: 0.8196 - val_f1_score: 0.7465 - val_loss: 0.6118 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8019 - f1_score: 0.6724 - loss: 0.6618 - val_accuracy: 0.8144 - val_f1_score: 0.7499 - val_loss: 0.6253 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8194 - f1_score: 0.6845 - loss: 0.6451 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6108 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7884 - f1_score: 0.6734 - loss: 0.6588 - val_accuracy: 0.8402 - val_f1_score: 0.7416 - val_loss: 0.6015 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8161 - f1_score: 0.6845 - loss: 0.6336 \n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8158 - f1_score: 0.6845 - loss: 0.6338 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.6197 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8129 - f1_score: 0.6907 - loss: 0.6291 - val_accuracy: 0.8144 - val_f1_score: 0.7391 - val_loss: 0.6028 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7884 - f1_score: 0.6955 - loss: 0.6226 - val_accuracy: 0.8144 - val_f1_score: 0.7391 - val_loss: 0.6031 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7867 - f1_score: 0.6867 - loss: 0.6331 - val_accuracy: 0.8299 - val_f1_score: 0.7463 - val_loss: 0.6027 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8134 - f1_score: 0.6845 - loss: 0.6300 - val_accuracy: 0.8299 - val_f1_score: 0.7463 - val_loss: 0.6058 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7870 - f1_score: 0.6857 - loss: 0.6196 - val_accuracy: 0.8299 - val_f1_score: 0.7463 - val_loss: 0.6039 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8216 - f1_score: 0.7074 - loss: 0.6160 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6037 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8079 - f1_score: 0.6994 - loss: 0.6299 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6057 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7948 - f1_score: 0.6718 - loss: 0.6253 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6041 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8236 - f1_score: 0.7021 - loss: 0.6319 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6060 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8063 - f1_score: 0.6949 - loss: 0.6150 \n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8066 - f1_score: 0.6947 - loss: 0.6159 - val_accuracy: 0.8196 - val_f1_score: 0.7432 - val_loss: 0.6035 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8054 - f1_score: 0.6885 - loss: 0.6123 - val_accuracy: 0.8351 - val_f1_score: 0.7454 - val_loss: 0.6041 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8016 - f1_score: 0.6957 - loss: 0.6234 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8069 - f1_score: 0.6938 - loss: 0.6151 - val_accuracy: 0.8351 - val_f1_score: 0.7454 - val_loss: 0.6038 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7826 - f1_score: 0.6718 - loss: 0.6444 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6038 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8006 - f1_score: 0.6898 - loss: 0.6337 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6041 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8100 - f1_score: 0.7115 - loss: 0.6166 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8063 - f1_score: 0.6894 - loss: 0.6425 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6042 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8119 - f1_score: 0.7009 - loss: 0.6189 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6036 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8299 - f1_score: 0.6975 - loss: 0.6198 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6037 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8001 - f1_score: 0.6882 - loss: 0.6239\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8017 - f1_score: 0.6891 - loss: 0.6242 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7918 - f1_score: 0.6960 - loss: 0.6285 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8051 - f1_score: 0.6961 - loss: 0.6140 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8126 - f1_score: 0.6916 - loss: 0.6281 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8166 - f1_score: 0.6969 - loss: 0.6089 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8107 - f1_score: 0.6924 - loss: 0.6192 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8060 - f1_score: 0.6886 - loss: 0.6326 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7971 - f1_score: 0.6882 - loss: 0.6268 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8014 - f1_score: 0.6963 - loss: 0.6235 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8094 - f1_score: 0.6910 - loss: 0.6388 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7931 - f1_score: 0.6940 - loss: 0.6374 \n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7943 - f1_score: 0.6938 - loss: 0.6365 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8074 - f1_score: 0.6901 - loss: 0.6192 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8077 - f1_score: 0.6979 - loss: 0.6332 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8277 - f1_score: 0.6942 - loss: 0.6338 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8066 - f1_score: 0.6940 - loss: 0.6188 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8235 - f1_score: 0.6848 - loss: 0.6386 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8095 - f1_score: 0.6953 - loss: 0.6237 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8228 - f1_score: 0.7043 - loss: 0.6206 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8165 - f1_score: 0.6940 - loss: 0.6210 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8110 - f1_score: 0.7004 - loss: 0.6136 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8401 - f1_score: 0.6947 - loss: 0.6226 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8091 - f1_score: 0.6871 - loss: 0.6287 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7914 - f1_score: 0.6835 - loss: 0.6078 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8116 - f1_score: 0.6936 - loss: 0.6283 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7977 - f1_score: 0.6869 - loss: 0.6186 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7960 - f1_score: 0.6878 - loss: 0.6378 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7844 - f1_score: 0.6758 - loss: 0.6288 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8179 - f1_score: 0.7082 - loss: 0.6095 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7997 - f1_score: 0.6971 - loss: 0.6306 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7907 - f1_score: 0.6741 - loss: 0.6202 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8095 - f1_score: 0.6886 - loss: 0.6324 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8151 - f1_score: 0.6980 - loss: 0.6238 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8146 - f1_score: 0.6839 - loss: 0.6205 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7909 - f1_score: 0.6915 - loss: 0.6222 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8215 - f1_score: 0.7064 - loss: 0.6066 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8238 - f1_score: 0.7142 - loss: 0.6228 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8187 - f1_score: 0.6974 - loss: 0.6249 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7859 - f1_score: 0.6924 - loss: 0.6518 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8138 - f1_score: 0.6902 - loss: 0.6149 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8066 - f1_score: 0.7029 - loss: 0.6142 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8006 - f1_score: 0.6900 - loss: 0.6116 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8184 - f1_score: 0.7013 - loss: 0.6500 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8032 - f1_score: 0.6720 - loss: 0.6437 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8086 - f1_score: 0.6910 - loss: 0.6230 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8079 - f1_score: 0.6941 - loss: 0.6278 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8190 - f1_score: 0.7076 - loss: 0.6006 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6040 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7945 - f1_score: 0.6701 - loss: 0.6422 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8173 - f1_score: 0.6896 - loss: 0.6224 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8077 - f1_score: 0.6967 - loss: 0.6309 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8138 - f1_score: 0.6952 - loss: 0.6145 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8073 - f1_score: 0.7005 - loss: 0.6043 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8007 - f1_score: 0.6801 - loss: 0.6335 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8089 - f1_score: 0.6938 - loss: 0.6357 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7906 - f1_score: 0.6877 - loss: 0.6202 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6690768859966256, 0.8937093275488069, 0.4444444444444444)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_15', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.8628 - f1_score: 0.5365 - loss: 0.7688 - val_accuracy: 0.8711 - val_f1_score: 0.6461 - val_loss: 0.6453 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8283 - f1_score: 0.6167 - loss: 0.7037 - val_accuracy: 0.8196 - val_f1_score: 0.7143 - val_loss: 0.6986 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8239 - f1_score: 0.6896 - loss: 0.6685 - val_accuracy: 0.8299 - val_f1_score: 0.7142 - val_loss: 0.6439 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7773 - f1_score: 0.6556 - loss: 0.6781 - val_accuracy: 0.8454 - val_f1_score: 0.7112 - val_loss: 0.6239 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7767 - f1_score: 0.6391 - loss: 0.6953 - val_accuracy: 0.8196 - val_f1_score: 0.7439 - val_loss: 0.6127 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7961 - f1_score: 0.6669 - loss: 0.6734 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6088 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7971 - f1_score: 0.6829 - loss: 0.6452 - val_accuracy: 0.7887 - val_f1_score: 0.7576 - val_loss: 0.6581 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8128 - f1_score: 0.6891 - loss: 0.6613 - val_accuracy: 0.7423 - val_f1_score: 0.7358 - val_loss: 0.6359 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7542 - f1_score: 0.6722 - loss: 0.6501 - val_accuracy: 0.8454 - val_f1_score: 0.6851 - val_loss: 0.5998 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8215 - f1_score: 0.6824 - loss: 0.6585 - val_accuracy: 0.8196 - val_f1_score: 0.7389 - val_loss: 0.5997 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8258 - f1_score: 0.6782 - loss: 0.6455 - val_accuracy: 0.8505 - val_f1_score: 0.7272 - val_loss: 0.6467 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8179 - f1_score: 0.6846 - loss: 0.6515 - val_accuracy: 0.8557 - val_f1_score: 0.6689 - val_loss: 0.6077 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8419 - f1_score: 0.6746 - loss: 0.6650 - val_accuracy: 0.8351 - val_f1_score: 0.7358 - val_loss: 0.6059 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8172 - f1_score: 0.6910 - loss: 0.6352 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.6314 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7861 - f1_score: 0.6721 - loss: 0.6480 - val_accuracy: 0.8505 - val_f1_score: 0.7354 - val_loss: 0.5891 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7962 - f1_score: 0.6907 - loss: 0.6565 - val_accuracy: 0.7784 - val_f1_score: 0.7365 - val_loss: 0.7012 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7995 - f1_score: 0.6909 - loss: 0.6535 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.6226 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8019 - f1_score: 0.6779 - loss: 0.6392 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.5913 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8015 - f1_score: 0.6931 - loss: 0.6229 - val_accuracy: 0.8299 - val_f1_score: 0.7013 - val_loss: 0.6261 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8101 - f1_score: 0.6756 - loss: 0.6487 - val_accuracy: 0.8041 - val_f1_score: 0.7443 - val_loss: 0.6365 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8101 - f1_score: 0.6964 - loss: 0.6413 - val_accuracy: 0.8247 - val_f1_score: 0.6934 - val_loss: 0.6104 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8021 - f1_score: 0.6669 - loss: 0.6357 - val_accuracy: 0.8505 - val_f1_score: 0.7478 - val_loss: 0.6274 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8144 - f1_score: 0.6748 - loss: 0.6512 - val_accuracy: 0.7990 - val_f1_score: 0.7402 - val_loss: 0.6050 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7823 - f1_score: 0.6867 - loss: 0.6431 - val_accuracy: 0.8505 - val_f1_score: 0.7449 - val_loss: 0.5967 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8148 - f1_score: 0.6941 - loss: 0.6210\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8132 - f1_score: 0.6922 - loss: 0.6233 - val_accuracy: 0.8144 - val_f1_score: 0.7499 - val_loss: 0.6140 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7730 - f1_score: 0.6913 - loss: 0.6451 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6105 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8297 - f1_score: 0.6815 - loss: 0.6298 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6063 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8046 - f1_score: 0.7018 - loss: 0.6139 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6057 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8104 - f1_score: 0.6895 - loss: 0.6282 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6069 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8195 - f1_score: 0.6957 - loss: 0.6123 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6083 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8295 - f1_score: 0.7091 - loss: 0.6013 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6061 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8384 - f1_score: 0.6857 - loss: 0.6087 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6093 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8410 - f1_score: 0.7088 - loss: 0.6088 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6104 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8098 - f1_score: 0.6919 - loss: 0.6081 - val_accuracy: 0.8454 - val_f1_score: 0.7574 - val_loss: 0.6075 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8155 - f1_score: 0.7042 - loss: 0.6147 \n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8164 - f1_score: 0.7008 - loss: 0.6135 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6062 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8239 - f1_score: 0.7045 - loss: 0.6182 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6077 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8052 - f1_score: 0.7009 - loss: 0.6273 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8205 - f1_score: 0.6826 - loss: 0.6332 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6083 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8222 - f1_score: 0.6916 - loss: 0.6085 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8100 - f1_score: 0.6901 - loss: 0.6240 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8336 - f1_score: 0.6976 - loss: 0.6073 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6078 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8420 - f1_score: 0.6999 - loss: 0.6049 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8477 - f1_score: 0.6714 - loss: 0.6193 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8341 - f1_score: 0.7043 - loss: 0.6162 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8232 - f1_score: 0.6931 - loss: 0.5838\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8233 - f1_score: 0.6931 - loss: 0.5869 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6078 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8278 - f1_score: 0.7006 - loss: 0.6021 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8267 - f1_score: 0.6874 - loss: 0.6136 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8303 - f1_score: 0.6937 - loss: 0.6048 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8072 - f1_score: 0.6826 - loss: 0.6281 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8186 - f1_score: 0.7086 - loss: 0.5940 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8025 - f1_score: 0.6921 - loss: 0.6222 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8229 - f1_score: 0.6931 - loss: 0.5931 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8342 - f1_score: 0.7124 - loss: 0.5994 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8134 - f1_score: 0.6875 - loss: 0.6094 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6078 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8312 - f1_score: 0.7035 - loss: 0.6074 \n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8307 - f1_score: 0.7029 - loss: 0.6077 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8314 - f1_score: 0.7028 - loss: 0.6077 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8289 - f1_score: 0.6855 - loss: 0.6202 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8269 - f1_score: 0.6892 - loss: 0.6147 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8094 - f1_score: 0.6955 - loss: 0.6314 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8277 - f1_score: 0.6925 - loss: 0.5928 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8239 - f1_score: 0.6936 - loss: 0.6026 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8409 - f1_score: 0.7101 - loss: 0.6011 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8240 - f1_score: 0.6820 - loss: 0.6124 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8327 - f1_score: 0.7096 - loss: 0.5965 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8245 - f1_score: 0.6890 - loss: 0.6197 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8090 - f1_score: 0.6957 - loss: 0.6048 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8174 - f1_score: 0.7039 - loss: 0.5779 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8040 - f1_score: 0.6754 - loss: 0.6278 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8257 - f1_score: 0.7048 - loss: 0.6081 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8384 - f1_score: 0.6901 - loss: 0.6203 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8277 - f1_score: 0.6916 - loss: 0.6106 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8038 - f1_score: 0.6934 - loss: 0.6052 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8091 - f1_score: 0.7044 - loss: 0.6148 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8177 - f1_score: 0.7041 - loss: 0.5903 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8223 - f1_score: 0.7039 - loss: 0.5940 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8281 - f1_score: 0.6878 - loss: 0.6252 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6079 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8119 - f1_score: 0.6846 - loss: 0.6171 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8151 - f1_score: 0.6863 - loss: 0.6108 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8436 - f1_score: 0.7087 - loss: 0.6113 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8416 - f1_score: 0.7038 - loss: 0.6145 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8226 - f1_score: 0.6947 - loss: 0.6098 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8194 - f1_score: 0.6833 - loss: 0.6125 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8323 - f1_score: 0.6869 - loss: 0.6027 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8371 - f1_score: 0.6978 - loss: 0.6074 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8316 - f1_score: 0.6850 - loss: 0.6179 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8251 - f1_score: 0.6915 - loss: 0.6124 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8381 - f1_score: 0.6992 - loss: 0.5905 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8244 - f1_score: 0.7004 - loss: 0.6155 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8189 - f1_score: 0.6936 - loss: 0.6162 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8084 - f1_score: 0.6998 - loss: 0.5954 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8015 - f1_score: 0.6729 - loss: 0.6313 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8230 - f1_score: 0.7110 - loss: 0.5825 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8367 - f1_score: 0.6894 - loss: 0.6163 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8208 - f1_score: 0.6930 - loss: 0.6319 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8189 - f1_score: 0.6987 - loss: 0.6110 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8263 - f1_score: 0.6955 - loss: 0.6153 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8396 - f1_score: 0.6963 - loss: 0.6009 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8363 - f1_score: 0.6875 - loss: 0.6259 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8090 - f1_score: 0.6862 - loss: 0.5963 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8122 - f1_score: 0.6786 - loss: 0.6188 - val_accuracy: 0.8505 - val_f1_score: 0.7567 - val_loss: 0.6080 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6547858729395872, 0.9023861171366594, 0.40718562874251496)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_16', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - accuracy: 0.7460 - f1_score: 0.5533 - loss: 0.8088 - val_accuracy: 0.8763 - val_f1_score: 0.6711 - val_loss: 0.6813 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8584 - f1_score: 0.5851 - loss: 0.7116 - val_accuracy: 0.6598 - val_f1_score: 0.6742 - val_loss: 0.7111 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7374 - f1_score: 0.6343 - loss: 0.7227 - val_accuracy: 0.8763 - val_f1_score: 0.7116 - val_loss: 0.6287 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8395 - f1_score: 0.6434 - loss: 0.6835 - val_accuracy: 0.8247 - val_f1_score: 0.7246 - val_loss: 0.6406 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8138 - f1_score: 0.6767 - loss: 0.6838 - val_accuracy: 0.8557 - val_f1_score: 0.7297 - val_loss: 0.6128 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8118 - f1_score: 0.6627 - loss: 0.6732 - val_accuracy: 0.8196 - val_f1_score: 0.7362 - val_loss: 0.6363 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8230 - f1_score: 0.6558 - loss: 0.6625 - val_accuracy: 0.8144 - val_f1_score: 0.7449 - val_loss: 0.6226 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7752 - f1_score: 0.6804 - loss: 0.6809 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6097 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7971 - f1_score: 0.6833 - loss: 0.6632 - val_accuracy: 0.8454 - val_f1_score: 0.7112 - val_loss: 0.6226 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8182 - f1_score: 0.6641 - loss: 0.6618 - val_accuracy: 0.8041 - val_f1_score: 0.7499 - val_loss: 0.6098 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7820 - f1_score: 0.6894 - loss: 0.6677 - val_accuracy: 0.8402 - val_f1_score: 0.7121 - val_loss: 0.6500 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8053 - f1_score: 0.6814 - loss: 0.6666 - val_accuracy: 0.8402 - val_f1_score: 0.7337 - val_loss: 0.6514 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8225 - f1_score: 0.6681 - loss: 0.6641 - val_accuracy: 0.8557 - val_f1_score: 0.6881 - val_loss: 0.6298 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8149 - f1_score: 0.6666 - loss: 0.6510 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.6023 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7760 - f1_score: 0.6700 - loss: 0.6610 - val_accuracy: 0.8454 - val_f1_score: 0.6943 - val_loss: 0.6365 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8160 - f1_score: 0.6626 - loss: 0.6683 - val_accuracy: 0.8247 - val_f1_score: 0.7456 - val_loss: 0.6033 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7918 - f1_score: 0.6784 - loss: 0.6498 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.6225 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7839 - f1_score: 0.6609 - loss: 0.6667 - val_accuracy: 0.8402 - val_f1_score: 0.6994 - val_loss: 0.6290 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8068 - f1_score: 0.6612 - loss: 0.6562 - val_accuracy: 0.7887 - val_f1_score: 0.7426 - val_loss: 0.6329 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7949 - f1_score: 0.6830 - loss: 0.6495 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.5945 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8105 - f1_score: 0.6846 - loss: 0.6659 - val_accuracy: 0.7990 - val_f1_score: 0.7533 - val_loss: 0.6390 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7965 - f1_score: 0.6731 - loss: 0.6405 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6166 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8017 - f1_score: 0.7059 - loss: 0.6356 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.6094 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8163 - f1_score: 0.6970 - loss: 0.6337 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6281 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8180 - f1_score: 0.6814 - loss: 0.6363 - val_accuracy: 0.8402 - val_f1_score: 0.7131 - val_loss: 0.6032 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8180 - f1_score: 0.6881 - loss: 0.6308 - val_accuracy: 0.8247 - val_f1_score: 0.7353 - val_loss: 0.6337 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8170 - f1_score: 0.6816 - loss: 0.6493 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6459 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8156 - f1_score: 0.6808 - loss: 0.6358 - val_accuracy: 0.8351 - val_f1_score: 0.7264 - val_loss: 0.6569 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7545 - f1_score: 0.6585 - loss: 0.6682 - val_accuracy: 0.8299 - val_f1_score: 0.7395 - val_loss: 0.6175 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8084 - f1_score: 0.6912 - loss: 0.6397\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8070 - f1_score: 0.6895 - loss: 0.6410 - val_accuracy: 0.8351 - val_f1_score: 0.7387 - val_loss: 0.5987 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8060 - f1_score: 0.6772 - loss: 0.6266 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6040 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8060 - f1_score: 0.6877 - loss: 0.6314 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5955 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8129 - f1_score: 0.6800 - loss: 0.6267 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.5955 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7900 - f1_score: 0.6680 - loss: 0.6324 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5935 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7810 - f1_score: 0.6744 - loss: 0.6403 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5968 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7996 - f1_score: 0.6953 - loss: 0.6235 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5970 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8119 - f1_score: 0.7010 - loss: 0.6171 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5989 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8166 - f1_score: 0.6954 - loss: 0.6039 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5968 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8112 - f1_score: 0.7077 - loss: 0.6152 - val_accuracy: 0.8196 - val_f1_score: 0.7516 - val_loss: 0.6023 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7822 - f1_score: 0.6939 - loss: 0.6057 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5992 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8199 - f1_score: 0.6907 - loss: 0.6086 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7791 - f1_score: 0.6714 - loss: 0.6224 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5995 - learning_rate: 1.0000e-03\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8106 - f1_score: 0.6936 - loss: 0.6246 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5986 - learning_rate: 1.0000e-03\n",
            "Epoch 44/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8349 - f1_score: 0.6840 - loss: 0.6254\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8315 - f1_score: 0.6840 - loss: 0.6247 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5980 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8132 - f1_score: 0.6993 - loss: 0.6132 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5986 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8180 - f1_score: 0.6751 - loss: 0.6147 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5983 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8033 - f1_score: 0.6753 - loss: 0.6411 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5983 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8282 - f1_score: 0.7063 - loss: 0.6193 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5984 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8071 - f1_score: 0.6909 - loss: 0.6053 - val_accuracy: 0.8351 - val_f1_score: 0.7413 - val_loss: 0.5986 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7847 - f1_score: 0.6796 - loss: 0.6216 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5986 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8169 - f1_score: 0.6920 - loss: 0.6231 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.5985 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8083 - f1_score: 0.6928 - loss: 0.6271 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5989 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8234 - f1_score: 0.7024 - loss: 0.5892 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5992 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8148 - f1_score: 0.6834 - loss: 0.6325 \n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8144 - f1_score: 0.6837 - loss: 0.6319 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - f1_score: 0.6991 - loss: 0.6233 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7795 - f1_score: 0.6639 - loss: 0.6412 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7841 - f1_score: 0.6834 - loss: 0.6132 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7956 - f1_score: 0.6889 - loss: 0.6320 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8199 - f1_score: 0.6954 - loss: 0.6120 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8131 - f1_score: 0.7053 - loss: 0.6084 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8158 - f1_score: 0.6932 - loss: 0.6047 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7962 - f1_score: 0.7008 - loss: 0.6063 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7906 - f1_score: 0.6881 - loss: 0.6062 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7922 - f1_score: 0.6936 - loss: 0.6251\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7940 - f1_score: 0.6934 - loss: 0.6240 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8035 - f1_score: 0.6936 - loss: 0.6309 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8032 - f1_score: 0.6982 - loss: 0.5955 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7851 - f1_score: 0.6759 - loss: 0.6234 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7918 - f1_score: 0.6774 - loss: 0.6447 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7902 - f1_score: 0.6730 - loss: 0.6282 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8265 - f1_score: 0.6934 - loss: 0.6343 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7840 - f1_score: 0.6914 - loss: 0.6107 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8240 - f1_score: 0.7053 - loss: 0.6077 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7937 - f1_score: 0.6678 - loss: 0.6330 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8119 - f1_score: 0.6896 - loss: 0.6231 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8109 - f1_score: 0.6781 - loss: 0.6304 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8222 - f1_score: 0.6815 - loss: 0.6164 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8159 - f1_score: 0.6971 - loss: 0.6042 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8007 - f1_score: 0.6981 - loss: 0.6052 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7954 - f1_score: 0.6829 - loss: 0.6237 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7981 - f1_score: 0.7048 - loss: 0.5991 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8082 - f1_score: 0.6980 - loss: 0.6081 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8085 - f1_score: 0.6954 - loss: 0.6263 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7819 - f1_score: 0.6811 - loss: 0.6176 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7941 - f1_score: 0.6970 - loss: 0.6234 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7788 - f1_score: 0.6901 - loss: 0.6139 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8033 - f1_score: 0.7000 - loss: 0.6131 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8057 - f1_score: 0.6779 - loss: 0.6261 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8010 - f1_score: 0.6768 - loss: 0.6282 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8053 - f1_score: 0.6916 - loss: 0.6142 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7871 - f1_score: 0.6890 - loss: 0.6254 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8079 - f1_score: 0.6723 - loss: 0.6467 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8213 - f1_score: 0.6937 - loss: 0.6178 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8050 - f1_score: 0.6939 - loss: 0.6301 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8053 - f1_score: 0.6899 - loss: 0.6211 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8034 - f1_score: 0.6999 - loss: 0.6140 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8269 - f1_score: 0.6931 - loss: 0.6029 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8302 - f1_score: 0.7141 - loss: 0.5948 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8141 - f1_score: 0.7049 - loss: 0.6028 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7952 - f1_score: 0.6775 - loss: 0.6148 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8177 - f1_score: 0.6985 - loss: 0.6096 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.5997 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6593280587088637, 0.8976034858387799, 0.42105263157894735)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_17', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - accuracy: 0.8126 - f1_score: 0.5684 - loss: 0.7826 - val_accuracy: 0.8711 - val_f1_score: 0.6763 - val_loss: 0.6787 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8390 - f1_score: 0.6239 - loss: 0.7058 - val_accuracy: 0.8660 - val_f1_score: 0.7129 - val_loss: 0.6475 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7935 - f1_score: 0.6351 - loss: 0.7017 - val_accuracy: 0.8505 - val_f1_score: 0.7188 - val_loss: 0.6436 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8050 - f1_score: 0.6243 - loss: 0.6853 - val_accuracy: 0.7577 - val_f1_score: 0.7229 - val_loss: 0.6392 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7884 - f1_score: 0.6925 - loss: 0.6934 - val_accuracy: 0.8454 - val_f1_score: 0.7148 - val_loss: 0.6033 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8113 - f1_score: 0.6775 - loss: 0.6609 - val_accuracy: 0.8557 - val_f1_score: 0.7191 - val_loss: 0.6064 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7974 - f1_score: 0.6606 - loss: 0.6823 - val_accuracy: 0.7216 - val_f1_score: 0.7132 - val_loss: 0.6551 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8006 - f1_score: 0.6668 - loss: 0.6642 - val_accuracy: 0.8351 - val_f1_score: 0.7233 - val_loss: 0.6053 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8014 - f1_score: 0.6784 - loss: 0.6680 - val_accuracy: 0.8247 - val_f1_score: 0.7353 - val_loss: 0.6179 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7726 - f1_score: 0.6602 - loss: 0.6773 - val_accuracy: 0.8041 - val_f1_score: 0.7366 - val_loss: 0.6432 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7662 - f1_score: 0.6711 - loss: 0.6792 - val_accuracy: 0.7990 - val_f1_score: 0.7457 - val_loss: 0.6035 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7811 - f1_score: 0.6732 - loss: 0.6492 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6244 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7923 - f1_score: 0.6874 - loss: 0.6535 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6524 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8204 - f1_score: 0.6697 - loss: 0.6542 - val_accuracy: 0.7835 - val_f1_score: 0.7460 - val_loss: 0.6132 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8046 - f1_score: 0.6960 - loss: 0.6410\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8054 - f1_score: 0.6945 - loss: 0.6421 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.6337 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8089 - f1_score: 0.6987 - loss: 0.6409 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.5997 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8197 - f1_score: 0.6875 - loss: 0.6307 - val_accuracy: 0.8299 - val_f1_score: 0.7384 - val_loss: 0.5979 - learning_rate: 1.0000e-03\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8238 - f1_score: 0.7024 - loss: 0.6328 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.6024 - learning_rate: 1.0000e-03\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8161 - f1_score: 0.6939 - loss: 0.6338 - val_accuracy: 0.8402 - val_f1_score: 0.7366 - val_loss: 0.5986 - learning_rate: 1.0000e-03\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8217 - f1_score: 0.7057 - loss: 0.6221 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6024 - learning_rate: 1.0000e-03\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8016 - f1_score: 0.6921 - loss: 0.6334 - val_accuracy: 0.8247 - val_f1_score: 0.7403 - val_loss: 0.5986 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8050 - f1_score: 0.6875 - loss: 0.6389 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6023 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8196 - f1_score: 0.6940 - loss: 0.6274 - val_accuracy: 0.8351 - val_f1_score: 0.7375 - val_loss: 0.6018 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8297 - f1_score: 0.6940 - loss: 0.6211 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5994 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8174 - f1_score: 0.6964 - loss: 0.6243 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5996 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8086 - f1_score: 0.6932 - loss: 0.6239 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6022 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7781 - f1_score: 0.6722 - loss: 0.6314\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7807 - f1_score: 0.6756 - loss: 0.6316 - val_accuracy: 0.8402 - val_f1_score: 0.7366 - val_loss: 0.6054 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8120 - f1_score: 0.6841 - loss: 0.6317 - val_accuracy: 0.8402 - val_f1_score: 0.7366 - val_loss: 0.6046 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8066 - f1_score: 0.6697 - loss: 0.6433 - val_accuracy: 0.8402 - val_f1_score: 0.7366 - val_loss: 0.6029 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8072 - f1_score: 0.6776 - loss: 0.6560 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6011 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8192 - f1_score: 0.6846 - loss: 0.6396 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5999 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8130 - f1_score: 0.6892 - loss: 0.6390 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5994 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7983 - f1_score: 0.7015 - loss: 0.6343 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5995 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8173 - f1_score: 0.6814 - loss: 0.6426 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5991 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7956 - f1_score: 0.6824 - loss: 0.6396 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6000 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8288 - f1_score: 0.6926 - loss: 0.6357 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5993 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8285 - f1_score: 0.7157 - loss: 0.6234\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8262 - f1_score: 0.7118 - loss: 0.6247 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6000 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8156 - f1_score: 0.6877 - loss: 0.6170 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6000 - learning_rate: 1.0000e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7939 - f1_score: 0.6734 - loss: 0.6390 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8130 - f1_score: 0.7008 - loss: 0.6372 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6000 - learning_rate: 1.0000e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8217 - f1_score: 0.6996 - loss: 0.6212 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8011 - f1_score: 0.6981 - loss: 0.6355 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8105 - f1_score: 0.6866 - loss: 0.6318 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8012 - f1_score: 0.6706 - loss: 0.6416 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8106 - f1_score: 0.6888 - loss: 0.6440 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5999 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7986 - f1_score: 0.6870 - loss: 0.6354 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6000 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8080 - f1_score: 0.6727 - loss: 0.6532\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8083 - f1_score: 0.6741 - loss: 0.6514 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8222 - f1_score: 0.6890 - loss: 0.6304 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8216 - f1_score: 0.6939 - loss: 0.6230 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7961 - f1_score: 0.6862 - loss: 0.6195 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8158 - f1_score: 0.6857 - loss: 0.6266 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8110 - f1_score: 0.6845 - loss: 0.6224 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7968 - f1_score: 0.6977 - loss: 0.6242 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8089 - f1_score: 0.6887 - loss: 0.6233 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8135 - f1_score: 0.7002 - loss: 0.6216 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8178 - f1_score: 0.6963 - loss: 0.6297 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8306 - f1_score: 0.6926 - loss: 0.6185 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7986 - f1_score: 0.6968 - loss: 0.6191 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8030 - f1_score: 0.6804 - loss: 0.6285 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8118 - f1_score: 0.7047 - loss: 0.6222 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8254 - f1_score: 0.7048 - loss: 0.6174 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8189 - f1_score: 0.7073 - loss: 0.6066 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7936 - f1_score: 0.6796 - loss: 0.6403 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8115 - f1_score: 0.6856 - loss: 0.6438 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8066 - f1_score: 0.6887 - loss: 0.6243 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8125 - f1_score: 0.6770 - loss: 0.6519 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7988 - f1_score: 0.6857 - loss: 0.6313 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8323 - f1_score: 0.6880 - loss: 0.6500 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8321 - f1_score: 0.6943 - loss: 0.6242 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7949 - f1_score: 0.6697 - loss: 0.6588 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8255 - f1_score: 0.6889 - loss: 0.6268 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7901 - f1_score: 0.6740 - loss: 0.6395 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8076 - f1_score: 0.6843 - loss: 0.6405 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8234 - f1_score: 0.6917 - loss: 0.6348 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8044 - f1_score: 0.6938 - loss: 0.6316 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8026 - f1_score: 0.6785 - loss: 0.6342 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8008 - f1_score: 0.6754 - loss: 0.6352 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7946 - f1_score: 0.6762 - loss: 0.6338 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8124 - f1_score: 0.6832 - loss: 0.6349 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8140 - f1_score: 0.6938 - loss: 0.6450 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - f1_score: 0.7079 - loss: 0.6253 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7885 - f1_score: 0.6756 - loss: 0.6293 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7980 - f1_score: 0.6864 - loss: 0.6439 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8220 - f1_score: 0.6865 - loss: 0.6397 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8105 - f1_score: 0.6947 - loss: 0.6403 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7954 - f1_score: 0.6596 - loss: 0.6511 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8227 - f1_score: 0.6912 - loss: 0.6427 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8018 - f1_score: 0.6875 - loss: 0.6439 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8195 - f1_score: 0.6877 - loss: 0.6403 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8115 - f1_score: 0.6841 - loss: 0.6457 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8293 - f1_score: 0.7001 - loss: 0.6268 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8238 - f1_score: 0.6967 - loss: 0.6494 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8219 - f1_score: 0.6916 - loss: 0.6301 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8222 - f1_score: 0.7016 - loss: 0.6226 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8160 - f1_score: 0.6926 - loss: 0.6321 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8023 - f1_score: 0.6854 - loss: 0.6289 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8156 - f1_score: 0.6837 - loss: 0.6330 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8101 - f1_score: 0.6737 - loss: 0.6423 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8149 - f1_score: 0.6801 - loss: 0.6388 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8136 - f1_score: 0.6894 - loss: 0.6125 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.5998 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.660098910927553, 0.8864628820960698, 0.43373493975903615)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_18', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - accuracy: 0.8466 - f1_score: 0.5384 - loss: 0.7650 - val_accuracy: 0.8660 - val_f1_score: 0.6865 - val_loss: 0.6664 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8424 - f1_score: 0.6522 - loss: 0.7073 - val_accuracy: 0.8454 - val_f1_score: 0.6849 - val_loss: 0.6375 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7981 - f1_score: 0.6282 - loss: 0.7060 - val_accuracy: 0.8608 - val_f1_score: 0.6581 - val_loss: 0.6306 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8157 - f1_score: 0.6579 - loss: 0.6966 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6370 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7716 - f1_score: 0.6706 - loss: 0.6652 - val_accuracy: 0.7887 - val_f1_score: 0.7374 - val_loss: 0.6230 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8056 - f1_score: 0.6566 - loss: 0.6625 - val_accuracy: 0.8454 - val_f1_score: 0.6986 - val_loss: 0.6364 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8012 - f1_score: 0.6711 - loss: 0.6822 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6073 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8299 - f1_score: 0.6744 - loss: 0.6536 - val_accuracy: 0.7887 - val_f1_score: 0.7449 - val_loss: 0.6172 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8131 - f1_score: 0.6898 - loss: 0.6621 - val_accuracy: 0.8351 - val_f1_score: 0.7183 - val_loss: 0.5930 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8305 - f1_score: 0.6733 - loss: 0.6686 - val_accuracy: 0.8041 - val_f1_score: 0.7470 - val_loss: 0.6079 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7616 - f1_score: 0.6826 - loss: 0.6704 - val_accuracy: 0.8557 - val_f1_score: 0.7016 - val_loss: 0.6022 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8124 - f1_score: 0.6827 - loss: 0.6462 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6068 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8305 - f1_score: 0.6681 - loss: 0.6553 - val_accuracy: 0.8196 - val_f1_score: 0.7284 - val_loss: 0.5975 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7920 - f1_score: 0.6652 - loss: 0.6847 - val_accuracy: 0.8402 - val_f1_score: 0.7287 - val_loss: 0.6039 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7876 - f1_score: 0.6836 - loss: 0.6315 - val_accuracy: 0.7629 - val_f1_score: 0.7455 - val_loss: 0.6386 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8326 - f1_score: 0.6735 - loss: 0.6580 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6227 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8154 - f1_score: 0.6762 - loss: 0.6459 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.5893 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8081 - f1_score: 0.6691 - loss: 0.6667 - val_accuracy: 0.8402 - val_f1_score: 0.7395 - val_loss: 0.5970 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8059 - f1_score: 0.6861 - loss: 0.6302 - val_accuracy: 0.8351 - val_f1_score: 0.7489 - val_loss: 0.5930 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7974 - f1_score: 0.6965 - loss: 0.6487 - val_accuracy: 0.8351 - val_f1_score: 0.7052 - val_loss: 0.6053 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8248 - f1_score: 0.6834 - loss: 0.6634 - val_accuracy: 0.8402 - val_f1_score: 0.7169 - val_loss: 0.6026 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8256 - f1_score: 0.6780 - loss: 0.6456 - val_accuracy: 0.8505 - val_f1_score: 0.7237 - val_loss: 0.6264 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8205 - f1_score: 0.6853 - loss: 0.6585 - val_accuracy: 0.8505 - val_f1_score: 0.7403 - val_loss: 0.6079 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8394 - f1_score: 0.6996 - loss: 0.6317 - val_accuracy: 0.8454 - val_f1_score: 0.7457 - val_loss: 0.6006 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8330 - f1_score: 0.7209 - loss: 0.5986 - val_accuracy: 0.8196 - val_f1_score: 0.7541 - val_loss: 0.6379 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8343 - f1_score: 0.7187 - loss: 0.6212 - val_accuracy: 0.8351 - val_f1_score: 0.7092 - val_loss: 0.6004 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8364 - f1_score: 0.6960 - loss: 0.6314 \n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8296 - f1_score: 0.6898 - loss: 0.6363 - val_accuracy: 0.8402 - val_f1_score: 0.7083 - val_loss: 0.6002 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8527 - f1_score: 0.6947 - loss: 0.6037 - val_accuracy: 0.8505 - val_f1_score: 0.7642 - val_loss: 0.6034 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8093 - f1_score: 0.6808 - loss: 0.6101 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8031 - f1_score: 0.6944 - loss: 0.6202 - val_accuracy: 0.8454 - val_f1_score: 0.7574 - val_loss: 0.6066 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8159 - f1_score: 0.6798 - loss: 0.6124 - val_accuracy: 0.8454 - val_f1_score: 0.7574 - val_loss: 0.5965 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7957 - f1_score: 0.6841 - loss: 0.6139 - val_accuracy: 0.8351 - val_f1_score: 0.7166 - val_loss: 0.5952 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8124 - f1_score: 0.6957 - loss: 0.6258 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5919 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8048 - f1_score: 0.6718 - loss: 0.6260 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5938 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8171 - f1_score: 0.6859 - loss: 0.6135 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5989 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8297 - f1_score: 0.6856 - loss: 0.6098 - val_accuracy: 0.8144 - val_f1_score: 0.7475 - val_loss: 0.6026 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8049 - f1_score: 0.7061 - loss: 0.5996\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8036 - f1_score: 0.7056 - loss: 0.6012 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6001 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8055 - f1_score: 0.6885 - loss: 0.6114 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5967 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8192 - f1_score: 0.6937 - loss: 0.6194 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5973 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8146 - f1_score: 0.7012 - loss: 0.6005 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5972 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8252 - f1_score: 0.6993 - loss: 0.6200 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5989 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8425 - f1_score: 0.7143 - loss: 0.5985 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5983 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8147 - f1_score: 0.7030 - loss: 0.5903 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5997 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8123 - f1_score: 0.7035 - loss: 0.6130 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6002 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8214 - f1_score: 0.7029 - loss: 0.6018 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5980 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8103 - f1_score: 0.6858 - loss: 0.6110 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5991 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7928 - f1_score: 0.6875 - loss: 0.6097\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7954 - f1_score: 0.6896 - loss: 0.6085 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5984 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8243 - f1_score: 0.7194 - loss: 0.5732 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5984 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8185 - f1_score: 0.7110 - loss: 0.5895 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5984 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8263 - f1_score: 0.7248 - loss: 0.5764 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5988 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8120 - f1_score: 0.6945 - loss: 0.6041 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5991 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8046 - f1_score: 0.6915 - loss: 0.6003 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5991 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8235 - f1_score: 0.7082 - loss: 0.6042 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5990 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8282 - f1_score: 0.7039 - loss: 0.5986 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5990 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8151 - f1_score: 0.7119 - loss: 0.6128 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5991 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8179 - f1_score: 0.6999 - loss: 0.5912 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5993 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8230 - f1_score: 0.7211 - loss: 0.5940\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8221 - f1_score: 0.7197 - loss: 0.5945 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8103 - f1_score: 0.7106 - loss: 0.5919 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7911 - f1_score: 0.7025 - loss: 0.5946 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7992 - f1_score: 0.7012 - loss: 0.6066 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8112 - f1_score: 0.6925 - loss: 0.6089 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8178 - f1_score: 0.7145 - loss: 0.5921 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8049 - f1_score: 0.7058 - loss: 0.5902 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8166 - f1_score: 0.7074 - loss: 0.5877 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7935 - f1_score: 0.7093 - loss: 0.5907 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8270 - f1_score: 0.7069 - loss: 0.6036 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8029 - f1_score: 0.7100 - loss: 0.5838 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8275 - f1_score: 0.7147 - loss: 0.6014 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8166 - f1_score: 0.6916 - loss: 0.6116 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8037 - f1_score: 0.6942 - loss: 0.6047 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8097 - f1_score: 0.6980 - loss: 0.6106 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8098 - f1_score: 0.6991 - loss: 0.6113 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8130 - f1_score: 0.7061 - loss: 0.5870 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8149 - f1_score: 0.6964 - loss: 0.5928 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7924 - f1_score: 0.6795 - loss: 0.6032 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7991 - f1_score: 0.6905 - loss: 0.6069 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8147 - f1_score: 0.7069 - loss: 0.6057 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8311 - f1_score: 0.7214 - loss: 0.5960 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8123 - f1_score: 0.7013 - loss: 0.6277 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8117 - f1_score: 0.6806 - loss: 0.6222 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8103 - f1_score: 0.6930 - loss: 0.5926 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8088 - f1_score: 0.6948 - loss: 0.5950 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8006 - f1_score: 0.6973 - loss: 0.5922 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8045 - f1_score: 0.6931 - loss: 0.6078 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7974 - f1_score: 0.7153 - loss: 0.5918 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8456 - f1_score: 0.7050 - loss: 0.5927 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8290 - f1_score: 0.7038 - loss: 0.6046 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7935 - f1_score: 0.6838 - loss: 0.6044 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8211 - f1_score: 0.7039 - loss: 0.5975 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8152 - f1_score: 0.7038 - loss: 0.5985 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8117 - f1_score: 0.6948 - loss: 0.5925 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8204 - f1_score: 0.6928 - loss: 0.6112 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8231 - f1_score: 0.7173 - loss: 0.5927 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8209 - f1_score: 0.7196 - loss: 0.5969 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8280 - f1_score: 0.7165 - loss: 0.5910 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5994 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8213 - f1_score: 0.7126 - loss: 0.5930 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8014 - f1_score: 0.6775 - loss: 0.6108 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8119 - f1_score: 0.7022 - loss: 0.5918 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7919 - f1_score: 0.7028 - loss: 0.6166 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8111 - f1_score: 0.7023 - loss: 0.5958 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.5995 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6646076927146711, 0.9023861171366594, 0.4268292682926829)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_19', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 162ms/step - accuracy: 0.7656 - f1_score: 0.5187 - loss: 0.8038 - val_accuracy: 0.8505 - val_f1_score: 0.5531 - val_loss: 0.6797 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8455 - f1_score: 0.5650 - loss: 0.7221 - val_accuracy: 0.8093 - val_f1_score: 0.7123 - val_loss: 0.6589 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7879 - f1_score: 0.6568 - loss: 0.6974 - val_accuracy: 0.8402 - val_f1_score: 0.7142 - val_loss: 0.6287 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8025 - f1_score: 0.6441 - loss: 0.7121 - val_accuracy: 0.8351 - val_f1_score: 0.7166 - val_loss: 0.6203 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8122 - f1_score: 0.6542 - loss: 0.6750 - val_accuracy: 0.8351 - val_f1_score: 0.7068 - val_loss: 0.6871 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8107 - f1_score: 0.6635 - loss: 0.6754 - val_accuracy: 0.8454 - val_f1_score: 0.7148 - val_loss: 0.6063 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8176 - f1_score: 0.6550 - loss: 0.6647 - val_accuracy: 0.8299 - val_f1_score: 0.7422 - val_loss: 0.6303 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8099 - f1_score: 0.6880 - loss: 0.6501 - val_accuracy: 0.7732 - val_f1_score: 0.7344 - val_loss: 0.6208 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7647 - f1_score: 0.6777 - loss: 0.6773 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6337 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8194 - f1_score: 0.6882 - loss: 0.6537 - val_accuracy: 0.8557 - val_f1_score: 0.6926 - val_loss: 0.6336 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - f1_score: 0.6646 - loss: 0.6673 - val_accuracy: 0.7938 - val_f1_score: 0.7438 - val_loss: 0.6345 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7804 - f1_score: 0.6873 - loss: 0.6500 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.6507 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8074 - f1_score: 0.6727 - loss: 0.6658 - val_accuracy: 0.8093 - val_f1_score: 0.7433 - val_loss: 0.6050 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8061 - f1_score: 0.6831 - loss: 0.6451 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.5982 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8201 - f1_score: 0.6846 - loss: 0.6503 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6077 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8027 - f1_score: 0.6995 - loss: 0.6392 - val_accuracy: 0.8505 - val_f1_score: 0.6934 - val_loss: 0.6039 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.6730 - loss: 0.6830 - val_accuracy: 0.8505 - val_f1_score: 0.7320 - val_loss: 0.6076 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8305 - f1_score: 0.6801 - loss: 0.6537 - val_accuracy: 0.8144 - val_f1_score: 0.7475 - val_loss: 0.6165 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8154 - f1_score: 0.7125 - loss: 0.6261 - val_accuracy: 0.8196 - val_f1_score: 0.7465 - val_loss: 0.5977 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8401 - f1_score: 0.7081 - loss: 0.6236 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6054 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7939 - f1_score: 0.6988 - loss: 0.6442 - val_accuracy: 0.7835 - val_f1_score: 0.7407 - val_loss: 0.6376 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7996 - f1_score: 0.6835 - loss: 0.6368 - val_accuracy: 0.8557 - val_f1_score: 0.7536 - val_loss: 0.6017 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8524 - f1_score: 0.6938 - loss: 0.6310 - val_accuracy: 0.7732 - val_f1_score: 0.7344 - val_loss: 0.6279 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7878 - f1_score: 0.7104 - loss: 0.6495 - val_accuracy: 0.8454 - val_f1_score: 0.7548 - val_loss: 0.6401 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8206 - f1_score: 0.7093 - loss: 0.6421 - val_accuracy: 0.7526 - val_f1_score: 0.7367 - val_loss: 0.6137 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8018 - f1_score: 0.6944 - loss: 0.6353 - val_accuracy: 0.8505 - val_f1_score: 0.7617 - val_loss: 0.6169 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8311 - f1_score: 0.6828 - loss: 0.6540 - val_accuracy: 0.8505 - val_f1_score: 0.6977 - val_loss: 0.6199 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8216 - f1_score: 0.6505 - loss: 0.6540 - val_accuracy: 0.7680 - val_f1_score: 0.7335 - val_loss: 0.6304 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8108 - f1_score: 0.6707 - loss: 0.6532\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8108 - f1_score: 0.6711 - loss: 0.6529 - val_accuracy: 0.8402 - val_f1_score: 0.6813 - val_loss: 0.6883 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8603 - f1_score: 0.6966 - loss: 0.6466 - val_accuracy: 0.8196 - val_f1_score: 0.7597 - val_loss: 0.6174 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8123 - f1_score: 0.7143 - loss: 0.5899 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6127 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8230 - f1_score: 0.7130 - loss: 0.5996 - val_accuracy: 0.8557 - val_f1_score: 0.6881 - val_loss: 0.6358 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8494 - f1_score: 0.6874 - loss: 0.6027 - val_accuracy: 0.7990 - val_f1_score: 0.7405 - val_loss: 0.6169 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8193 - f1_score: 0.7250 - loss: 0.5943 - val_accuracy: 0.8351 - val_f1_score: 0.7215 - val_loss: 0.6165 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8333 - f1_score: 0.7151 - loss: 0.5935 - val_accuracy: 0.8144 - val_f1_score: 0.7182 - val_loss: 0.6176 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8449 - f1_score: 0.7313 - loss: 0.5707 - val_accuracy: 0.8402 - val_f1_score: 0.7207 - val_loss: 0.6261 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8269 - f1_score: 0.7183 - loss: 0.6010 - val_accuracy: 0.7371 - val_f1_score: 0.7083 - val_loss: 0.6449 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7744 - f1_score: 0.7097 - loss: 0.5958 - val_accuracy: 0.8402 - val_f1_score: 0.7207 - val_loss: 0.6233 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8169 - f1_score: 0.7167 - loss: 0.5901 \n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8176 - f1_score: 0.7173 - loss: 0.5894 - val_accuracy: 0.8402 - val_f1_score: 0.7035 - val_loss: 0.6321 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8550 - f1_score: 0.7138 - loss: 0.5769 - val_accuracy: 0.8041 - val_f1_score: 0.7219 - val_loss: 0.6234 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8287 - f1_score: 0.7442 - loss: 0.5689 - val_accuracy: 0.8299 - val_f1_score: 0.7238 - val_loss: 0.6246 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8472 - f1_score: 0.7423 - loss: 0.5603 - val_accuracy: 0.8196 - val_f1_score: 0.7205 - val_loss: 0.6242 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8215 - f1_score: 0.7155 - loss: 0.5758 - val_accuracy: 0.8196 - val_f1_score: 0.7205 - val_loss: 0.6243 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8331 - f1_score: 0.7349 - loss: 0.5689 - val_accuracy: 0.8196 - val_f1_score: 0.7205 - val_loss: 0.6260 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8305 - f1_score: 0.7209 - loss: 0.5764 - val_accuracy: 0.8299 - val_f1_score: 0.7238 - val_loss: 0.6265 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8633 - f1_score: 0.7531 - loss: 0.5508 - val_accuracy: 0.8144 - val_f1_score: 0.7225 - val_loss: 0.6276 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8446 - f1_score: 0.7331 - loss: 0.5739 - val_accuracy: 0.8247 - val_f1_score: 0.7246 - val_loss: 0.6279 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8600 - f1_score: 0.7152 - loss: 0.5784 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6284 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8430 - f1_score: 0.7301 - loss: 0.5764\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8427 - f1_score: 0.7301 - loss: 0.5757 - val_accuracy: 0.8093 - val_f1_score: 0.7184 - val_loss: 0.6292 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8237 - f1_score: 0.7224 - loss: 0.5670 - val_accuracy: 0.8093 - val_f1_score: 0.7184 - val_loss: 0.6292 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8787 - f1_score: 0.7307 - loss: 0.5790 - val_accuracy: 0.8144 - val_f1_score: 0.7225 - val_loss: 0.6294 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8429 - f1_score: 0.7400 - loss: 0.5751 - val_accuracy: 0.8144 - val_f1_score: 0.7225 - val_loss: 0.6294 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8326 - f1_score: 0.7254 - loss: 0.5782 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6296 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8338 - f1_score: 0.7409 - loss: 0.5631 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6298 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8467 - f1_score: 0.7292 - loss: 0.5596 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6297 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8403 - f1_score: 0.7268 - loss: 0.5645 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6298 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8483 - f1_score: 0.7436 - loss: 0.5765 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6300 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8368 - f1_score: 0.7272 - loss: 0.5890 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8234 - f1_score: 0.7172 - loss: 0.5588\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8246 - f1_score: 0.7181 - loss: 0.5594 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8374 - f1_score: 0.7410 - loss: 0.5487 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8222 - f1_score: 0.7061 - loss: 0.6078 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8555 - f1_score: 0.7498 - loss: 0.5407 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8469 - f1_score: 0.7287 - loss: 0.5511 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8284 - f1_score: 0.7271 - loss: 0.5619 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8620 - f1_score: 0.7285 - loss: 0.5626 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8290 - f1_score: 0.7263 - loss: 0.5667 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8513 - f1_score: 0.7267 - loss: 0.5717 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8367 - f1_score: 0.7354 - loss: 0.5676 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8332 - f1_score: 0.7196 - loss: 0.5772 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8325 - f1_score: 0.7215 - loss: 0.5903 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8331 - f1_score: 0.7321 - loss: 0.5716 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8301 - f1_score: 0.7227 - loss: 0.5709 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8420 - f1_score: 0.7333 - loss: 0.5721 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8328 - f1_score: 0.7330 - loss: 0.5680 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8374 - f1_score: 0.7240 - loss: 0.5563 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8318 - f1_score: 0.7134 - loss: 0.5837 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8321 - f1_score: 0.7281 - loss: 0.5640 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8186 - f1_score: 0.7255 - loss: 0.5777 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8296 - f1_score: 0.7153 - loss: 0.5947 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8245 - f1_score: 0.7182 - loss: 0.5786 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8596 - f1_score: 0.7328 - loss: 0.5741 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8419 - f1_score: 0.7185 - loss: 0.5674 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8341 - f1_score: 0.7243 - loss: 0.5634 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8383 - f1_score: 0.7371 - loss: 0.5472 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8353 - f1_score: 0.7249 - loss: 0.5628 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8465 - f1_score: 0.7265 - loss: 0.5622 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8336 - f1_score: 0.7318 - loss: 0.5718 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8590 - f1_score: 0.7409 - loss: 0.5595 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8224 - f1_score: 0.7086 - loss: 0.5997 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8305 - f1_score: 0.7345 - loss: 0.5653 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8079 - f1_score: 0.7270 - loss: 0.5733 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8361 - f1_score: 0.7295 - loss: 0.5515 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8322 - f1_score: 0.7290 - loss: 0.5617 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8378 - f1_score: 0.7261 - loss: 0.5746 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8357 - f1_score: 0.7492 - loss: 0.5516 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8424 - f1_score: 0.7226 - loss: 0.5840 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8385 - f1_score: 0.7299 - loss: 0.5659 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8416 - f1_score: 0.7343 - loss: 0.5555 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8540 - f1_score: 0.7322 - loss: 0.5514 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8434 - f1_score: 0.7411 - loss: 0.5573 - val_accuracy: 0.8196 - val_f1_score: 0.7267 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6540825517935676, 0.8884120171673819, 0.41975308641975306)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_20', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.8581 - f1_score: 0.5300 - loss: 0.7599 - val_accuracy: 0.8557 - val_f1_score: 0.7215 - val_loss: 0.6775 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8087 - f1_score: 0.6239 - loss: 0.6969 - val_accuracy: 0.8866 - val_f1_score: 0.6744 - val_loss: 0.6585 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7937 - f1_score: 0.6175 - loss: 0.7417 - val_accuracy: 0.7835 - val_f1_score: 0.7386 - val_loss: 0.8417 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7670 - f1_score: 0.6677 - loss: 0.7348 - val_accuracy: 0.8505 - val_f1_score: 0.7223 - val_loss: 0.6016 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8147 - f1_score: 0.6651 - loss: 0.6707 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.6240 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7908 - f1_score: 0.6461 - loss: 0.6713 - val_accuracy: 0.8454 - val_f1_score: 0.7264 - val_loss: 0.6024 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8214 - f1_score: 0.6864 - loss: 0.6755 - val_accuracy: 0.7990 - val_f1_score: 0.7457 - val_loss: 0.6087 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7612 - f1_score: 0.6811 - loss: 0.6672 - val_accuracy: 0.8299 - val_f1_score: 0.7005 - val_loss: 0.6023 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7907 - f1_score: 0.6883 - loss: 0.6484 - val_accuracy: 0.8196 - val_f1_score: 0.7362 - val_loss: 0.6406 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8175 - f1_score: 0.6560 - loss: 0.6734 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.5981 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7864 - f1_score: 0.6630 - loss: 0.6551 - val_accuracy: 0.8402 - val_f1_score: 0.7240 - val_loss: 0.6031 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8330 - f1_score: 0.6873 - loss: 0.6377 - val_accuracy: 0.8402 - val_f1_score: 0.7416 - val_loss: 0.6175 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7978 - f1_score: 0.6801 - loss: 0.6451 - val_accuracy: 0.7990 - val_f1_score: 0.7480 - val_loss: 0.6215 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7985 - f1_score: 0.6839 - loss: 0.6455 - val_accuracy: 0.8299 - val_f1_score: 0.7366 - val_loss: 0.6143 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7878 - f1_score: 0.7016 - loss: 0.6558 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6347 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8138 - f1_score: 0.7237 - loss: 0.6457 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.6114 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8178 - f1_score: 0.6805 - loss: 0.6204 - val_accuracy: 0.8299 - val_f1_score: 0.7334 - val_loss: 0.5886 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8124 - f1_score: 0.6721 - loss: 0.6582 - val_accuracy: 0.7732 - val_f1_score: 0.7323 - val_loss: 0.6695 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7981 - f1_score: 0.7055 - loss: 0.6361 - val_accuracy: 0.8299 - val_f1_score: 0.7304 - val_loss: 0.6102 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7953 - f1_score: 0.6684 - loss: 0.6598 - val_accuracy: 0.8351 - val_f1_score: 0.7345 - val_loss: 0.6065 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8096 - f1_score: 0.6768 - loss: 0.6773 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6221 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7788 - f1_score: 0.6866 - loss: 0.6175 - val_accuracy: 0.7835 - val_f1_score: 0.7460 - val_loss: 0.6161 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7884 - f1_score: 0.6872 - loss: 0.6620 - val_accuracy: 0.8454 - val_f1_score: 0.7208 - val_loss: 0.6044 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7909 - f1_score: 0.6610 - loss: 0.6506 - val_accuracy: 0.8557 - val_f1_score: 0.7395 - val_loss: 0.5899 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8070 - f1_score: 0.6837 - loss: 0.6252 - val_accuracy: 0.8402 - val_f1_score: 0.7042 - val_loss: 0.5929 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8030 - f1_score: 0.6609 - loss: 0.6438 - val_accuracy: 0.8299 - val_f1_score: 0.7574 - val_loss: 0.6237 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7732 - f1_score: 0.6769 - loss: 0.6537 \n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7755 - f1_score: 0.6777 - loss: 0.6527 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.5986 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7944 - f1_score: 0.6937 - loss: 0.6343 - val_accuracy: 0.8299 - val_f1_score: 0.7472 - val_loss: 0.6028 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8065 - f1_score: 0.6655 - loss: 0.6340 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6051 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8429 - f1_score: 0.6964 - loss: 0.6263 - val_accuracy: 0.8093 - val_f1_score: 0.7433 - val_loss: 0.6115 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7725 - f1_score: 0.6865 - loss: 0.6235 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6044 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8182 - f1_score: 0.6965 - loss: 0.6151 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6033 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7966 - f1_score: 0.6987 - loss: 0.6194 - val_accuracy: 0.8454 - val_f1_score: 0.7471 - val_loss: 0.5994 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8346 - f1_score: 0.7091 - loss: 0.6026 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6019 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7895 - f1_score: 0.6919 - loss: 0.6296 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6042 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7694 - f1_score: 0.6885 - loss: 0.6178 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6008 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7928 - f1_score: 0.6708 - loss: 0.6165\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7943 - f1_score: 0.6726 - loss: 0.6162 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6006 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8163 - f1_score: 0.6894 - loss: 0.5986 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7993 - f1_score: 0.6755 - loss: 0.6123 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8351 - f1_score: 0.7190 - loss: 0.5969 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6003 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8150 - f1_score: 0.6837 - loss: 0.6318 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6010 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8203 - f1_score: 0.7093 - loss: 0.5942 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7976 - f1_score: 0.7016 - loss: 0.6132 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6018 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8018 - f1_score: 0.7021 - loss: 0.6098 - val_accuracy: 0.8351 - val_f1_score: 0.7540 - val_loss: 0.6023 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8292 - f1_score: 0.6935 - loss: 0.6188 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.6027 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8141 - f1_score: 0.6856 - loss: 0.6201 - val_accuracy: 0.8454 - val_f1_score: 0.7514 - val_loss: 0.6018 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8611 - f1_score: 0.7158 - loss: 0.6009 \n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8586 - f1_score: 0.7151 - loss: 0.6008 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.6023 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8500 - f1_score: 0.7287 - loss: 0.5571 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.6022 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8356 - f1_score: 0.7236 - loss: 0.6010 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.6025 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8473 - f1_score: 0.7262 - loss: 0.5763 - val_accuracy: 0.8402 - val_f1_score: 0.7523 - val_loss: 0.6024 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8098 - f1_score: 0.7199 - loss: 0.5871 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8089 - f1_score: 0.7007 - loss: 0.5934 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8153 - f1_score: 0.6958 - loss: 0.6024 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8125 - f1_score: 0.6965 - loss: 0.6167 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8191 - f1_score: 0.6998 - loss: 0.5754 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8194 - f1_score: 0.6914 - loss: 0.6076 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8393 - f1_score: 0.6982 - loss: 0.6071\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8372 - f1_score: 0.7017 - loss: 0.6044 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8233 - f1_score: 0.7006 - loss: 0.6005 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8288 - f1_score: 0.7097 - loss: 0.5920 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8318 - f1_score: 0.7157 - loss: 0.5975 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8296 - f1_score: 0.7146 - loss: 0.6177 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8375 - f1_score: 0.7115 - loss: 0.5976 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8359 - f1_score: 0.6999 - loss: 0.6010 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8085 - f1_score: 0.6947 - loss: 0.6134 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8031 - f1_score: 0.7149 - loss: 0.5761 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8227 - f1_score: 0.7105 - loss: 0.5977 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8262 - f1_score: 0.7022 - loss: 0.6276 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8058 - f1_score: 0.7013 - loss: 0.6122 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8331 - f1_score: 0.7164 - loss: 0.6074 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8363 - f1_score: 0.7286 - loss: 0.5729 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8252 - f1_score: 0.7156 - loss: 0.5964 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8175 - f1_score: 0.7036 - loss: 0.6091 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8086 - f1_score: 0.7066 - loss: 0.6055 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8389 - f1_score: 0.7094 - loss: 0.5900 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8217 - f1_score: 0.6958 - loss: 0.6122 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8299 - f1_score: 0.7220 - loss: 0.5852 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8326 - f1_score: 0.6980 - loss: 0.6116 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8408 - f1_score: 0.7042 - loss: 0.5944 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8182 - f1_score: 0.6982 - loss: 0.6044 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8044 - f1_score: 0.7005 - loss: 0.6097 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8431 - f1_score: 0.7240 - loss: 0.5953 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8373 - f1_score: 0.7228 - loss: 0.5814 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8151 - f1_score: 0.6830 - loss: 0.6014 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8422 - f1_score: 0.7262 - loss: 0.5774 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8107 - f1_score: 0.6964 - loss: 0.6212 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8426 - f1_score: 0.7169 - loss: 0.6169 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8085 - f1_score: 0.6918 - loss: 0.5915 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8309 - f1_score: 0.7187 - loss: 0.5908 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8243 - f1_score: 0.7290 - loss: 0.5746 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8234 - f1_score: 0.7040 - loss: 0.5989 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8249 - f1_score: 0.7014 - loss: 0.6008 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8109 - f1_score: 0.7069 - loss: 0.5896 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8289 - f1_score: 0.6992 - loss: 0.5876 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8312 - f1_score: 0.7070 - loss: 0.6149 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8347 - f1_score: 0.7080 - loss: 0.5903 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8309 - f1_score: 0.7043 - loss: 0.5992 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8219 - f1_score: 0.7077 - loss: 0.5911 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8240 - f1_score: 0.7028 - loss: 0.5961 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8410 - f1_score: 0.7128 - loss: 0.5765 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8365 - f1_score: 0.7018 - loss: 0.5920 - val_accuracy: 0.8351 - val_f1_score: 0.7481 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6630805384625833, 0.8984881209503239, 0.4276729559748428)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_21', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.7326 - f1_score: 0.5313 - loss: 0.7758 - val_accuracy: 0.8763 - val_f1_score: 0.6345 - val_loss: 0.6552 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8536 - f1_score: 0.6119 - loss: 0.7068 - val_accuracy: 0.8711 - val_f1_score: 0.7159 - val_loss: 0.6436 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8416 - f1_score: 0.6562 - loss: 0.6659 - val_accuracy: 0.8196 - val_f1_score: 0.7321 - val_loss: 0.6367 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8144 - f1_score: 0.6664 - loss: 0.6863 - val_accuracy: 0.8505 - val_f1_score: 0.7140 - val_loss: 0.6132 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7602 - f1_score: 0.6696 - loss: 0.6897 - val_accuracy: 0.8505 - val_f1_score: 0.7065 - val_loss: 0.6275 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8247 - f1_score: 0.6196 - loss: 0.7122 - val_accuracy: 0.7887 - val_f1_score: 0.7374 - val_loss: 0.6196 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7844 - f1_score: 0.6669 - loss: 0.6836 - val_accuracy: 0.5464 - val_f1_score: 0.6255 - val_loss: 0.7732 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7344 - f1_score: 0.6665 - loss: 0.7398 - val_accuracy: 0.7165 - val_f1_score: 0.7106 - val_loss: 0.6599 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8057 - f1_score: 0.6993 - loss: 0.6957 - val_accuracy: 0.8505 - val_f1_score: 0.6977 - val_loss: 0.6101 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8210 - f1_score: 0.6638 - loss: 0.6894 - val_accuracy: 0.8454 - val_f1_score: 0.6851 - val_loss: 0.6250 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8320 - f1_score: 0.6518 - loss: 0.6797 - val_accuracy: 0.8454 - val_f1_score: 0.7328 - val_loss: 0.6164 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8018 - f1_score: 0.6675 - loss: 0.6559 - val_accuracy: 0.8041 - val_f1_score: 0.7447 - val_loss: 0.6238 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8292 - f1_score: 0.6785 - loss: 0.6637 - val_accuracy: 0.8505 - val_f1_score: 0.7025 - val_loss: 0.6171 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8136 - f1_score: 0.6620 - loss: 0.6443 - val_accuracy: 0.8454 - val_f1_score: 0.7197 - val_loss: 0.6118 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8095 - f1_score: 0.6726 - loss: 0.6622 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.5988 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8067 - f1_score: 0.7016 - loss: 0.6421 - val_accuracy: 0.8505 - val_f1_score: 0.7025 - val_loss: 0.6071 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8158 - f1_score: 0.6633 - loss: 0.6865 - val_accuracy: 0.8247 - val_f1_score: 0.7380 - val_loss: 0.6004 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7984 - f1_score: 0.6943 - loss: 0.6227 - val_accuracy: 0.8505 - val_f1_score: 0.7285 - val_loss: 0.6274 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8218 - f1_score: 0.6856 - loss: 0.6280 - val_accuracy: 0.7835 - val_f1_score: 0.7306 - val_loss: 0.6437 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8105 - f1_score: 0.6987 - loss: 0.6429 - val_accuracy: 0.8454 - val_f1_score: 0.7346 - val_loss: 0.6033 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8125 - f1_score: 0.6915 - loss: 0.6368 - val_accuracy: 0.8196 - val_f1_score: 0.7439 - val_loss: 0.6170 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8004 - f1_score: 0.6898 - loss: 0.6309 - val_accuracy: 0.8402 - val_f1_score: 0.7042 - val_loss: 0.6093 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8474 - f1_score: 0.6873 - loss: 0.6214 - val_accuracy: 0.7784 - val_f1_score: 0.7365 - val_loss: 0.6314 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7718 - f1_score: 0.6931 - loss: 0.6462 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.5948 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8212 - f1_score: 0.6852 - loss: 0.6477 - val_accuracy: 0.8505 - val_f1_score: 0.7449 - val_loss: 0.6190 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8158 - f1_score: 0.7004 - loss: 0.6304 - val_accuracy: 0.8247 - val_f1_score: 0.7430 - val_loss: 0.6081 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8190 - f1_score: 0.6930 - loss: 0.6505 - val_accuracy: 0.7938 - val_f1_score: 0.7336 - val_loss: 0.6347 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7992 - f1_score: 0.7010 - loss: 0.6138 - val_accuracy: 0.8144 - val_f1_score: 0.7398 - val_loss: 0.5996 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8076 - f1_score: 0.6954 - loss: 0.6321 - val_accuracy: 0.8299 - val_f1_score: 0.7445 - val_loss: 0.6022 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8274 - f1_score: 0.6908 - loss: 0.6452 - val_accuracy: 0.8402 - val_f1_score: 0.7556 - val_loss: 0.6257 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8222 - f1_score: 0.6891 - loss: 0.6202 - val_accuracy: 0.8144 - val_f1_score: 0.7398 - val_loss: 0.6321 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8146 - f1_score: 0.6922 - loss: 0.6337 - val_accuracy: 0.8402 - val_f1_score: 0.7429 - val_loss: 0.6060 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8464 - f1_score: 0.6766 - loss: 0.6250 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6182 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8268 - f1_score: 0.7100 - loss: 0.6059\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8233 - f1_score: 0.7086 - loss: 0.6084 - val_accuracy: 0.7990 - val_f1_score: 0.7454 - val_loss: 0.6182 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8029 - f1_score: 0.7108 - loss: 0.6037 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6040 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8168 - f1_score: 0.6766 - loss: 0.6193 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6085 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7949 - f1_score: 0.6798 - loss: 0.6355 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6055 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8199 - f1_score: 0.7074 - loss: 0.5927 - val_accuracy: 0.8299 - val_f1_score: 0.7445 - val_loss: 0.6115 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8053 - f1_score: 0.7134 - loss: 0.5908 - val_accuracy: 0.8299 - val_f1_score: 0.7445 - val_loss: 0.6068 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8348 - f1_score: 0.6953 - loss: 0.6007 - val_accuracy: 0.8351 - val_f1_score: 0.7436 - val_loss: 0.6005 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8292 - f1_score: 0.6852 - loss: 0.5990 - val_accuracy: 0.8196 - val_f1_score: 0.7412 - val_loss: 0.6191 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8161 - f1_score: 0.6857 - loss: 0.6037 - val_accuracy: 0.7990 - val_f1_score: 0.7377 - val_loss: 0.6435 - learning_rate: 1.0000e-03\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8055 - f1_score: 0.6991 - loss: 0.5708 - val_accuracy: 0.8196 - val_f1_score: 0.7255 - val_loss: 0.6266 - learning_rate: 1.0000e-03\n",
            "Epoch 44/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8027 - f1_score: 0.6810 - loss: 0.5854\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8042 - f1_score: 0.6853 - loss: 0.5826 - val_accuracy: 0.7938 - val_f1_score: 0.7413 - val_loss: 0.6760 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8164 - f1_score: 0.7081 - loss: 0.5556 - val_accuracy: 0.8144 - val_f1_score: 0.7343 - val_loss: 0.6333 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8095 - f1_score: 0.6862 - loss: 0.5551 - val_accuracy: 0.8196 - val_f1_score: 0.7412 - val_loss: 0.6389 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8157 - f1_score: 0.7133 - loss: 0.5159 - val_accuracy: 0.8196 - val_f1_score: 0.7412 - val_loss: 0.6412 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8106 - f1_score: 0.6961 - loss: 0.5628 - val_accuracy: 0.8144 - val_f1_score: 0.7343 - val_loss: 0.6396 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8235 - f1_score: 0.6953 - loss: 0.5251 - val_accuracy: 0.8041 - val_f1_score: 0.7391 - val_loss: 0.6476 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7965 - f1_score: 0.7031 - loss: 0.5475 - val_accuracy: 0.8093 - val_f1_score: 0.7353 - val_loss: 0.6428 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8139 - f1_score: 0.6943 - loss: 0.5338 - val_accuracy: 0.8144 - val_f1_score: 0.7422 - val_loss: 0.6457 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8211 - f1_score: 0.7009 - loss: 0.5317 - val_accuracy: 0.8144 - val_f1_score: 0.7449 - val_loss: 0.6488 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8323 - f1_score: 0.7241 - loss: 0.5131 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6494 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8004 - f1_score: 0.7327 - loss: 0.5219\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8023 - f1_score: 0.7277 - loss: 0.5242 - val_accuracy: 0.8144 - val_f1_score: 0.7449 - val_loss: 0.6517 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8131 - f1_score: 0.7007 - loss: 0.5231 - val_accuracy: 0.8144 - val_f1_score: 0.7449 - val_loss: 0.6520 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7964 - f1_score: 0.7083 - loss: 0.5355 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6519 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8031 - f1_score: 0.7091 - loss: 0.5434 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6512 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8260 - f1_score: 0.7005 - loss: 0.5237 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6515 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8104 - f1_score: 0.6949 - loss: 0.5357 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6516 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8009 - f1_score: 0.7128 - loss: 0.5217 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6524 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8038 - f1_score: 0.7057 - loss: 0.5215 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6522 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8196 - f1_score: 0.6989 - loss: 0.5240 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6524 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8160 - f1_score: 0.7133 - loss: 0.5225 - val_accuracy: 0.8093 - val_f1_score: 0.7381 - val_loss: 0.6521 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8257 - f1_score: 0.7151 - loss: 0.5324\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8230 - f1_score: 0.7129 - loss: 0.5324 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8188 - f1_score: 0.7154 - loss: 0.5318 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8057 - f1_score: 0.7039 - loss: 0.5450 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8136 - f1_score: 0.7104 - loss: 0.5281 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8227 - f1_score: 0.7255 - loss: 0.5120 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8086 - f1_score: 0.6958 - loss: 0.5230 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8112 - f1_score: 0.6957 - loss: 0.5440 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8080 - f1_score: 0.7057 - loss: 0.5242 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8236 - f1_score: 0.7038 - loss: 0.5349 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8214 - f1_score: 0.7187 - loss: 0.5304 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6526 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8081 - f1_score: 0.7209 - loss: 0.5076 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6527 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8091 - f1_score: 0.7082 - loss: 0.5407 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8081 - f1_score: 0.7137 - loss: 0.5207 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7956 - f1_score: 0.7138 - loss: 0.5270 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7997 - f1_score: 0.7051 - loss: 0.5409 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8141 - f1_score: 0.7028 - loss: 0.5213 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8246 - f1_score: 0.7197 - loss: 0.5275 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8276 - f1_score: 0.7081 - loss: 0.5152 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6529 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8193 - f1_score: 0.7204 - loss: 0.5042 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6529 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7865 - f1_score: 0.6965 - loss: 0.5271 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6529 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7873 - f1_score: 0.6892 - loss: 0.5407 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6529 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8130 - f1_score: 0.7019 - loss: 0.5365 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7976 - f1_score: 0.6984 - loss: 0.5360 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8072 - f1_score: 0.6972 - loss: 0.5351 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8188 - f1_score: 0.7090 - loss: 0.5327 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8244 - f1_score: 0.7215 - loss: 0.5190 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8153 - f1_score: 0.7076 - loss: 0.5278 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8235 - f1_score: 0.7204 - loss: 0.5102 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8175 - f1_score: 0.7098 - loss: 0.5181 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7959 - f1_score: 0.7039 - loss: 0.5423 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8045 - f1_score: 0.6941 - loss: 0.5449 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8288 - f1_score: 0.7064 - loss: 0.5213 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6530 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7990 - f1_score: 0.7106 - loss: 0.5394 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6531 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8014 - f1_score: 0.7053 - loss: 0.5281 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6531 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8034 - f1_score: 0.6980 - loss: 0.5335 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6531 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8011 - f1_score: 0.7153 - loss: 0.5324 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6531 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8118 - f1_score: 0.6990 - loss: 0.5347 - val_accuracy: 0.8041 - val_f1_score: 0.7312 - val_loss: 0.6531 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6222269539411522, 0.8763557483731019, 0.36809815950920244)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_22', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.7502 - f1_score: 0.5377 - loss: 0.7763 - val_accuracy: 0.8814 - val_f1_score: 0.6550 - val_loss: 0.6679 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8690 - f1_score: 0.6300 - loss: 0.7033 - val_accuracy: 0.7526 - val_f1_score: 0.7151 - val_loss: 0.6722 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7854 - f1_score: 0.6696 - loss: 0.6999 - val_accuracy: 0.8454 - val_f1_score: 0.7183 - val_loss: 0.6352 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7975 - f1_score: 0.6670 - loss: 0.6950 - val_accuracy: 0.8557 - val_f1_score: 0.7144 - val_loss: 0.6252 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8152 - f1_score: 0.6478 - loss: 0.6854 - val_accuracy: 0.8247 - val_f1_score: 0.7463 - val_loss: 0.6114 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7758 - f1_score: 0.6747 - loss: 0.6679 - val_accuracy: 0.8505 - val_f1_score: 0.7337 - val_loss: 0.6254 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7925 - f1_score: 0.6859 - loss: 0.6628 - val_accuracy: 0.7113 - val_f1_score: 0.7165 - val_loss: 0.6556 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7755 - f1_score: 0.6772 - loss: 0.6730 - val_accuracy: 0.8608 - val_f1_score: 0.6778 - val_loss: 0.6365 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8290 - f1_score: 0.6631 - loss: 0.6690 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6058 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8033 - f1_score: 0.6695 - loss: 0.6595 - val_accuracy: 0.8557 - val_f1_score: 0.6926 - val_loss: 0.6238 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8399 - f1_score: 0.6686 - loss: 0.6697 - val_accuracy: 0.8299 - val_f1_score: 0.7395 - val_loss: 0.6192 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7972 - f1_score: 0.6880 - loss: 0.6418 - val_accuracy: 0.8247 - val_f1_score: 0.7353 - val_loss: 0.6134 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8025 - f1_score: 0.6810 - loss: 0.6521 - val_accuracy: 0.8402 - val_f1_score: 0.7366 - val_loss: 0.6040 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8024 - f1_score: 0.6904 - loss: 0.6486 - val_accuracy: 0.8041 - val_f1_score: 0.7470 - val_loss: 0.6142 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8117 - f1_score: 0.6865 - loss: 0.6522 - val_accuracy: 0.7835 - val_f1_score: 0.7407 - val_loss: 0.6910 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8051 - f1_score: 0.7084 - loss: 0.6596 - val_accuracy: 0.8402 - val_f1_score: 0.7157 - val_loss: 0.6021 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7975 - f1_score: 0.6734 - loss: 0.6578 - val_accuracy: 0.8505 - val_f1_score: 0.6934 - val_loss: 0.6307 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8333 - f1_score: 0.6883 - loss: 0.6321 - val_accuracy: 0.8402 - val_f1_score: 0.7083 - val_loss: 0.5960 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8218 - f1_score: 0.6717 - loss: 0.6404 - val_accuracy: 0.8247 - val_f1_score: 0.7507 - val_loss: 0.6102 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8243 - f1_score: 0.6844 - loss: 0.6453 - val_accuracy: 0.8351 - val_f1_score: 0.7166 - val_loss: 0.6904 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7870 - f1_score: 0.6530 - loss: 0.6908 - val_accuracy: 0.8247 - val_f1_score: 0.7380 - val_loss: 0.8291 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8088 - f1_score: 0.6885 - loss: 0.6716 - val_accuracy: 0.8351 - val_f1_score: 0.7044 - val_loss: 0.7322 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8191 - f1_score: 0.6638 - loss: 0.6646 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.5994 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7947 - f1_score: 0.6895 - loss: 0.6674 - val_accuracy: 0.8247 - val_f1_score: 0.7532 - val_loss: 0.6004 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7999 - f1_score: 0.6584 - loss: 0.6655 - val_accuracy: 0.8299 - val_f1_score: 0.7337 - val_loss: 0.6940 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8171 - f1_score: 0.6487 - loss: 0.6833 - val_accuracy: 0.8144 - val_f1_score: 0.7475 - val_loss: 0.6191 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8165 - f1_score: 0.6968 - loss: 0.6298 - val_accuracy: 0.8299 - val_f1_score: 0.7091 - val_loss: 0.6132 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8157 - f1_score: 0.6721 - loss: 0.6245 \n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8160 - f1_score: 0.6729 - loss: 0.6254 - val_accuracy: 0.7784 - val_f1_score: 0.7440 - val_loss: 0.6241 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7521 - f1_score: 0.7027 - loss: 0.6418 - val_accuracy: 0.8299 - val_f1_score: 0.7445 - val_loss: 0.5975 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8198 - f1_score: 0.6895 - loss: 0.6197 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.5973 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7998 - f1_score: 0.6894 - loss: 0.6106 - val_accuracy: 0.8351 - val_f1_score: 0.7591 - val_loss: 0.5937 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8023 - f1_score: 0.6842 - loss: 0.6051 - val_accuracy: 0.8299 - val_f1_score: 0.7445 - val_loss: 0.5969 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8164 - f1_score: 0.6959 - loss: 0.5696 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8048 - f1_score: 0.7004 - loss: 0.5809 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.6134 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8112 - f1_score: 0.6759 - loss: 0.5804 - val_accuracy: 0.8299 - val_f1_score: 0.7523 - val_loss: 0.6082 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8135 - f1_score: 0.6989 - loss: 0.5484 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6640 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8199 - f1_score: 0.6720 - loss: 0.5775 - val_accuracy: 0.8299 - val_f1_score: 0.7549 - val_loss: 0.6309 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8151 - f1_score: 0.6884 - loss: 0.5452 - val_accuracy: 0.8351 - val_f1_score: 0.7425 - val_loss: 0.6213 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8043 - f1_score: 0.6851 - loss: 0.5418 - val_accuracy: 0.8144 - val_f1_score: 0.7422 - val_loss: 0.6306 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8159 - f1_score: 0.7118 - loss: 0.5507 - val_accuracy: 0.8351 - val_f1_score: 0.7345 - val_loss: 0.6338 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8214 - f1_score: 0.6818 - loss: 0.5425\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8212 - f1_score: 0.6818 - loss: 0.5419 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6348 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8139 - f1_score: 0.6942 - loss: 0.5361 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6366 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8075 - f1_score: 0.6910 - loss: 0.5083 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6388 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7893 - f1_score: 0.6841 - loss: 0.5100 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6370 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8156 - f1_score: 0.6853 - loss: 0.5030 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6395 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7963 - f1_score: 0.6854 - loss: 0.5100 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6399 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8068 - f1_score: 0.7035 - loss: 0.4999 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6416 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8086 - f1_score: 0.6988 - loss: 0.4877 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6406 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8267 - f1_score: 0.7135 - loss: 0.5091 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6418 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8144 - f1_score: 0.7107 - loss: 0.5045 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6437 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m19/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8229 - f1_score: 0.7004 - loss: 0.5111\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8197 - f1_score: 0.7001 - loss: 0.5090 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6440 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8149 - f1_score: 0.7124 - loss: 0.5009 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6438 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8147 - f1_score: 0.6921 - loss: 0.4831 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6438 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8158 - f1_score: 0.7040 - loss: 0.4989 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6434 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8167 - f1_score: 0.7094 - loss: 0.4992 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6435 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7943 - f1_score: 0.6843 - loss: 0.5164 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6438 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8125 - f1_score: 0.6912 - loss: 0.4903 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6438 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8083 - f1_score: 0.6946 - loss: 0.4912 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6438 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7974 - f1_score: 0.6920 - loss: 0.4996 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6441 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8251 - f1_score: 0.7011 - loss: 0.5033 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6441 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7998 - f1_score: 0.6816 - loss: 0.5162\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8018 - f1_score: 0.6846 - loss: 0.5136 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6443 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8133 - f1_score: 0.7063 - loss: 0.4977 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6443 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8317 - f1_score: 0.7027 - loss: 0.4983 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6443 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8037 - f1_score: 0.6883 - loss: 0.5229 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7927 - f1_score: 0.6863 - loss: 0.5116 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7928 - f1_score: 0.6814 - loss: 0.5208 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6443 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8155 - f1_score: 0.6957 - loss: 0.5008 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8150 - f1_score: 0.7155 - loss: 0.5082 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6443 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7923 - f1_score: 0.7042 - loss: 0.5044 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8217 - f1_score: 0.6945 - loss: 0.5064 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8348 - f1_score: 0.7188 - loss: 0.4776 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8162 - f1_score: 0.6935 - loss: 0.4947 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7985 - f1_score: 0.6706 - loss: 0.5129 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8258 - f1_score: 0.7229 - loss: 0.4872 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8159 - f1_score: 0.7106 - loss: 0.5073 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8189 - f1_score: 0.7048 - loss: 0.5153 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8304 - f1_score: 0.6869 - loss: 0.5165 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8218 - f1_score: 0.7098 - loss: 0.4719 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7976 - f1_score: 0.6722 - loss: 0.5120 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8186 - f1_score: 0.6999 - loss: 0.4959 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8263 - f1_score: 0.6930 - loss: 0.5221 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8128 - f1_score: 0.6939 - loss: 0.5005 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8051 - f1_score: 0.6941 - loss: 0.4916 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8101 - f1_score: 0.7101 - loss: 0.4873 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8227 - f1_score: 0.7045 - loss: 0.4970 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8232 - f1_score: 0.7196 - loss: 0.4877 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7965 - f1_score: 0.6842 - loss: 0.4978 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8117 - f1_score: 0.7045 - loss: 0.5048 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8181 - f1_score: 0.6965 - loss: 0.5077 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8040 - f1_score: 0.6928 - loss: 0.5044 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8146 - f1_score: 0.6921 - loss: 0.5136 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8256 - f1_score: 0.6929 - loss: 0.4900 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7972 - f1_score: 0.6966 - loss: 0.5017 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8204 - f1_score: 0.7053 - loss: 0.5059 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8235 - f1_score: 0.7058 - loss: 0.4851 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7909 - f1_score: 0.6740 - loss: 0.5223 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8193 - f1_score: 0.6896 - loss: 0.5011 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6445 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8142 - f1_score: 0.6967 - loss: 0.4948 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6445 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8114 - f1_score: 0.7010 - loss: 0.4847 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8352 - f1_score: 0.7100 - loss: 0.4999 - val_accuracy: 0.8196 - val_f1_score: 0.7403 - val_loss: 0.6444 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6284493591354612, 0.8869565217391304, 0.3699421965317919)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_23', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - accuracy: 0.8261 - f1_score: 0.5155 - loss: 0.7599 - val_accuracy: 0.8814 - val_f1_score: 0.6750 - val_loss: 0.6427 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8300 - f1_score: 0.6366 - loss: 0.7039 - val_accuracy: 0.7990 - val_f1_score: 0.7248 - val_loss: 0.6397 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8066 - f1_score: 0.6404 - loss: 0.6911 - val_accuracy: 0.6804 - val_f1_score: 0.6914 - val_loss: 0.7877 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7857 - f1_score: 0.6925 - loss: 0.6824 - val_accuracy: 0.7320 - val_f1_score: 0.7303 - val_loss: 0.6362 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8030 - f1_score: 0.6893 - loss: 0.6626 - val_accuracy: 0.8454 - val_f1_score: 0.7026 - val_loss: 0.6185 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8299 - f1_score: 0.6490 - loss: 0.6486 - val_accuracy: 0.8454 - val_f1_score: 0.7232 - val_loss: 0.5922 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8233 - f1_score: 0.6611 - loss: 0.6588 - val_accuracy: 0.8351 - val_f1_score: 0.7296 - val_loss: 0.5984 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8050 - f1_score: 0.6825 - loss: 0.6537 - val_accuracy: 0.7990 - val_f1_score: 0.7480 - val_loss: 0.6082 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7868 - f1_score: 0.6770 - loss: 0.6913 - val_accuracy: 0.8041 - val_f1_score: 0.7523 - val_loss: 0.5995 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7947 - f1_score: 0.6872 - loss: 0.6622 - val_accuracy: 0.8144 - val_f1_score: 0.7575 - val_loss: 0.6168 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7962 - f1_score: 0.6828 - loss: 0.6473 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.6137 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7594 - f1_score: 0.6735 - loss: 0.6803 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.5943 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7703 - f1_score: 0.6664 - loss: 0.6495 - val_accuracy: 0.8454 - val_f1_score: 0.7408 - val_loss: 0.5933 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8017 - f1_score: 0.7026 - loss: 0.6319 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.5865 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7755 - f1_score: 0.6748 - loss: 0.6703 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6311 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7936 - f1_score: 0.6784 - loss: 0.6612 - val_accuracy: 0.8299 - val_f1_score: 0.7395 - val_loss: 0.5893 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8261 - f1_score: 0.6902 - loss: 0.6448 - val_accuracy: 0.7784 - val_f1_score: 0.7418 - val_loss: 0.6275 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7959 - f1_score: 0.6946 - loss: 0.6519 - val_accuracy: 0.7887 - val_f1_score: 0.7449 - val_loss: 0.6358 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8151 - f1_score: 0.6978 - loss: 0.6368 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.6189 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7997 - f1_score: 0.6664 - loss: 0.6532 - val_accuracy: 0.8557 - val_f1_score: 0.7395 - val_loss: 0.5945 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8028 - f1_score: 0.6814 - loss: 0.6637 - val_accuracy: 0.8402 - val_f1_score: 0.7083 - val_loss: 0.6210 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8300 - f1_score: 0.6926 - loss: 0.6431 - val_accuracy: 0.8557 - val_f1_score: 0.7520 - val_loss: 0.5892 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7962 - f1_score: 0.6833 - loss: 0.6511 - val_accuracy: 0.8505 - val_f1_score: 0.7478 - val_loss: 0.5945 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7922 - f1_score: 0.6784 - loss: 0.6428\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7941 - f1_score: 0.6802 - loss: 0.6417 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6063 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8166 - f1_score: 0.7096 - loss: 0.6129 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6033 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8104 - f1_score: 0.7015 - loss: 0.6172 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6036 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8150 - f1_score: 0.7064 - loss: 0.6040 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6052 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8143 - f1_score: 0.7016 - loss: 0.6165 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8160 - f1_score: 0.6946 - loss: 0.6237 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6025 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7999 - f1_score: 0.6906 - loss: 0.6237 - val_accuracy: 0.8402 - val_f1_score: 0.7472 - val_loss: 0.6070 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8243 - f1_score: 0.7132 - loss: 0.5952 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6040 - learning_rate: 1.0000e-03\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8013 - f1_score: 0.6905 - loss: 0.6414 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-03\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8163 - f1_score: 0.7078 - loss: 0.5990 - val_accuracy: 0.8299 - val_f1_score: 0.7498 - val_loss: 0.6039 - learning_rate: 1.0000e-03\n",
            "Epoch 34/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7776 - f1_score: 0.6914 - loss: 0.6246\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7796 - f1_score: 0.6919 - loss: 0.6237 - val_accuracy: 0.8454 - val_f1_score: 0.7514 - val_loss: 0.6086 - learning_rate: 1.0000e-03\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8032 - f1_score: 0.7037 - loss: 0.5867 - val_accuracy: 0.8402 - val_f1_score: 0.7445 - val_loss: 0.6083 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8144 - f1_score: 0.6927 - loss: 0.6166 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6076 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8127 - f1_score: 0.7011 - loss: 0.6068 - val_accuracy: 0.8351 - val_f1_score: 0.7489 - val_loss: 0.6071 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8283 - f1_score: 0.7034 - loss: 0.6094 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6065 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8075 - f1_score: 0.6982 - loss: 0.6062 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6064 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8110 - f1_score: 0.7008 - loss: 0.5962 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6057 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7961 - f1_score: 0.6927 - loss: 0.6171 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6055 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8218 - f1_score: 0.7047 - loss: 0.6050 - val_accuracy: 0.8454 - val_f1_score: 0.7514 - val_loss: 0.6052 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8072 - f1_score: 0.6987 - loss: 0.5851 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6058 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7857 - f1_score: 0.6880 - loss: 0.6044\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7895 - f1_score: 0.6891 - loss: 0.6057 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7904 - f1_score: 0.6895 - loss: 0.6177 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8037 - f1_score: 0.6912 - loss: 0.6178 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8097 - f1_score: 0.7012 - loss: 0.5961 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8032 - f1_score: 0.6871 - loss: 0.6136 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8134 - f1_score: 0.6896 - loss: 0.6152 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8082 - f1_score: 0.6987 - loss: 0.6143 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6059 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8279 - f1_score: 0.7018 - loss: 0.6043 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8126 - f1_score: 0.6922 - loss: 0.6233 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - f1_score: 0.6936 - loss: 0.6051 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7899 - f1_score: 0.6817 - loss: 0.6125\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7935 - f1_score: 0.6846 - loss: 0.6123 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7957 - f1_score: 0.6904 - loss: 0.6154 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7940 - f1_score: 0.6956 - loss: 0.6162 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8061 - f1_score: 0.7049 - loss: 0.5865 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8085 - f1_score: 0.7035 - loss: 0.5971 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7905 - f1_score: 0.7010 - loss: 0.6055 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8097 - f1_score: 0.7081 - loss: 0.6083 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8109 - f1_score: 0.6964 - loss: 0.6192 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8152 - f1_score: 0.7049 - loss: 0.5944 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8098 - f1_score: 0.6950 - loss: 0.6131 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8192 - f1_score: 0.6942 - loss: 0.6096 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8208 - f1_score: 0.7085 - loss: 0.6050 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8093 - f1_score: 0.6971 - loss: 0.5999 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8083 - f1_score: 0.6988 - loss: 0.5814 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8046 - f1_score: 0.6971 - loss: 0.5958 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8205 - f1_score: 0.7123 - loss: 0.5914 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8025 - f1_score: 0.6792 - loss: 0.6123 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8005 - f1_score: 0.6918 - loss: 0.6208 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8031 - f1_score: 0.6911 - loss: 0.6025 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8069 - f1_score: 0.7200 - loss: 0.5816 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7918 - f1_score: 0.7000 - loss: 0.6044 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8060 - f1_score: 0.7168 - loss: 0.6261 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8046 - f1_score: 0.6922 - loss: 0.6004 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8145 - f1_score: 0.7056 - loss: 0.6242 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8121 - f1_score: 0.6897 - loss: 0.6081 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7930 - f1_score: 0.6808 - loss: 0.6268 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8109 - f1_score: 0.6963 - loss: 0.6084 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8045 - f1_score: 0.6888 - loss: 0.6186 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8099 - f1_score: 0.6868 - loss: 0.6027 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8320 - f1_score: 0.6858 - loss: 0.6182 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8025 - f1_score: 0.6887 - loss: 0.6225 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8059 - f1_score: 0.6887 - loss: 0.6300 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8404 - f1_score: 0.7024 - loss: 0.6066 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8109 - f1_score: 0.6738 - loss: 0.6152 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7975 - f1_score: 0.6891 - loss: 0.6033 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7986 - f1_score: 0.6987 - loss: 0.6060 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8029 - f1_score: 0.6855 - loss: 0.6022 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8140 - f1_score: 0.6961 - loss: 0.6011 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8209 - f1_score: 0.6980 - loss: 0.5928 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8168 - f1_score: 0.6946 - loss: 0.6078 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7913 - f1_score: 0.6908 - loss: 0.6120 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7952 - f1_score: 0.6934 - loss: 0.6059 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8120 - f1_score: 0.6987 - loss: 0.6148 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8060 - f1_score: 0.6821 - loss: 0.6360 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8076 - f1_score: 0.6828 - loss: 0.6164 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8062 - f1_score: 0.6913 - loss: 0.6204 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8186 - f1_score: 0.7016 - loss: 0.5875 - val_accuracy: 0.8402 - val_f1_score: 0.7532 - val_loss: 0.6060 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6649403765968184, 0.9004329004329005, 0.4294478527607362)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_24', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 167ms/step - accuracy: 0.7845 - f1_score: 0.5338 - loss: 0.7840 - val_accuracy: 0.8814 - val_f1_score: 0.6750 - val_loss: 0.6553 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8258 - f1_score: 0.6053 - loss: 0.7060 - val_accuracy: 0.8299 - val_f1_score: 0.7078 - val_loss: 0.6433 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7895 - f1_score: 0.6455 - loss: 0.6821 - val_accuracy: 0.8402 - val_f1_score: 0.7317 - val_loss: 0.6173 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7897 - f1_score: 0.6390 - loss: 0.6877 - val_accuracy: 0.8454 - val_f1_score: 0.7248 - val_loss: 0.6093 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8312 - f1_score: 0.6811 - loss: 0.6670 - val_accuracy: 0.8093 - val_f1_score: 0.7541 - val_loss: 0.6132 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8155 - f1_score: 0.6927 - loss: 0.6506 - val_accuracy: 0.8454 - val_f1_score: 0.7112 - val_loss: 0.5985 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8109 - f1_score: 0.6614 - loss: 0.6663 - val_accuracy: 0.8093 - val_f1_score: 0.7408 - val_loss: 0.6193 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7935 - f1_score: 0.6950 - loss: 0.6662 - val_accuracy: 0.8196 - val_f1_score: 0.7389 - val_loss: 0.6686 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7919 - f1_score: 0.6523 - loss: 0.6715 - val_accuracy: 0.8505 - val_f1_score: 0.7400 - val_loss: 0.6040 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7921 - f1_score: 0.6672 - loss: 0.6537 - val_accuracy: 0.8454 - val_f1_score: 0.7328 - val_loss: 0.5892 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8068 - f1_score: 0.6851 - loss: 0.6594 - val_accuracy: 0.8041 - val_f1_score: 0.7447 - val_loss: 0.6003 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7723 - f1_score: 0.6672 - loss: 0.6769 - val_accuracy: 0.8351 - val_f1_score: 0.7387 - val_loss: 0.5924 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8345 - f1_score: 0.6691 - loss: 0.6572 - val_accuracy: 0.8402 - val_f1_score: 0.7429 - val_loss: 0.6151 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8075 - f1_score: 0.6966 - loss: 0.6450 - val_accuracy: 0.8351 - val_f1_score: 0.7130 - val_loss: 0.5963 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8141 - f1_score: 0.6714 - loss: 0.6549 - val_accuracy: 0.8351 - val_f1_score: 0.7264 - val_loss: 0.5984 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8096 - f1_score: 0.6801 - loss: 0.6445 - val_accuracy: 0.8557 - val_f1_score: 0.7016 - val_loss: 0.6313 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8321 - f1_score: 0.6917 - loss: 0.6462 - val_accuracy: 0.7113 - val_f1_score: 0.7222 - val_loss: 0.6455 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7931 - f1_score: 0.6725 - loss: 0.6784 - val_accuracy: 0.8247 - val_f1_score: 0.7380 - val_loss: 0.6452 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8185 - f1_score: 0.6795 - loss: 0.6604 - val_accuracy: 0.8454 - val_f1_score: 0.7314 - val_loss: 0.5997 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8187 - f1_score: 0.6738 - loss: 0.6337\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8165 - f1_score: 0.6730 - loss: 0.6355 - val_accuracy: 0.7423 - val_f1_score: 0.7234 - val_loss: 0.7080 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7704 - f1_score: 0.6918 - loss: 0.6532 - val_accuracy: 0.8351 - val_f1_score: 0.7358 - val_loss: 0.5951 - learning_rate: 1.0000e-03\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7914 - f1_score: 0.6769 - loss: 0.6222 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.6055 - learning_rate: 1.0000e-03\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8029 - f1_score: 0.6985 - loss: 0.6298 - val_accuracy: 0.8351 - val_f1_score: 0.7387 - val_loss: 0.6032 - learning_rate: 1.0000e-03\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8004 - f1_score: 0.6641 - loss: 0.6352 - val_accuracy: 0.8351 - val_f1_score: 0.7464 - val_loss: 0.6006 - learning_rate: 1.0000e-03\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8100 - f1_score: 0.6967 - loss: 0.6118 - val_accuracy: 0.8402 - val_f1_score: 0.7456 - val_loss: 0.5984 - learning_rate: 1.0000e-03\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8168 - f1_score: 0.6941 - loss: 0.6241 - val_accuracy: 0.8454 - val_f1_score: 0.7524 - val_loss: 0.5988 - learning_rate: 1.0000e-03\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8414 - f1_score: 0.6860 - loss: 0.6230 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6041 - learning_rate: 1.0000e-03\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7971 - f1_score: 0.6957 - loss: 0.6253 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-03\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8061 - f1_score: 0.6974 - loss: 0.6105 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6032 - learning_rate: 1.0000e-03\n",
            "Epoch 30/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8270 - f1_score: 0.6917 - loss: 0.6171\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8245 - f1_score: 0.6911 - loss: 0.6183 - val_accuracy: 0.8351 - val_f1_score: 0.7565 - val_loss: 0.6013 - learning_rate: 1.0000e-03\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8011 - f1_score: 0.7117 - loss: 0.6169 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6019 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7755 - f1_score: 0.6938 - loss: 0.6201 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6023 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8018 - f1_score: 0.6977 - loss: 0.6194 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6041 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8153 - f1_score: 0.7047 - loss: 0.6240 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6036 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8061 - f1_score: 0.6926 - loss: 0.6349 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6032 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8249 - f1_score: 0.7091 - loss: 0.6098 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6037 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7898 - f1_score: 0.6886 - loss: 0.6336 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8125 - f1_score: 0.7025 - loss: 0.6233 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6024 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7910 - f1_score: 0.6931 - loss: 0.6100 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6025 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8236 - f1_score: 0.7209 - loss: 0.6070\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8204 - f1_score: 0.7172 - loss: 0.6095 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6035 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7859 - f1_score: 0.6755 - loss: 0.6241 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6034 - learning_rate: 1.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8024 - f1_score: 0.7048 - loss: 0.6183 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6032 - learning_rate: 1.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7868 - f1_score: 0.6888 - loss: 0.6117 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6033 - learning_rate: 1.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7997 - f1_score: 0.7135 - loss: 0.5942 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6033 - learning_rate: 1.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8032 - f1_score: 0.7042 - loss: 0.6103 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6033 - learning_rate: 1.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8025 - f1_score: 0.6864 - loss: 0.6314 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6034 - learning_rate: 1.0000e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8131 - f1_score: 0.7130 - loss: 0.6095 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6032 - learning_rate: 1.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8044 - f1_score: 0.6947 - loss: 0.6371 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6033 - learning_rate: 1.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7993 - f1_score: 0.7012 - loss: 0.6251 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6032 - learning_rate: 1.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8193 - f1_score: 0.7037 - loss: 0.6218\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8164 - f1_score: 0.7023 - loss: 0.6215 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8054 - f1_score: 0.6927 - loss: 0.6256 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7967 - f1_score: 0.6860 - loss: 0.6402 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7913 - f1_score: 0.6963 - loss: 0.6362 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7990 - f1_score: 0.6953 - loss: 0.6128 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8133 - f1_score: 0.7134 - loss: 0.6191 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7873 - f1_score: 0.6925 - loss: 0.6163 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7970 - f1_score: 0.6944 - loss: 0.6255 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7876 - f1_score: 0.6818 - loss: 0.6409 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8026 - f1_score: 0.7064 - loss: 0.6131 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8024 - f1_score: 0.6959 - loss: 0.6179 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8090 - f1_score: 0.6919 - loss: 0.6272 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7872 - f1_score: 0.6713 - loss: 0.6365 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8024 - f1_score: 0.6978 - loss: 0.6260 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8042 - f1_score: 0.6945 - loss: 0.6226 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7981 - f1_score: 0.7059 - loss: 0.6171 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7882 - f1_score: 0.6810 - loss: 0.6276 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8023 - f1_score: 0.6981 - loss: 0.6310 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7903 - f1_score: 0.6986 - loss: 0.6268 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8137 - f1_score: 0.6986 - loss: 0.6204 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8120 - f1_score: 0.6987 - loss: 0.6481 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7816 - f1_score: 0.6813 - loss: 0.6387 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8008 - f1_score: 0.6962 - loss: 0.6257 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8212 - f1_score: 0.7091 - loss: 0.6080 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8167 - f1_score: 0.7087 - loss: 0.6274 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8052 - f1_score: 0.6931 - loss: 0.6323 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7993 - f1_score: 0.6968 - loss: 0.6183 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7936 - f1_score: 0.6680 - loss: 0.6273 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7931 - f1_score: 0.6975 - loss: 0.6333 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7719 - f1_score: 0.6894 - loss: 0.6233 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8117 - f1_score: 0.6991 - loss: 0.6137 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8218 - f1_score: 0.7327 - loss: 0.6068 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8013 - f1_score: 0.6818 - loss: 0.6356 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7883 - f1_score: 0.6865 - loss: 0.6230 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8040 - f1_score: 0.6998 - loss: 0.6218 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7984 - f1_score: 0.6914 - loss: 0.6301 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7880 - f1_score: 0.6721 - loss: 0.6334 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7976 - f1_score: 0.6949 - loss: 0.6280 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7972 - f1_score: 0.6928 - loss: 0.6244 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7898 - f1_score: 0.6891 - loss: 0.6205 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8088 - f1_score: 0.6979 - loss: 0.6353 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6031 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7930 - f1_score: 0.6816 - loss: 0.6271 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7856 - f1_score: 0.6732 - loss: 0.6427 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7961 - f1_score: 0.7036 - loss: 0.6026 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8121 - f1_score: 0.7043 - loss: 0.5924 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7995 - f1_score: 0.6877 - loss: 0.6142 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8226 - f1_score: 0.7193 - loss: 0.5956 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8303 - f1_score: 0.7070 - loss: 0.6347 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7973 - f1_score: 0.7035 - loss: 0.6030 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8036 - f1_score: 0.6940 - loss: 0.6294 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7793 - f1_score: 0.6826 - loss: 0.6302 - val_accuracy: 0.8402 - val_f1_score: 0.7481 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6613699475470534, 0.8941684665226782, 0.42857142857142855)\n",
            "Best threshold: 0.45, Best F1: 0.6750181554103123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot best_thres against best_f1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have 'thresholds' and 'f1_scores' from the previous code\n",
        "# Replace with your actual data if necessary\n",
        "\n",
        "plt.plot(thresholds, f1_scores)\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.title(\"F1 Score vs. Threshold\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vTyqy0mM401g",
        "outputId": "1e1d0156-6b95-4ec4-b56c-8190680c3f70"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GAT(64, 1, 0.5)\n",
        "trained_model, f1, y_pred = tune_graph_threshold(model, 0.45)\n",
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIDn97FXEMpZ",
        "outputId": "7eb9fe0b-b5e7-4afc-e9f2-1ec08622ee55"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'gat_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.7224 - f1_score: 0.5126 - loss: 0.7820 - val_accuracy: 0.8660 - val_f1_score: 0.6362 - val_loss: 0.6570 - learning_rate: 0.0100\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.8472 - f1_score: 0.5808 - loss: 0.7159 - val_accuracy: 0.8660 - val_f1_score: 0.6955 - val_loss: 0.6520 - learning_rate: 0.0100\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.8063 - f1_score: 0.6235 - loss: 0.7076 - val_accuracy: 0.8041 - val_f1_score: 0.7372 - val_loss: 0.6443 - learning_rate: 0.0100\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.7940 - f1_score: 0.6683 - loss: 0.6727 - val_accuracy: 0.8351 - val_f1_score: 0.7166 - val_loss: 0.6142 - learning_rate: 0.0100\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.8151 - f1_score: 0.6650 - loss: 0.6834 - val_accuracy: 0.8247 - val_f1_score: 0.7183 - val_loss: 0.6064 - learning_rate: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 242ms/step - accuracy: 0.8269 - f1_score: 0.6769 - loss: 0.6793 - val_accuracy: 0.8557 - val_f1_score: 0.7057 - val_loss: 0.6357 - learning_rate: 0.0100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.8039 - f1_score: 0.6689 - loss: 0.6821 - val_accuracy: 0.7887 - val_f1_score: 0.7396 - val_loss: 0.6382 - learning_rate: 0.0100\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.8104 - f1_score: 0.6803 - loss: 0.6855 - val_accuracy: 0.8093 - val_f1_score: 0.7414 - val_loss: 0.6431 - learning_rate: 0.0100\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - accuracy: 0.8094 - f1_score: 0.6890 - loss: 0.6711 - val_accuracy: 0.8351 - val_f1_score: 0.7264 - val_loss: 0.6352 - learning_rate: 0.0100\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - accuracy: 0.7989 - f1_score: 0.6792 - loss: 0.6776 - val_accuracy: 0.8505 - val_f1_score: 0.7065 - val_loss: 0.6245 - learning_rate: 0.0100\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.8427 - f1_score: 0.6634 - loss: 0.6626 - val_accuracy: 0.8299 - val_f1_score: 0.7412 - val_loss: 0.6058 - learning_rate: 0.0100\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.8031 - f1_score: 0.6838 - loss: 0.6614 - val_accuracy: 0.8351 - val_f1_score: 0.7081 - val_loss: 0.6038 - learning_rate: 0.0100\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.8177 - f1_score: 0.6770 - loss: 0.6537 - val_accuracy: 0.7938 - val_f1_score: 0.7460 - val_loss: 0.6388 - learning_rate: 0.0100\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.7902 - f1_score: 0.6862 - loss: 0.6690 - val_accuracy: 0.8144 - val_f1_score: 0.7418 - val_loss: 0.5997 - learning_rate: 0.0100\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8051 - f1_score: 0.6906 - loss: 0.6614 - val_accuracy: 0.8247 - val_f1_score: 0.7343 - val_loss: 0.6008 - learning_rate: 0.0100\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - accuracy: 0.7949 - f1_score: 0.6764 - loss: 0.6642 - val_accuracy: 0.8505 - val_f1_score: 0.7400 - val_loss: 0.5954 - learning_rate: 0.0100\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - accuracy: 0.8177 - f1_score: 0.6929 - loss: 0.6564 - val_accuracy: 0.8454 - val_f1_score: 0.7160 - val_loss: 0.5993 - learning_rate: 0.0100\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.8421 - f1_score: 0.6863 - loss: 0.6601 - val_accuracy: 0.8247 - val_f1_score: 0.7380 - val_loss: 0.5966 - learning_rate: 0.0100\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7955 - f1_score: 0.7099 - loss: 0.6269 - val_accuracy: 0.8557 - val_f1_score: 0.7442 - val_loss: 0.5918 - learning_rate: 0.0100\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.8273 - f1_score: 0.7030 - loss: 0.6300 - val_accuracy: 0.8041 - val_f1_score: 0.7366 - val_loss: 0.6228 - learning_rate: 0.0100\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 400ms/step - accuracy: 0.8235 - f1_score: 0.6851 - loss: 0.6336 - val_accuracy: 0.8402 - val_f1_score: 0.7273 - val_loss: 0.6057 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 342ms/step - accuracy: 0.8221 - f1_score: 0.6732 - loss: 0.6404 - val_accuracy: 0.8505 - val_f1_score: 0.7435 - val_loss: 0.5913 - learning_rate: 0.0100\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 350ms/step - accuracy: 0.7940 - f1_score: 0.6559 - loss: 0.6693 - val_accuracy: 0.8608 - val_f1_score: 0.7513 - val_loss: 0.6205 - learning_rate: 0.0100\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 357ms/step - accuracy: 0.7987 - f1_score: 0.6877 - loss: 0.6341 - val_accuracy: 0.8299 - val_f1_score: 0.7516 - val_loss: 0.5887 - learning_rate: 0.0100\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.7990 - f1_score: 0.6769 - loss: 0.6499 - val_accuracy: 0.8505 - val_f1_score: 0.7237 - val_loss: 0.5980 - learning_rate: 0.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.8192 - f1_score: 0.6808 - loss: 0.6542 - val_accuracy: 0.7835 - val_f1_score: 0.7460 - val_loss: 0.6490 - learning_rate: 0.0100\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.7580 - f1_score: 0.6822 - loss: 0.6417 - val_accuracy: 0.8557 - val_f1_score: 0.7411 - val_loss: 0.6257 - learning_rate: 0.0100\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8339 - f1_score: 0.6799 - loss: 0.6440 - val_accuracy: 0.8247 - val_f1_score: 0.7480 - val_loss: 0.5997 - learning_rate: 0.0100\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.8212 - f1_score: 0.6886 - loss: 0.6302 - val_accuracy: 0.8093 - val_f1_score: 0.7457 - val_loss: 0.6244 - learning_rate: 0.0100\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - accuracy: 0.7950 - f1_score: 0.6840 - loss: 0.6296 - val_accuracy: 0.8608 - val_f1_score: 0.7513 - val_loss: 0.6076 - learning_rate: 0.0100\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.8345 - f1_score: 0.7098 - loss: 0.6220 - val_accuracy: 0.8144 - val_f1_score: 0.7551 - val_loss: 0.6212 - learning_rate: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 0.7954 - f1_score: 0.6864 - loss: 0.6382 - val_accuracy: 0.8093 - val_f1_score: 0.7509 - val_loss: 0.6044 - learning_rate: 0.0100\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.8010 - f1_score: 0.6945 - loss: 0.6313 - val_accuracy: 0.8247 - val_f1_score: 0.7583 - val_loss: 0.6210 - learning_rate: 0.0100\n",
            "Epoch 34/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.7919 - f1_score: 0.6943 - loss: 0.6289\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.7924 - f1_score: 0.6936 - loss: 0.6292 - val_accuracy: 0.8402 - val_f1_score: 0.7607 - val_loss: 0.6143 - learning_rate: 0.0100\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.7800 - f1_score: 0.6934 - loss: 0.6255 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6045 - learning_rate: 1.0000e-03\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.7938 - f1_score: 0.6700 - loss: 0.6266 - val_accuracy: 0.8402 - val_f1_score: 0.7416 - val_loss: 0.6029 - learning_rate: 1.0000e-03\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 252ms/step - accuracy: 0.8023 - f1_score: 0.6733 - loss: 0.6347 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6050 - learning_rate: 1.0000e-03\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 245ms/step - accuracy: 0.7952 - f1_score: 0.6861 - loss: 0.6391 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6114 - learning_rate: 1.0000e-03\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.8107 - f1_score: 0.6820 - loss: 0.6164 - val_accuracy: 0.8402 - val_f1_score: 0.7506 - val_loss: 0.6113 - learning_rate: 1.0000e-03\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 361ms/step - accuracy: 0.7904 - f1_score: 0.6892 - loss: 0.6206 - val_accuracy: 0.8454 - val_f1_score: 0.7498 - val_loss: 0.6136 - learning_rate: 1.0000e-03\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - accuracy: 0.8360 - f1_score: 0.6861 - loss: 0.5991 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6141 - learning_rate: 1.0000e-03\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.7736 - f1_score: 0.6861 - loss: 0.6196 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6095 - learning_rate: 1.0000e-03\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 244ms/step - accuracy: 0.8207 - f1_score: 0.6837 - loss: 0.6051 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6140 - learning_rate: 1.0000e-03\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8310 - f1_score: 0.7038 - loss: 0.5955\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 287ms/step - accuracy: 0.8303 - f1_score: 0.7035 - loss: 0.5962 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6089 - learning_rate: 1.0000e-03\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 333ms/step - accuracy: 0.8157 - f1_score: 0.7026 - loss: 0.5920 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6103 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.8204 - f1_score: 0.6980 - loss: 0.6100 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6099 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.8009 - f1_score: 0.6911 - loss: 0.6124 - val_accuracy: 0.8402 - val_f1_score: 0.7582 - val_loss: 0.6101 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.8083 - f1_score: 0.6871 - loss: 0.6206 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6103 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.8155 - f1_score: 0.7010 - loss: 0.6129 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6118 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.8008 - f1_score: 0.6955 - loss: 0.6313 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6116 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - accuracy: 0.7980 - f1_score: 0.6898 - loss: 0.6089 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6113 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.8142 - f1_score: 0.6927 - loss: 0.5993 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6106 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.8199 - f1_score: 0.6968 - loss: 0.6182 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6114 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7979 - f1_score: 0.6714 - loss: 0.6114\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.7984 - f1_score: 0.6724 - loss: 0.6113 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.7993 - f1_score: 0.7118 - loss: 0.5931 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - accuracy: 0.8039 - f1_score: 0.6813 - loss: 0.6164 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6118 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.8154 - f1_score: 0.6964 - loss: 0.6059 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6119 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - accuracy: 0.7888 - f1_score: 0.6719 - loss: 0.6123 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6119 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 242ms/step - accuracy: 0.8090 - f1_score: 0.6961 - loss: 0.6216 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6119 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.8187 - f1_score: 0.6876 - loss: 0.6178 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6118 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.8330 - f1_score: 0.7098 - loss: 0.6105 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6118 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.8009 - f1_score: 0.6701 - loss: 0.6289 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.8059 - f1_score: 0.7027 - loss: 0.6066 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8216 - f1_score: 0.7029 - loss: 0.5889\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.8207 - f1_score: 0.7024 - loss: 0.5904 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.7982 - f1_score: 0.6772 - loss: 0.6335 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.7971 - f1_score: 0.6846 - loss: 0.6140 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.8161 - f1_score: 0.7091 - loss: 0.6169 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - accuracy: 0.8267 - f1_score: 0.6965 - loss: 0.6083 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - accuracy: 0.7836 - f1_score: 0.6756 - loss: 0.6276 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.8219 - f1_score: 0.7165 - loss: 0.6061 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.8241 - f1_score: 0.7060 - loss: 0.6114 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - accuracy: 0.7981 - f1_score: 0.6864 - loss: 0.5988 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.8070 - f1_score: 0.7108 - loss: 0.6116 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - accuracy: 0.8296 - f1_score: 0.6942 - loss: 0.6138 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 245ms/step - accuracy: 0.8026 - f1_score: 0.6848 - loss: 0.6097 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.8186 - f1_score: 0.7037 - loss: 0.6090 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.8058 - f1_score: 0.6844 - loss: 0.5967 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.7830 - f1_score: 0.6868 - loss: 0.6013 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - accuracy: 0.8254 - f1_score: 0.6906 - loss: 0.6223 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.8260 - f1_score: 0.7139 - loss: 0.6005 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.7941 - f1_score: 0.6890 - loss: 0.6244 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 251ms/step - accuracy: 0.8147 - f1_score: 0.7075 - loss: 0.6024 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8141 - f1_score: 0.6929 - loss: 0.6273 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.8107 - f1_score: 0.7079 - loss: 0.5996 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.8193 - f1_score: 0.6929 - loss: 0.6073 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.8008 - f1_score: 0.6971 - loss: 0.6052 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.7994 - f1_score: 0.6970 - loss: 0.5961 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - accuracy: 0.8306 - f1_score: 0.7243 - loss: 0.5927 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 242ms/step - accuracy: 0.8284 - f1_score: 0.7080 - loss: 0.6008 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.8202 - f1_score: 0.7071 - loss: 0.5988 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.8152 - f1_score: 0.7024 - loss: 0.6238 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.8170 - f1_score: 0.6977 - loss: 0.6086 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - accuracy: 0.8114 - f1_score: 0.6879 - loss: 0.6051 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.8036 - f1_score: 0.6903 - loss: 0.5996 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.8291 - f1_score: 0.6807 - loss: 0.6446 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.8101 - f1_score: 0.6881 - loss: 0.6157 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.8088 - f1_score: 0.6988 - loss: 0.5876 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.8053 - f1_score: 0.6863 - loss: 0.5945 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - accuracy: 0.8277 - f1_score: 0.7060 - loss: 0.5985 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - accuracy: 0.8015 - f1_score: 0.7021 - loss: 0.6173 - val_accuracy: 0.8351 - val_f1_score: 0.7514 - val_loss: 0.6117 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
            "Jiaqi's Weighted F1 Score: (0.6668176784455855, 0.8917748917748918, 0.4418604651162791)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6668176784455855"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation"
      ],
      "metadata": {
        "id": "7AA_6E-iNJiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a GAT model class similar to GNN model and train\n",
        "\n",
        "import keras\n",
        "from spektral.layers import GATConv\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import F1Score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class GAT(Model):\n",
        "    def __init__(self, n_hidden, n_heads, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.gat1 = NewGATConv(n_hidden, attn_heads=n_heads, concat_heads=True, activation=\"elu\")\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.gat2 = NewGATConv(n_hidden, attn_heads=n_heads, concat_heads=True, activation=\"elu\")\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.gat3 = NewGATConv(n_hidden, attn_heads=1, concat_heads=False, activation=\"elu\")\n",
        "        self.dropout3 = Dropout(dropout_rate)\n",
        "        self.pool = keras.layers.GlobalAveragePooling1D()\n",
        "        self.dense1 = Dense(64, activation='relu')\n",
        "        self.dense2 = Dense(32, activation='relu')\n",
        "        self.dense3 = Dense(2, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, adj, meta = inputs\n",
        "        out = self.gat1([x, adj])\n",
        "        out = self.dropout1(out)\n",
        "        out = self.gat2([out, adj])\n",
        "        out = self.dropout2(out)\n",
        "        out = self.gat3([out, adj])\n",
        "        out = self.dropout3(out)\n",
        "        out = self.pool(out)\n",
        "        out = concatenate([out, meta])\n",
        "        out = self.dense1(out)\n",
        "        out = self.dropout1(out)\n",
        "        out = self.dense3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "n_hidden = 64  # Number of hidden units\n",
        "n_heads = 1  # Number of attention heads\n",
        "dropout_rate = 0.5\n",
        "\n",
        "model = GAT(n_hidden, n_heads, dropout_rate)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=1e-2)\n",
        "f1_scorer = F1Score(average='weighted')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# model.fit([train_feature_matrices, train_adjacency_matrices, X_train_meta], y_train,\n",
        "#           epochs=100, batch_size=32, validation_split=0.2,\n",
        "#           sample_weight=weights,\n",
        "#           callbacks=[reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "2vDFadksNGN1",
        "outputId": "19228ee7-2552-449c-a466-d40d65b6f1bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gat\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gat\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gat_conv (\u001b[38;5;33mNewGATConv\u001b[0m)       â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_1 (\u001b[38;5;33mNewGATConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_2 (\u001b[38;5;33mNewGATConv\u001b[0m)     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d        â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ new_gat_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)       â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ new_gat_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NewGATConv</span>)     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d        â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function to run cross validations to train the GAT model with the entire dataset: connectome_matrices, df_train_meta_imputed, df_train_y\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def run_cross_validation(model, connectome_matrices, df_train_meta_imputed, df_train_y, n_splits=5):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    f1_scores = []\n",
        "    all_folds_preds = []\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(connectome_matrices)):\n",
        "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
        "\n",
        "        X_train_mri, X_val_mri = connectome_matrices[train_index], connectome_matrices[val_index]\n",
        "        X_train_meta, X_val_meta = df_train_meta_imputed[train_index], df_train_meta_imputed[val_index]\n",
        "        y_train, y_val = df_train_y.iloc[train_index].values, df_train_y.iloc[val_index].values\n",
        "\n",
        "        # Create adjacency matrices (replace with your actual function)\n",
        "        train_adjacency_matrices = [create_adjacency_matrix(cm, threshold=0.45) for cm in X_train_mri]  # Example threshold\n",
        "        val_adjacency_matrices = [create_adjacency_matrix(cm, threshold=0.45) for cm in X_val_mri]\n",
        "\n",
        "        # Create feature matrices (replace with your actual data)\n",
        "        train_feature_matrices = [np.eye(200,200) for _ in X_train_mri]\n",
        "        val_feature_matrices = [np.eye(200,200) for _ in X_val_mri]\n",
        "\n",
        "        # Compile the model (you might need to recompile for each fold)\n",
        "        optimizer = Adam(learning_rate=1e-2)  # Adjust learning rate if needed\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "        model.fit([np.array(train_feature_matrices), np.array(train_adjacency_matrices), X_train_meta], y_train,\n",
        "                  sample_weight=weights,\n",
        "                  epochs=50, batch_size=32, validation_split=0.2,  callbacks=[reduce_lr])  # Adjust epochs and batch size\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = model.predict([np.array(val_feature_matrices), np.array(val_adjacency_matrices), X_val_meta])\n",
        "        y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        f1 = compute_weighted_f1(y_val[:, 0], y_pred_classes[:, 0], y_val[:, 1], y_pred_classes[:, 1])\n",
        "        f1_scores.append(f1[0])\n",
        "        print(f\"Fold {fold + 1} Weighted F1 Score: {f1[0]}\")\n",
        "\n",
        "        fold_predictions = {\n",
        "            'y_val': y_val,\n",
        "            'y_pred': y_pred,\n",
        "            'model': model\n",
        "        }\n",
        "        all_folds_preds.append(fold_predictions)\n",
        "\n",
        "    print(f\"Average Weighted F1 Score across all folds: {np.mean(f1_scores)}\")\n",
        "\n",
        "    return f1_scores, model, all_folds_preds\n",
        "\n",
        "f1scores, model, all_folds_preds = run_cross_validation(model, connectome_matrices, df_train_meta_imputed, df_train_y, n_splits=5)\n",
        "y_val, y_pred = all_folds_preds[-1]['y_val'], all_folds_preds[-1]['y_pred']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaEn1TcWOAvx",
        "outputId": "d5b9056b-0e92-4091-c469-9d69af4d6220"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - accuracy: 0.9142 - loss: 0.5866 - val_accuracy: 0.5825 - val_loss: 1.1991 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9334 - loss: 0.6022 - val_accuracy: 0.5876 - val_loss: 0.9853 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9216 - loss: 0.5905 - val_accuracy: 0.5979 - val_loss: 1.3168 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9213 - loss: 0.5715 - val_accuracy: 0.5979 - val_loss: 1.0555 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9325 - loss: 0.5947 - val_accuracy: 0.5876 - val_loss: 0.9475 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9043 - loss: 0.5820 - val_accuracy: 0.5876 - val_loss: 0.9104 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9216 - loss: 0.5668 - val_accuracy: 0.5979 - val_loss: 0.8908 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9186 - loss: 0.5610 - val_accuracy: 0.5825 - val_loss: 1.0843 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9294 - loss: 0.5772 - val_accuracy: 0.5773 - val_loss: 1.0349 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9192 - loss: 0.5755 - val_accuracy: 0.6031 - val_loss: 1.0345 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9090 - loss: 0.5689 - val_accuracy: 0.5773 - val_loss: 0.9524 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9063 - loss: 0.5605 - val_accuracy: 0.5876 - val_loss: 1.0325 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9322 - loss: 0.5687 - val_accuracy: 0.6031 - val_loss: 1.0325 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9162 - loss: 0.5780 - val_accuracy: 0.5928 - val_loss: 0.9751 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9222 - loss: 0.6018 - val_accuracy: 0.5979 - val_loss: 1.0036 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9338 - loss: 0.5760 - val_accuracy: 0.6082 - val_loss: 0.7925 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9119 - loss: 0.5939 - val_accuracy: 0.5670 - val_loss: 1.0581 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9341 - loss: 0.5539 - val_accuracy: 0.5825 - val_loss: 1.1543 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9244 - loss: 0.5504 - val_accuracy: 0.5773 - val_loss: 0.9762 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9283 - loss: 0.5539 - val_accuracy: 0.6031 - val_loss: 0.9227 - learning_rate: 0.0100\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9085 - loss: 0.5652 - val_accuracy: 0.5979 - val_loss: 0.9295 - learning_rate: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9202 - loss: 0.5505 - val_accuracy: 0.5928 - val_loss: 1.0806 - learning_rate: 0.0100\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9077 - loss: 0.5442 - val_accuracy: 0.5876 - val_loss: 1.1425 - learning_rate: 0.0100\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9043 - loss: 0.5490 - val_accuracy: 0.5670 - val_loss: 1.0994 - learning_rate: 0.0100\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9115 - loss: 0.5384 - val_accuracy: 0.5928 - val_loss: 1.1908 - learning_rate: 0.0100\n",
            "Epoch 26/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9090 - loss: 0.5784\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9104 - loss: 0.5767 - val_accuracy: 0.5979 - val_loss: 1.0148 - learning_rate: 0.0100\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9223 - loss: 0.5375 - val_accuracy: 0.5979 - val_loss: 1.0364 - learning_rate: 1.0000e-03\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9218 - loss: 0.5273 - val_accuracy: 0.5979 - val_loss: 1.0568 - learning_rate: 1.0000e-03\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9202 - loss: 0.5369 - val_accuracy: 0.5979 - val_loss: 1.0731 - learning_rate: 1.0000e-03\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9291 - loss: 0.5257 - val_accuracy: 0.5825 - val_loss: 1.0768 - learning_rate: 1.0000e-03\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9275 - loss: 0.5387 - val_accuracy: 0.5928 - val_loss: 1.0716 - learning_rate: 1.0000e-03\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9151 - loss: 0.5233 - val_accuracy: 0.5979 - val_loss: 1.0592 - learning_rate: 1.0000e-03\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9191 - loss: 0.5184 - val_accuracy: 0.5979 - val_loss: 1.0633 - learning_rate: 1.0000e-03\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9066 - loss: 0.5297 - val_accuracy: 0.5876 - val_loss: 1.0749 - learning_rate: 1.0000e-03\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9297 - loss: 0.5153 - val_accuracy: 0.5876 - val_loss: 1.0690 - learning_rate: 1.0000e-03\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9236 - loss: 0.5572\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9235 - loss: 0.5561 - val_accuracy: 0.6031 - val_loss: 1.0641 - learning_rate: 1.0000e-03\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9257 - loss: 0.5336 - val_accuracy: 0.6031 - val_loss: 1.0662 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9233 - loss: 0.5318 - val_accuracy: 0.6031 - val_loss: 1.0718 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9157 - loss: 0.5230 - val_accuracy: 0.6031 - val_loss: 1.0728 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9260 - loss: 0.5339 - val_accuracy: 0.6031 - val_loss: 1.0708 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9260 - loss: 0.5281 - val_accuracy: 0.6031 - val_loss: 1.0735 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9217 - loss: 0.5051 - val_accuracy: 0.6031 - val_loss: 1.0790 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9215 - loss: 0.5182 - val_accuracy: 0.6031 - val_loss: 1.0772 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9092 - loss: 0.5436 - val_accuracy: 0.6031 - val_loss: 1.0764 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9221 - loss: 0.5216 - val_accuracy: 0.6031 - val_loss: 1.0705 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.5191\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9167 - loss: 0.5214 - val_accuracy: 0.6031 - val_loss: 1.0722 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9152 - loss: 0.5490 - val_accuracy: 0.6031 - val_loss: 1.0718 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9291 - loss: 0.5178 - val_accuracy: 0.6031 - val_loss: 1.0723 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9150 - loss: 0.5260 - val_accuracy: 0.6031 - val_loss: 1.0718 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9330 - loss: 0.5232 - val_accuracy: 0.6031 - val_loss: 1.0716 - learning_rate: 1.0000e-05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "Fold 1 Weighted F1 Score: 0.6421510153154264\n",
            "Fold 2/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.9230 - loss: 0.5686 - val_accuracy: 0.5825 - val_loss: 1.1688 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9416 - loss: 0.5573 - val_accuracy: 0.5876 - val_loss: 1.1074 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9358 - loss: 0.5255 - val_accuracy: 0.6186 - val_loss: 1.0779 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9254 - loss: 0.5570 - val_accuracy: 0.5979 - val_loss: 1.1181 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9430 - loss: 0.5409 - val_accuracy: 0.6289 - val_loss: 0.9599 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9293 - loss: 0.5793 - val_accuracy: 0.5928 - val_loss: 1.0818 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9237 - loss: 0.5399 - val_accuracy: 0.5773 - val_loss: 0.8661 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8987 - loss: 0.5544 - val_accuracy: 0.6082 - val_loss: 0.9111 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9310 - loss: 0.5417 - val_accuracy: 0.6134 - val_loss: 1.2376 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9390 - loss: 0.5206 - val_accuracy: 0.6082 - val_loss: 1.0348 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9275 - loss: 0.5397 - val_accuracy: 0.5722 - val_loss: 1.2491 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.5356 - val_accuracy: 0.6031 - val_loss: 1.2712 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9489 - loss: 0.5510 - val_accuracy: 0.5979 - val_loss: 1.2015 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9435 - loss: 0.5138 - val_accuracy: 0.6082 - val_loss: 0.9709 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9256 - loss: 0.5578 - val_accuracy: 0.6186 - val_loss: 1.1161 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8883 - loss: 0.5643 - val_accuracy: 0.5928 - val_loss: 1.1218 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9280 - loss: 0.5022\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9274 - loss: 0.5042 - val_accuracy: 0.5876 - val_loss: 1.0754 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9354 - loss: 0.5105 - val_accuracy: 0.5876 - val_loss: 1.0854 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9480 - loss: 0.5199 - val_accuracy: 0.5979 - val_loss: 1.0962 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9332 - loss: 0.4992 - val_accuracy: 0.6031 - val_loss: 1.0970 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9370 - loss: 0.4983 - val_accuracy: 0.6031 - val_loss: 1.0940 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9288 - loss: 0.5033 - val_accuracy: 0.6031 - val_loss: 1.0776 - learning_rate: 1.0000e-03\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9357 - loss: 0.4840 - val_accuracy: 0.6082 - val_loss: 1.0873 - learning_rate: 1.0000e-03\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9338 - loss: 0.4983 - val_accuracy: 0.6031 - val_loss: 1.0782 - learning_rate: 1.0000e-03\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9252 - loss: 0.4820 - val_accuracy: 0.6031 - val_loss: 1.0987 - learning_rate: 1.0000e-03\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9386 - loss: 0.5139 - val_accuracy: 0.6082 - val_loss: 1.0964 - learning_rate: 1.0000e-03\n",
            "Epoch 27/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9283 - loss: 0.5025\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9287 - loss: 0.5029 - val_accuracy: 0.6082 - val_loss: 1.1043 - learning_rate: 1.0000e-03\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9403 - loss: 0.5172 - val_accuracy: 0.6082 - val_loss: 1.1031 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9230 - loss: 0.5350 - val_accuracy: 0.6031 - val_loss: 1.0975 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9467 - loss: 0.4980 - val_accuracy: 0.6082 - val_loss: 1.0968 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9433 - loss: 0.5282 - val_accuracy: 0.6031 - val_loss: 1.0971 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9281 - loss: 0.5091 - val_accuracy: 0.6031 - val_loss: 1.0984 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9357 - loss: 0.4853 - val_accuracy: 0.6031 - val_loss: 1.0986 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9371 - loss: 0.4811 - val_accuracy: 0.6031 - val_loss: 1.0994 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9441 - loss: 0.4846 - val_accuracy: 0.6031 - val_loss: 1.1002 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9331 - loss: 0.5066 - val_accuracy: 0.6031 - val_loss: 1.0992 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9399 - loss: 0.5016\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9397 - loss: 0.5017 - val_accuracy: 0.6031 - val_loss: 1.0964 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9337 - loss: 0.5097 - val_accuracy: 0.6031 - val_loss: 1.0971 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9340 - loss: 0.5026 - val_accuracy: 0.6031 - val_loss: 1.0972 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9213 - loss: 0.5082 - val_accuracy: 0.6031 - val_loss: 1.0970 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9287 - loss: 0.4943 - val_accuracy: 0.6031 - val_loss: 1.0967 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9503 - loss: 0.5122 - val_accuracy: 0.6031 - val_loss: 1.0971 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9344 - loss: 0.4850 - val_accuracy: 0.6031 - val_loss: 1.0978 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9254 - loss: 0.5263 - val_accuracy: 0.6031 - val_loss: 1.0977 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9513 - loss: 0.4777 - val_accuracy: 0.6031 - val_loss: 1.0980 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9309 - loss: 0.5183 - val_accuracy: 0.6031 - val_loss: 1.0976 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9398 - loss: 0.4925\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9396 - loss: 0.4929 - val_accuracy: 0.6031 - val_loss: 1.0983 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9469 - loss: 0.4877 - val_accuracy: 0.6031 - val_loss: 1.0982 - learning_rate: 1.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9421 - loss: 0.4942 - val_accuracy: 0.6031 - val_loss: 1.0982 - learning_rate: 1.0000e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9362 - loss: 0.5201 - val_accuracy: 0.6031 - val_loss: 1.0981 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342ms/step\n",
            "Fold 2 Weighted F1 Score: 0.6824970748158855\n",
            "Fold 3/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 203ms/step - accuracy: 0.9092 - loss: 0.5780 - val_accuracy: 0.5515 - val_loss: 0.9399 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8986 - loss: 0.5642 - val_accuracy: 0.5567 - val_loss: 1.0631 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9147 - loss: 0.5689 - val_accuracy: 0.5361 - val_loss: 1.0238 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9343 - loss: 0.5526 - val_accuracy: 0.5928 - val_loss: 1.0216 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9291 - loss: 0.5395 - val_accuracy: 0.5722 - val_loss: 1.0602 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9362 - loss: 0.5379 - val_accuracy: 0.5515 - val_loss: 1.2291 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9436 - loss: 0.5461 - val_accuracy: 0.5515 - val_loss: 1.1641 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9386 - loss: 0.5388 - val_accuracy: 0.5515 - val_loss: 1.1819 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9313 - loss: 0.5364 - val_accuracy: 0.5670 - val_loss: 1.0924 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9236 - loss: 0.5741 - val_accuracy: 0.5464 - val_loss: 1.0710 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9104 - loss: 0.5269\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9111 - loss: 0.5284 - val_accuracy: 0.5567 - val_loss: 1.3419 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9357 - loss: 0.5645 - val_accuracy: 0.5515 - val_loss: 1.1147 - learning_rate: 1.0000e-03\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9169 - loss: 0.5320 - val_accuracy: 0.5515 - val_loss: 1.1387 - learning_rate: 1.0000e-03\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9349 - loss: 0.5335 - val_accuracy: 0.5567 - val_loss: 1.1046 - learning_rate: 1.0000e-03\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9469 - loss: 0.5233 - val_accuracy: 0.5670 - val_loss: 1.1040 - learning_rate: 1.0000e-03\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.5266 - val_accuracy: 0.5670 - val_loss: 1.1130 - learning_rate: 1.0000e-03\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9235 - loss: 0.5230 - val_accuracy: 0.5619 - val_loss: 1.1246 - learning_rate: 1.0000e-03\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9386 - loss: 0.5001 - val_accuracy: 0.5515 - val_loss: 1.1112 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9475 - loss: 0.4920 - val_accuracy: 0.5464 - val_loss: 1.1453 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9322 - loss: 0.5407 - val_accuracy: 0.5567 - val_loss: 1.1174 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9412 - loss: 0.5303\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9391 - loss: 0.5296 - val_accuracy: 0.5515 - val_loss: 1.1222 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9372 - loss: 0.5228 - val_accuracy: 0.5567 - val_loss: 1.1175 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9326 - loss: 0.5135 - val_accuracy: 0.5567 - val_loss: 1.1237 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9321 - loss: 0.5095 - val_accuracy: 0.5515 - val_loss: 1.1290 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9357 - loss: 0.5197 - val_accuracy: 0.5515 - val_loss: 1.1273 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9404 - loss: 0.5119 - val_accuracy: 0.5567 - val_loss: 1.1245 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9514 - loss: 0.4952 - val_accuracy: 0.5567 - val_loss: 1.1262 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9257 - loss: 0.5287 - val_accuracy: 0.5567 - val_loss: 1.1233 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9331 - loss: 0.5084 - val_accuracy: 0.5515 - val_loss: 1.1275 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9275 - loss: 0.5328 - val_accuracy: 0.5515 - val_loss: 1.1267 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9316 - loss: 0.5089\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9320 - loss: 0.5111 - val_accuracy: 0.5515 - val_loss: 1.1301 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9427 - loss: 0.5047 - val_accuracy: 0.5515 - val_loss: 1.1298 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9411 - loss: 0.5262 - val_accuracy: 0.5515 - val_loss: 1.1298 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9277 - loss: 0.5074 - val_accuracy: 0.5515 - val_loss: 1.1299 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9370 - loss: 0.5119 - val_accuracy: 0.5515 - val_loss: 1.1296 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9418 - loss: 0.5128 - val_accuracy: 0.5515 - val_loss: 1.1296 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9223 - loss: 0.5343 - val_accuracy: 0.5515 - val_loss: 1.1293 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9253 - loss: 0.5136 - val_accuracy: 0.5515 - val_loss: 1.1292 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9277 - loss: 0.5071 - val_accuracy: 0.5515 - val_loss: 1.1291 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9354 - loss: 0.5100 - val_accuracy: 0.5515 - val_loss: 1.1291 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9152 - loss: 0.5378\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9194 - loss: 0.5347 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9306 - loss: 0.5279 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9498 - loss: 0.5145 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9501 - loss: 0.5109 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9474 - loss: 0.5100 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9461 - loss: 0.5032 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9291 - loss: 0.5322 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9387 - loss: 0.5019 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9427 - loss: 0.5201 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9475 - loss: 0.5390 - val_accuracy: 0.5515 - val_loss: 1.1288 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b1d443af1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step\n",
            "Fold 3 Weighted F1 Score: 0.7144888958480127\n",
            "Fold 4/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.9409 - loss: 0.5414 - val_accuracy: 0.5487 - val_loss: 1.0698 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9327 - loss: 0.5425 - val_accuracy: 0.5436 - val_loss: 1.1266 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9275 - loss: 0.5084 - val_accuracy: 0.5846 - val_loss: 1.0949 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9317 - loss: 0.5172 - val_accuracy: 0.5333 - val_loss: 1.0698 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9366 - loss: 0.5526 - val_accuracy: 0.5436 - val_loss: 1.3585 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9264 - loss: 0.5223 - val_accuracy: 0.5385 - val_loss: 1.1444 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9073 - loss: 0.5150 - val_accuracy: 0.5590 - val_loss: 1.0747 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9167 - loss: 0.5184 - val_accuracy: 0.5692 - val_loss: 1.0565 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9316 - loss: 0.4995 - val_accuracy: 0.5744 - val_loss: 1.3323 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9445 - loss: 0.5366 - val_accuracy: 0.5538 - val_loss: 1.2522 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9220 - loss: 0.5256 - val_accuracy: 0.5641 - val_loss: 1.1166 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9353 - loss: 0.5047 - val_accuracy: 0.5385 - val_loss: 1.0974 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9285 - loss: 0.4884 - val_accuracy: 0.5538 - val_loss: 1.1002 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9300 - loss: 0.5262 - val_accuracy: 0.5590 - val_loss: 1.0405 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9334 - loss: 0.4970 - val_accuracy: 0.5641 - val_loss: 1.0985 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9215 - loss: 0.4958 - val_accuracy: 0.5590 - val_loss: 1.0892 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9145 - loss: 0.5319 - val_accuracy: 0.5436 - val_loss: 1.2020 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9186 - loss: 0.4892 - val_accuracy: 0.5385 - val_loss: 1.0114 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9349 - loss: 0.5150 - val_accuracy: 0.5590 - val_loss: 1.0375 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9288 - loss: 0.5003 - val_accuracy: 0.5590 - val_loss: 1.0839 - learning_rate: 0.0100\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9258 - loss: 0.5008 - val_accuracy: 0.5385 - val_loss: 1.0180 - learning_rate: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9100 - loss: 0.5179 - val_accuracy: 0.5282 - val_loss: 1.3183 - learning_rate: 0.0100\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9293 - loss: 0.4958 - val_accuracy: 0.5436 - val_loss: 1.2201 - learning_rate: 0.0100\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9070 - loss: 0.5038 - val_accuracy: 0.5282 - val_loss: 1.2696 - learning_rate: 0.0100\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9355 - loss: 0.4938 - val_accuracy: 0.5538 - val_loss: 1.3522 - learning_rate: 0.0100\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9332 - loss: 0.4853 - val_accuracy: 0.5538 - val_loss: 1.1556 - learning_rate: 0.0100\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9246 - loss: 0.4761 - val_accuracy: 0.5436 - val_loss: 1.0814 - learning_rate: 0.0100\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9167 - loss: 0.4779\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9164 - loss: 0.4783 - val_accuracy: 0.5641 - val_loss: 1.1551 - learning_rate: 0.0100\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9066 - loss: 0.4704 - val_accuracy: 0.5641 - val_loss: 1.1699 - learning_rate: 1.0000e-03\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9151 - loss: 0.4550 - val_accuracy: 0.5590 - val_loss: 1.1457 - learning_rate: 1.0000e-03\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9188 - loss: 0.4711 - val_accuracy: 0.5641 - val_loss: 1.1367 - learning_rate: 1.0000e-03\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9169 - loss: 0.4603 - val_accuracy: 0.5641 - val_loss: 1.1215 - learning_rate: 1.0000e-03\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9108 - loss: 0.4591 - val_accuracy: 0.5641 - val_loss: 1.1428 - learning_rate: 1.0000e-03\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9218 - loss: 0.4644 - val_accuracy: 0.5641 - val_loss: 1.1237 - learning_rate: 1.0000e-03\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9203 - loss: 0.4699 - val_accuracy: 0.5641 - val_loss: 1.1831 - learning_rate: 1.0000e-03\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9272 - loss: 0.4665 - val_accuracy: 0.5590 - val_loss: 1.1451 - learning_rate: 1.0000e-03\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9286 - loss: 0.4345 - val_accuracy: 0.5692 - val_loss: 1.1135 - learning_rate: 1.0000e-03\n",
            "Epoch 38/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9219 - loss: 0.4615\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9221 - loss: 0.4619 - val_accuracy: 0.5590 - val_loss: 1.1612 - learning_rate: 1.0000e-03\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9291 - loss: 0.4407 - val_accuracy: 0.5590 - val_loss: 1.1574 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9238 - loss: 0.4415 - val_accuracy: 0.5590 - val_loss: 1.1579 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9336 - loss: 0.4434 - val_accuracy: 0.5590 - val_loss: 1.1562 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9164 - loss: 0.4811 - val_accuracy: 0.5590 - val_loss: 1.1501 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9197 - loss: 0.4568 - val_accuracy: 0.5590 - val_loss: 1.1519 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9250 - loss: 0.4511 - val_accuracy: 0.5590 - val_loss: 1.1528 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9279 - loss: 0.4449 - val_accuracy: 0.5590 - val_loss: 1.1562 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9317 - loss: 0.4449 - val_accuracy: 0.5590 - val_loss: 1.1468 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9467 - loss: 0.4535 - val_accuracy: 0.5590 - val_loss: 1.1451 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9224 - loss: 0.4675\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9227 - loss: 0.4662 - val_accuracy: 0.5590 - val_loss: 1.1431 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9162 - loss: 0.4746 - val_accuracy: 0.5590 - val_loss: 1.1428 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9370 - loss: 0.4394 - val_accuracy: 0.5590 - val_loss: 1.1434 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b1ce07f9120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step\n",
            "Fold 4 Weighted F1 Score: 0.7023186157260758\n",
            "Fold 5/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.9246 - loss: 0.5113 - val_accuracy: 0.5641 - val_loss: 1.2447 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9234 - loss: 0.5012 - val_accuracy: 0.5538 - val_loss: 1.4198 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9171 - loss: 0.5134 - val_accuracy: 0.5744 - val_loss: 1.0418 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9100 - loss: 0.5098 - val_accuracy: 0.5641 - val_loss: 1.1818 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9212 - loss: 0.5012 - val_accuracy: 0.5846 - val_loss: 0.9713 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9042 - loss: 0.5235 - val_accuracy: 0.5795 - val_loss: 1.2172 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9116 - loss: 0.5270 - val_accuracy: 0.5538 - val_loss: 1.2775 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9262 - loss: 0.5021 - val_accuracy: 0.5538 - val_loss: 1.3666 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9388 - loss: 0.5048 - val_accuracy: 0.5487 - val_loss: 1.4393 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9406 - loss: 0.4958 - val_accuracy: 0.5744 - val_loss: 1.1090 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9263 - loss: 0.5081 - val_accuracy: 0.5590 - val_loss: 1.2407 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9221 - loss: 0.4722 - val_accuracy: 0.5744 - val_loss: 1.0713 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9211 - loss: 0.4944 - val_accuracy: 0.5538 - val_loss: 1.3547 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9252 - loss: 0.4703 - val_accuracy: 0.5487 - val_loss: 1.0928 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9212 - loss: 0.5058\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9223 - loss: 0.5029 - val_accuracy: 0.5641 - val_loss: 1.2132 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9205 - loss: 0.4864 - val_accuracy: 0.5538 - val_loss: 1.2143 - learning_rate: 1.0000e-03\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9423 - loss: 0.4620 - val_accuracy: 0.5692 - val_loss: 1.2320 - learning_rate: 1.0000e-03\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9336 - loss: 0.4586 - val_accuracy: 0.5641 - val_loss: 1.2318 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9421 - loss: 0.4712 - val_accuracy: 0.5538 - val_loss: 1.2669 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9080 - loss: 0.4856 - val_accuracy: 0.5590 - val_loss: 1.2617 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9209 - loss: 0.4621 - val_accuracy: 0.5487 - val_loss: 1.2547 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9387 - loss: 0.4699 - val_accuracy: 0.5744 - val_loss: 1.2359 - learning_rate: 1.0000e-03\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9247 - loss: 0.4680 - val_accuracy: 0.5692 - val_loss: 1.2507 - learning_rate: 1.0000e-03\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9402 - loss: 0.4533 - val_accuracy: 0.5744 - val_loss: 1.2471 - learning_rate: 1.0000e-03\n",
            "Epoch 25/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9126 - loss: 0.4627\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9162 - loss: 0.4612 - val_accuracy: 0.5692 - val_loss: 1.2298 - learning_rate: 1.0000e-03\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9459 - loss: 0.4348 - val_accuracy: 0.5692 - val_loss: 1.2375 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9276 - loss: 0.4669 - val_accuracy: 0.5744 - val_loss: 1.2397 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9227 - loss: 0.4423 - val_accuracy: 0.5744 - val_loss: 1.2441 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9385 - loss: 0.4362 - val_accuracy: 0.5744 - val_loss: 1.2402 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9266 - loss: 0.4667 - val_accuracy: 0.5744 - val_loss: 1.2452 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9269 - loss: 0.4519 - val_accuracy: 0.5795 - val_loss: 1.2357 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9488 - loss: 0.4585 - val_accuracy: 0.5744 - val_loss: 1.2442 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9398 - loss: 0.4514 - val_accuracy: 0.5744 - val_loss: 1.2449 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9312 - loss: 0.4496 - val_accuracy: 0.5795 - val_loss: 1.2348 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9294 - loss: 0.4682\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9298 - loss: 0.4655 - val_accuracy: 0.5744 - val_loss: 1.2379 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9340 - loss: 0.4499 - val_accuracy: 0.5744 - val_loss: 1.2381 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9394 - loss: 0.4630 - val_accuracy: 0.5744 - val_loss: 1.2381 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9293 - loss: 0.4642 - val_accuracy: 0.5744 - val_loss: 1.2389 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9343 - loss: 0.4481 - val_accuracy: 0.5744 - val_loss: 1.2393 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9408 - loss: 0.4433 - val_accuracy: 0.5744 - val_loss: 1.2393 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9370 - loss: 0.4415 - val_accuracy: 0.5744 - val_loss: 1.2394 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9317 - loss: 0.4595 - val_accuracy: 0.5744 - val_loss: 1.2398 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9234 - loss: 0.4824 - val_accuracy: 0.5744 - val_loss: 1.2401 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9259 - loss: 0.4513 - val_accuracy: 0.5744 - val_loss: 1.2408 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9166 - loss: 0.4577\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9196 - loss: 0.4566 - val_accuracy: 0.5744 - val_loss: 1.2409 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9299 - loss: 0.4411 - val_accuracy: 0.5744 - val_loss: 1.2410 - learning_rate: 1.0000e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9468 - loss: 0.4381 - val_accuracy: 0.5744 - val_loss: 1.2410 - learning_rate: 1.0000e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9401 - loss: 0.4435 - val_accuracy: 0.5744 - val_loss: 1.2410 - learning_rate: 1.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9300 - loss: 0.4695 - val_accuracy: 0.5744 - val_loss: 1.2410 - learning_rate: 1.0000e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9277 - loss: 0.4664 - val_accuracy: 0.5744 - val_loss: 1.2411 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Fold 5 Weighted F1 Score: 0.6931488376183635\n",
            "Average Weighted F1 Score across all folds: 0.6869208878647528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZNG20i3e9yl",
        "outputId": "626db700-5fb4-4597-c7e3-7a5d5aea939d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6421510153154264,\n",
              " 0.6824970748158855,\n",
              " 0.7144888958480127,\n",
              " 0.7023186157260758,\n",
              " 0.6931488376183635]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_fold_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDe1WCFBOuhJ",
        "outputId": "a7c416f3-dd80-442c-fb15-9a76f13d4a19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'y_val': array([[1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]]),\n",
              " 'y_pred': array([[0.9519999 , 0.23840077],\n",
              "        [0.9861326 , 0.6053636 ],\n",
              "        [0.8962833 , 0.9351248 ],\n",
              "        [0.9970733 , 0.8485068 ],\n",
              "        [0.98416615, 0.7198147 ],\n",
              "        [0.9986946 , 0.3286837 ],\n",
              "        [0.7371614 , 0.3270398 ],\n",
              "        [0.95760363, 0.18140759],\n",
              "        [0.98577905, 0.5848588 ],\n",
              "        [0.96641344, 0.29010856],\n",
              "        [0.9564929 , 0.4047447 ],\n",
              "        [0.974357  , 0.08621513],\n",
              "        [0.99982435, 0.12526193],\n",
              "        [0.96796304, 0.2609218 ],\n",
              "        [0.9885013 , 0.23033659],\n",
              "        [0.9854689 , 0.30648234],\n",
              "        [0.9783297 , 0.24670047],\n",
              "        [0.9950001 , 0.5842189 ],\n",
              "        [0.9943117 , 0.46352917],\n",
              "        [0.8458908 , 0.09347317],\n",
              "        [0.9974642 , 0.38424423],\n",
              "        [0.9633853 , 0.5255069 ],\n",
              "        [0.81895113, 0.274503  ],\n",
              "        [0.8538892 , 0.6144123 ],\n",
              "        [0.8549889 , 0.27483585],\n",
              "        [0.5946295 , 0.42679927],\n",
              "        [0.95061487, 0.80358547],\n",
              "        [0.9741247 , 0.67457014],\n",
              "        [0.9984536 , 0.53913546],\n",
              "        [0.9906227 , 0.24201523],\n",
              "        [0.98615754, 0.4811866 ],\n",
              "        [0.99933404, 0.12736918],\n",
              "        [0.99979085, 0.00330893],\n",
              "        [0.97922724, 0.5237844 ],\n",
              "        [0.99517256, 0.34897757],\n",
              "        [0.9811989 , 0.34829977],\n",
              "        [0.9841076 , 0.11058551],\n",
              "        [0.9841673 , 0.0280376 ],\n",
              "        [0.9743222 , 0.4766066 ],\n",
              "        [0.9675734 , 0.13494693],\n",
              "        [0.99948174, 0.06952482],\n",
              "        [0.97488016, 0.35497788],\n",
              "        [0.9987658 , 0.18503918],\n",
              "        [0.9336743 , 0.3045015 ],\n",
              "        [0.99989593, 0.32365283],\n",
              "        [0.9994029 , 0.62107575],\n",
              "        [0.98376024, 0.31965396],\n",
              "        [0.97627956, 0.50062627],\n",
              "        [0.89097095, 0.32448897],\n",
              "        [0.9450806 , 0.31258646],\n",
              "        [0.9810946 , 0.12218531],\n",
              "        [0.99898654, 0.17175047],\n",
              "        [0.9833398 , 0.343996  ],\n",
              "        [0.9922531 , 0.04128606],\n",
              "        [0.89685214, 0.5768718 ],\n",
              "        [0.9771385 , 0.53520447],\n",
              "        [0.9543535 , 0.15679705],\n",
              "        [0.9988851 , 0.47656155],\n",
              "        [0.99815184, 0.21392354],\n",
              "        [0.97512984, 0.3124286 ],\n",
              "        [0.9796484 , 0.20679656],\n",
              "        [0.91629344, 0.4234524 ],\n",
              "        [0.97906965, 0.34235877],\n",
              "        [0.9961139 , 0.0866688 ],\n",
              "        [0.9188689 , 0.5515843 ],\n",
              "        [0.92579424, 0.58915484],\n",
              "        [0.9994797 , 0.3013128 ],\n",
              "        [0.99065053, 0.9986015 ],\n",
              "        [0.9707812 , 0.34550378],\n",
              "        [0.8885309 , 0.0965574 ],\n",
              "        [0.9865514 , 0.12783366],\n",
              "        [0.96679986, 0.12316632],\n",
              "        [0.8464318 , 0.14777651],\n",
              "        [0.9669584 , 0.6295733 ],\n",
              "        [0.69560975, 0.5279376 ],\n",
              "        [0.9295553 , 0.1857617 ],\n",
              "        [0.99952507, 0.68218   ],\n",
              "        [0.9991844 , 0.55372113],\n",
              "        [0.999622  , 0.9738338 ],\n",
              "        [0.99215513, 0.8604779 ],\n",
              "        [0.95221364, 0.77463293],\n",
              "        [0.94179684, 0.35908628],\n",
              "        [0.95212716, 0.31079346],\n",
              "        [0.98988336, 0.14515337],\n",
              "        [0.8678338 , 0.53297627],\n",
              "        [0.9408494 , 0.86822593],\n",
              "        [0.94636756, 0.34309617],\n",
              "        [0.8970288 , 0.3830462 ],\n",
              "        [0.996327  , 0.37001106],\n",
              "        [0.99852115, 0.16952537],\n",
              "        [0.9938116 , 0.5282707 ],\n",
              "        [0.61764115, 0.56005085],\n",
              "        [0.9567151 , 0.26740906],\n",
              "        [0.9521451 , 0.88682246],\n",
              "        [0.9553157 , 0.07323364],\n",
              "        [0.99110657, 0.6695024 ],\n",
              "        [0.7789684 , 0.40418825],\n",
              "        [0.9431045 , 0.5335004 ],\n",
              "        [0.9944781 , 0.31493804],\n",
              "        [0.99965227, 0.09617539],\n",
              "        [0.9321073 , 0.65292233],\n",
              "        [0.99011457, 0.5757573 ],\n",
              "        [0.9409243 , 0.18011622],\n",
              "        [0.9954364 , 0.6113259 ],\n",
              "        [0.9680769 , 0.7733401 ],\n",
              "        [0.9355658 , 0.68582547],\n",
              "        [0.96190166, 0.39906427],\n",
              "        [0.4003994 , 0.337394  ],\n",
              "        [0.9586822 , 0.76022315],\n",
              "        [0.95236075, 0.39441356],\n",
              "        [0.99916494, 0.17457193],\n",
              "        [0.9954526 , 0.31216154],\n",
              "        [0.89330506, 0.09462828],\n",
              "        [0.8531968 , 0.7749678 ],\n",
              "        [0.81891906, 0.47130036],\n",
              "        [0.9094814 , 0.22012262],\n",
              "        [0.9897142 , 0.70319164],\n",
              "        [0.9136487 , 0.6263273 ],\n",
              "        [0.9947455 , 0.47527644],\n",
              "        [0.5396847 , 0.3329574 ],\n",
              "        [0.9851461 , 0.2468551 ],\n",
              "        [0.9046069 , 0.5432287 ],\n",
              "        [0.99717534, 0.44575453],\n",
              "        [0.959085  , 0.627734  ],\n",
              "        [0.968793  , 0.64974344],\n",
              "        [0.9022696 , 0.08692873],\n",
              "        [0.9674906 , 0.2966269 ],\n",
              "        [0.99886644, 0.3216317 ],\n",
              "        [0.78018063, 0.3788625 ],\n",
              "        [0.88140064, 0.71982014],\n",
              "        [0.8779286 , 0.05183364],\n",
              "        [0.3793772 , 0.11196315],\n",
              "        [0.95117486, 0.29844055],\n",
              "        [0.82324386, 0.31515792],\n",
              "        [0.9786982 , 0.7904029 ],\n",
              "        [0.9877176 , 0.49008945],\n",
              "        [0.8041502 , 0.19182244],\n",
              "        [0.96604186, 0.48905736],\n",
              "        [0.9676414 , 0.42586178],\n",
              "        [0.94197494, 0.42810163],\n",
              "        [0.9995435 , 0.6855891 ],\n",
              "        [0.8560914 , 0.47219616],\n",
              "        [0.99350786, 0.39358833],\n",
              "        [0.9279094 , 0.3739908 ],\n",
              "        [0.98674566, 0.7756463 ],\n",
              "        [0.8111629 , 0.18254319],\n",
              "        [0.6480544 , 0.10668298],\n",
              "        [0.9516594 , 0.40762296],\n",
              "        [0.9966943 , 0.15206972],\n",
              "        [0.9843679 , 0.40007433],\n",
              "        [0.9070549 , 0.33390853],\n",
              "        [0.99722147, 0.47424066],\n",
              "        [0.98178804, 0.41656485],\n",
              "        [0.97909284, 0.12703715],\n",
              "        [0.9763737 , 0.57392186],\n",
              "        [0.9939705 , 0.2527092 ],\n",
              "        [0.821802  , 0.48202577],\n",
              "        [0.77881396, 0.12368457],\n",
              "        [0.7796207 , 0.6269925 ],\n",
              "        [0.9834374 , 0.11281968],\n",
              "        [0.12645285, 0.17829917],\n",
              "        [0.6070322 , 0.36469874],\n",
              "        [0.30168912, 0.48365983],\n",
              "        [0.522199  , 0.1121216 ],\n",
              "        [0.44799745, 0.48675543],\n",
              "        [0.3442522 , 0.4090308 ],\n",
              "        [0.35142627, 0.20877047],\n",
              "        [0.45757914, 0.3084024 ],\n",
              "        [0.9945774 , 0.11913744],\n",
              "        [0.99766314, 0.78148466],\n",
              "        [0.99088025, 0.7921771 ],\n",
              "        [0.9851136 , 0.7057763 ],\n",
              "        [0.34415936, 0.3832311 ],\n",
              "        [0.8328101 , 0.35674772],\n",
              "        [0.5161023 , 0.35076025],\n",
              "        [0.55333215, 0.77985436],\n",
              "        [0.9873154 , 0.4586402 ],\n",
              "        [0.7483203 , 0.7088265 ],\n",
              "        [0.83984536, 0.5984356 ],\n",
              "        [0.33548886, 0.39435947],\n",
              "        [0.6461318 , 0.77096176],\n",
              "        [0.435994  , 0.47569364],\n",
              "        [0.20044467, 0.29171595],\n",
              "        [0.9492377 , 0.30977705],\n",
              "        [0.7841804 , 0.8823846 ],\n",
              "        [0.83687145, 0.03137324],\n",
              "        [0.9693888 , 0.8715854 ],\n",
              "        [0.97701114, 0.76514107],\n",
              "        [0.20935878, 0.0789843 ],\n",
              "        [0.98883855, 0.59534997],\n",
              "        [0.07520546, 0.13859153],\n",
              "        [0.18825826, 0.47548482],\n",
              "        [0.4768075 , 0.55633545],\n",
              "        [0.288669  , 0.23801413],\n",
              "        [0.882715  , 0.6754009 ],\n",
              "        [0.836511  , 0.46780238],\n",
              "        [0.21900715, 0.01700709],\n",
              "        [0.9051845 , 0.99460113],\n",
              "        [0.75568736, 0.47562772],\n",
              "        [0.6431156 , 0.33575448],\n",
              "        [0.9442981 , 0.21395981],\n",
              "        [0.6490384 , 0.12062486],\n",
              "        [0.94902   , 0.23638053],\n",
              "        [0.7683113 , 0.98701173],\n",
              "        [0.25859174, 0.55323726],\n",
              "        [0.5654743 , 0.59584284],\n",
              "        [0.97493637, 0.35283998],\n",
              "        [0.593603  , 0.3456306 ],\n",
              "        [0.8499777 , 0.15247834],\n",
              "        [0.8049386 , 0.7068433 ],\n",
              "        [0.71924305, 0.3376293 ],\n",
              "        [0.9617562 , 0.13313383],\n",
              "        [0.18192498, 0.5114813 ],\n",
              "        [0.24893631, 0.48987457],\n",
              "        [0.33827776, 0.6352287 ],\n",
              "        [0.6522855 , 0.42971292],\n",
              "        [0.1985751 , 0.10940201],\n",
              "        [0.9214463 , 0.02187261],\n",
              "        [0.18664858, 0.02777608],\n",
              "        [0.95578104, 0.45331898],\n",
              "        [0.8765358 , 0.6449036 ],\n",
              "        [0.5059276 , 0.68740463],\n",
              "        [0.7471342 , 0.7524746 ],\n",
              "        [0.73781055, 0.38436225],\n",
              "        [0.81831884, 0.4448757 ],\n",
              "        [0.44747767, 0.13366796],\n",
              "        [0.3505493 , 0.39370704],\n",
              "        [0.45747358, 0.20981008],\n",
              "        [0.96245813, 0.8874073 ],\n",
              "        [0.45139304, 0.27514923],\n",
              "        [0.85195416, 0.624024  ],\n",
              "        [0.90048873, 0.46256873],\n",
              "        [0.94782555, 0.64073914],\n",
              "        [0.7468181 , 0.4626126 ],\n",
              "        [0.49445185, 0.16592477],\n",
              "        [0.88442534, 0.56462765],\n",
              "        [0.83821756, 0.4830153 ],\n",
              "        [0.05270683, 0.30536714],\n",
              "        [0.32331735, 0.6349708 ],\n",
              "        [0.668008  , 0.14799692],\n",
              "        [0.9414679 , 0.13249978],\n",
              "        [0.86677307, 0.47770882]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwHwAJV8uHDb"
      },
      "source": [
        "## Threshold tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "VuDsSk12uHSE",
        "outputId": "e589a51f-9236-4a3e-fa4b-9469c4f2172f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: (np.float64(0.28), np.float64(0.36000000000000004))\n",
            "Best F1 Score: 0.6946276493564705\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define a range of thresholds to evaluate\n",
        "from itertools import product\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "thresholds = np.linspace(0.02, 0.98, 49)\n",
        "threshold_combinations = list(product(thresholds, thresholds))\n",
        "\n",
        "def classify_with_threshold(y_pred, t1, t2):\n",
        "  y_pred_classes = np.zeros_like(y_pred, dtype=int)\n",
        "  y_pred_classes[:, 0] = (y_pred[:, 0] > t1).astype(int)\n",
        "  y_pred_classes[:, 1] = (y_pred[:, 1] > t2).astype(int)\n",
        "  return y_pred_classes\n",
        "\n",
        "# Loop over thresholds to compute F1 score for each\n",
        "f1_scores = []\n",
        "for t1, t2 in threshold_combinations:\n",
        "    # Convert probabilities to class labels (0 or 1)\n",
        "    y_pred_classes = classify_with_threshold(y_pred, t1, t2)\n",
        "    # Calculate weighted F1 score\n",
        "    y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.int16)\n",
        "    y_pred_tensor = tf.convert_to_tensor(y_pred_classes, dtype=tf.int16)\n",
        "    # f1 = calculate_weighted_f1_score(y_val, y_pred_classes)\n",
        "    f1, f1_adhd, f1_sex = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Convert to numpy arrays for convenience\n",
        "f1_scores = np.array(f1_scores)\n",
        "\n",
        "# Find the best threshold and corresponding F1 score\n",
        "best_index = np.argmax(f1_scores)\n",
        "best_threshold = threshold_combinations[best_index]\n",
        "best_f1 = f1_scores[best_index]\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", best_f1)\n",
        "\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Convert threshold combinations to x, y coordinates\n",
        "x = [t[0] for t in threshold_combinations]\n",
        "y = [t[1] for t in threshold_combinations]\n",
        "z = f1_scores\n",
        "\n",
        "# Create a scatter plot of F1 scores\n",
        "img = ax.scatter(x, y, z, c=z, cmap='viridis')\n",
        "\n",
        "# Highlight the best F1 score point\n",
        "ax.scatter(best_threshold[0], best_threshold[1], best_f1, color='red', s=100,\n",
        "           label= f'Best: {best_f1:.3f} (Threshold: {best_threshold[0]:.2f}, {best_threshold[1]:.2f})')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Threshold 1')\n",
        "ax.set_ylabel('Threshold 2')\n",
        "ax.set_zlabel('F1 Score')\n",
        "ax.set_title('Interactive 3D Heatmap of F1 Scores')\n",
        "\n",
        "# Add a color bar\n",
        "fig.colorbar(img, ax=ax)\n",
        "\n",
        "# Make the plot interactive\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46NyGR2QRxHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfZv_-uyvCmG"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QnCU99hzE2Rs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARvEDI3vRrg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e632317-0a53-4851-f5a0-cce133241578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(304, 200, 200, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# X_test_cnn = df_test_X.reshape(df_test_X.shape[0], df_test_X.shape[1], 1)\n",
        "# X_test_cnn = connectome_matrices_test[..., np.newaxis]\n",
        "# X_test_cnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc01my4n5Jn9",
        "outputId": "dbec5bdb-e9c1-454e-e49f-81337807b30c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 684ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7959651 , 0.32561   ],\n",
              "       [0.6631302 , 0.21308805],\n",
              "       [0.974282  , 0.35367855],\n",
              "       [0.949085  , 0.13856368],\n",
              "       [0.4627343 , 0.57986236],\n",
              "       [0.7981347 , 0.24351336],\n",
              "       [0.85186577, 0.3636844 ],\n",
              "       [0.84053725, 0.23418865],\n",
              "       [0.9456729 , 0.36715353],\n",
              "       [0.9254804 , 0.4762097 ],\n",
              "       [0.5190235 , 0.49600157],\n",
              "       [0.990807  , 0.17829867],\n",
              "       [0.965709  , 0.1557051 ],\n",
              "       [0.9465776 , 0.26104942],\n",
              "       [0.8250758 , 0.30375907],\n",
              "       [0.3689472 , 0.3515932 ],\n",
              "       [0.62103254, 0.30291897],\n",
              "       [0.85552835, 0.15077648],\n",
              "       [0.57798725, 0.34479022],\n",
              "       [0.9572357 , 0.3085968 ],\n",
              "       [0.94251686, 0.11747731],\n",
              "       [0.97003967, 0.20382889],\n",
              "       [0.9654767 , 0.21589215],\n",
              "       [0.84040534, 0.32144588],\n",
              "       [0.95755255, 0.20472434],\n",
              "       [0.72912407, 0.44277066],\n",
              "       [0.9277785 , 0.23328254],\n",
              "       [0.940326  , 0.3667889 ],\n",
              "       [0.96667475, 0.26313457],\n",
              "       [0.98506635, 0.33633694],\n",
              "       [0.7695343 , 0.1702741 ],\n",
              "       [0.04025505, 0.22684203],\n",
              "       [0.9730366 , 0.6815122 ],\n",
              "       [0.5687493 , 0.30712968],\n",
              "       [0.77859193, 0.31033355],\n",
              "       [0.63890845, 0.29865003],\n",
              "       [0.7828807 , 0.38600558],\n",
              "       [0.15902095, 0.44501805],\n",
              "       [0.60125107, 0.38168487],\n",
              "       [0.9367933 , 0.21118297],\n",
              "       [0.88702625, 0.29553676],\n",
              "       [0.38940498, 0.43639746],\n",
              "       [0.7014703 , 0.24646239],\n",
              "       [0.95703065, 0.58671516],\n",
              "       [0.25018844, 0.30660492],\n",
              "       [0.68825245, 0.5789386 ],\n",
              "       [0.9381412 , 0.12365787],\n",
              "       [0.91454834, 0.5620384 ],\n",
              "       [0.97341007, 0.13036461],\n",
              "       [0.3252224 , 0.39789692],\n",
              "       [0.7193719 , 0.2787107 ],\n",
              "       [0.6745833 , 0.2412317 ],\n",
              "       [0.79255784, 0.37030837],\n",
              "       [0.9740787 , 0.45915076],\n",
              "       [0.40229172, 0.65865815],\n",
              "       [0.37699226, 0.24364316],\n",
              "       [0.7518029 , 0.42541668],\n",
              "       [0.8688013 , 0.28155166],\n",
              "       [0.77370095, 0.34338695],\n",
              "       [0.91643155, 0.13938482],\n",
              "       [0.6820524 , 0.44152915],\n",
              "       [0.90004313, 0.09151614],\n",
              "       [0.6921568 , 0.44590196],\n",
              "       [0.6519579 , 0.28418726],\n",
              "       [0.56983656, 0.46300134],\n",
              "       [0.4161553 , 0.43682298],\n",
              "       [0.81961095, 0.31336805],\n",
              "       [0.52533096, 0.45470545],\n",
              "       [0.26451233, 0.5662106 ],\n",
              "       [0.8092092 , 0.24651028],\n",
              "       [0.4963699 , 0.4890686 ],\n",
              "       [0.97238845, 0.14838229],\n",
              "       [0.8681511 , 0.2768294 ],\n",
              "       [0.44561255, 0.38048407],\n",
              "       [0.5877388 , 0.29599112],\n",
              "       [0.45644692, 0.358687  ],\n",
              "       [0.17214687, 0.56934774],\n",
              "       [0.82313347, 0.54675484],\n",
              "       [0.13442443, 0.31425413],\n",
              "       [0.61639756, 0.38556504],\n",
              "       [0.3927216 , 0.5254509 ],\n",
              "       [0.78524685, 0.15856457],\n",
              "       [0.8905084 , 0.15507439],\n",
              "       [0.18714795, 0.42550135],\n",
              "       [0.9049044 , 0.41850337],\n",
              "       [0.8221153 , 0.3530435 ],\n",
              "       [0.1238215 , 0.47784957],\n",
              "       [0.63923204, 0.29644606],\n",
              "       [0.25209227, 0.3196016 ],\n",
              "       [0.9702152 , 0.3396323 ],\n",
              "       [0.4140297 , 0.51153433],\n",
              "       [0.8162411 , 0.37221107],\n",
              "       [0.4166746 , 0.3752927 ],\n",
              "       [0.93238115, 0.55366296],\n",
              "       [0.80783784, 0.51851344],\n",
              "       [0.54459   , 0.50672525],\n",
              "       [0.96396655, 0.31115848],\n",
              "       [0.94915885, 0.15312986],\n",
              "       [0.6216205 , 0.26571098],\n",
              "       [0.7603532 , 0.57337224],\n",
              "       [0.16112085, 0.5307441 ],\n",
              "       [0.83982307, 0.2818196 ],\n",
              "       [0.9857625 , 0.31294677],\n",
              "       [0.92815816, 0.07559522],\n",
              "       [0.9691256 , 0.36426046],\n",
              "       [0.19083102, 0.5824207 ],\n",
              "       [0.5048958 , 0.38027155],\n",
              "       [0.9581796 , 0.16352418],\n",
              "       [0.24303335, 0.6000165 ],\n",
              "       [0.8853612 , 0.31253773],\n",
              "       [0.51652396, 0.47649917],\n",
              "       [0.12613794, 0.54529274],\n",
              "       [0.35029876, 0.4795836 ],\n",
              "       [0.7324817 , 0.43107703],\n",
              "       [0.32412395, 0.28313327],\n",
              "       [0.9209861 , 0.22804545],\n",
              "       [0.41765508, 0.35702989],\n",
              "       [0.84599817, 0.26419201],\n",
              "       [0.70346844, 0.37212628],\n",
              "       [0.8940561 , 0.28685215],\n",
              "       [0.902382  , 0.41658282],\n",
              "       [0.43257943, 0.36562294],\n",
              "       [0.6599969 , 0.48315898],\n",
              "       [0.7021739 , 0.33202705],\n",
              "       [0.87137085, 0.38538638],\n",
              "       [0.85864496, 0.31050584],\n",
              "       [0.7444803 , 0.3922718 ],\n",
              "       [0.9376361 , 0.63352185],\n",
              "       [0.8394832 , 0.19981293],\n",
              "       [0.8853977 , 0.14352101],\n",
              "       [0.87373334, 0.35846263],\n",
              "       [0.54113144, 0.21499759],\n",
              "       [0.58635265, 0.44782135],\n",
              "       [0.7544328 , 0.40199536],\n",
              "       [0.9384514 , 0.21524899],\n",
              "       [0.8522754 , 0.28928378],\n",
              "       [0.58207536, 0.21718712],\n",
              "       [0.17741142, 0.3730628 ],\n",
              "       [0.9443878 , 0.20377474],\n",
              "       [0.65068316, 0.3992559 ],\n",
              "       [0.67479295, 0.3155646 ],\n",
              "       [0.4632541 , 0.5388244 ],\n",
              "       [0.9112228 , 0.18743017],\n",
              "       [0.97438776, 0.26903802],\n",
              "       [0.3436607 , 0.204264  ],\n",
              "       [0.96697634, 0.39036462],\n",
              "       [0.9574412 , 0.278197  ],\n",
              "       [0.28929156, 0.4130093 ],\n",
              "       [0.88329583, 0.540853  ],\n",
              "       [0.5667953 , 0.32366586],\n",
              "       [0.26201034, 0.5044156 ],\n",
              "       [0.79922163, 0.67174727],\n",
              "       [0.16432741, 0.3866267 ],\n",
              "       [0.52816373, 0.5522656 ],\n",
              "       [0.96903473, 0.3888708 ],\n",
              "       [0.7167252 , 0.3451283 ],\n",
              "       [0.6511428 , 0.3808635 ],\n",
              "       [0.9180382 , 0.3693339 ],\n",
              "       [0.85947865, 0.30999318],\n",
              "       [0.8416684 , 0.510504  ],\n",
              "       [0.8584003 , 0.31808078],\n",
              "       [0.93936753, 0.3056638 ],\n",
              "       [0.5173045 , 0.5051593 ],\n",
              "       [0.27959216, 0.49327096],\n",
              "       [0.837951  , 0.27136663],\n",
              "       [0.9569893 , 0.21464029],\n",
              "       [0.8132959 , 0.2195401 ],\n",
              "       [0.96388716, 0.37638488],\n",
              "       [0.2925608 , 0.65132356],\n",
              "       [0.64292264, 0.40723217],\n",
              "       [0.9259197 , 0.21433935],\n",
              "       [0.52895117, 0.25366455],\n",
              "       [0.8915755 , 0.18449758],\n",
              "       [0.62680805, 0.49970546],\n",
              "       [0.86956257, 0.1946531 ],\n",
              "       [0.8850092 , 0.2718902 ],\n",
              "       [0.33700567, 0.49361044],\n",
              "       [0.69280607, 0.5378057 ],\n",
              "       [0.96417063, 0.3940427 ],\n",
              "       [0.13044381, 0.51167953],\n",
              "       [0.9560932 , 0.20281033],\n",
              "       [0.8569892 , 0.30841082],\n",
              "       [0.57587475, 0.39879656],\n",
              "       [0.61713403, 0.5906431 ],\n",
              "       [0.51445127, 0.45018768],\n",
              "       [0.73488134, 0.40208116],\n",
              "       [0.33899736, 0.31833142],\n",
              "       [0.7548244 , 0.2191922 ],\n",
              "       [0.23645733, 0.32347554],\n",
              "       [0.9702988 , 0.1679635 ],\n",
              "       [0.8368813 , 0.5073176 ],\n",
              "       [0.8218558 , 0.37180808],\n",
              "       [0.6284223 , 0.37092525],\n",
              "       [0.69822395, 0.41358405],\n",
              "       [0.93619066, 0.22031155],\n",
              "       [0.8884928 , 0.25352308],\n",
              "       [0.777205  , 0.31318706],\n",
              "       [0.5626316 , 0.30159417],\n",
              "       [0.88099855, 0.24693742],\n",
              "       [0.9519424 , 0.19551237],\n",
              "       [0.94661075, 0.3537    ],\n",
              "       [0.43008825, 0.44017535],\n",
              "       [0.6723878 , 0.4880187 ],\n",
              "       [0.41585016, 0.3370345 ],\n",
              "       [0.58967435, 0.49028182],\n",
              "       [0.9738775 , 0.22320014],\n",
              "       [0.99291366, 0.20400856],\n",
              "       [0.5330599 , 0.30453888],\n",
              "       [0.8777355 , 0.45355377],\n",
              "       [0.88003397, 0.2217279 ],\n",
              "       [0.987188  , 0.43708128],\n",
              "       [0.5755359 , 0.17275709],\n",
              "       [0.8606847 , 0.40046814],\n",
              "       [0.43525848, 0.61018705],\n",
              "       [0.8695037 , 0.465823  ],\n",
              "       [0.9900825 , 0.31603256],\n",
              "       [0.9105564 , 0.43707532],\n",
              "       [0.54770297, 0.4211844 ],\n",
              "       [0.42994928, 0.33090648],\n",
              "       [0.92063224, 0.5222674 ],\n",
              "       [0.9678939 , 0.1851802 ],\n",
              "       [0.90807384, 0.67387104],\n",
              "       [0.74342597, 0.66961086],\n",
              "       [0.5525344 , 0.366444  ],\n",
              "       [0.73228616, 0.31142017],\n",
              "       [0.900756  , 0.3227991 ],\n",
              "       [0.31285003, 0.49488956],\n",
              "       [0.12167104, 0.21589889],\n",
              "       [0.9926765 , 0.11315711],\n",
              "       [0.90230215, 0.38403812],\n",
              "       [0.9400266 , 0.1919456 ],\n",
              "       [0.9424228 , 0.38719255],\n",
              "       [0.40831414, 0.47619975],\n",
              "       [0.6653975 , 0.42151907],\n",
              "       [0.7080089 , 0.38850176],\n",
              "       [0.74476373, 0.5337762 ],\n",
              "       [0.44967803, 0.4463173 ],\n",
              "       [0.8992428 , 0.3521096 ],\n",
              "       [0.95408434, 0.18363833],\n",
              "       [0.6591474 , 0.27197376],\n",
              "       [0.9290746 , 0.2533326 ],\n",
              "       [0.5958372 , 0.33956143],\n",
              "       [0.8775604 , 0.4862271 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# # y_pred = model.predict([val_feature_matrices, val_adjacency_matrices, X_val_meta])\n",
        "# # y_pred = model.predict(X_val_cnn)\n",
        "# y_pred = model.predict([X_val_cnn, X_val_meta])\n",
        "# # X_test_meta\n",
        "# y_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CNN\n",
        "# X_test_meta = df_test_meta_imputed\n",
        "# print(X_test_meta.shape)\n",
        "# print(X_test_cnn.shape)\n",
        "\n",
        "# test_predictions = model.predict([X_test_cnn, X_test_meta])\n",
        "# test_predictions_classes = classify_with_threshold(test_predictions, best_threshold[0], best_threshold[1])\n",
        "# print(test_predictions_classes.shape)\n",
        "\n",
        "# submission_df = pd.DataFrame(test_predictions_classes, index=test_idx, columns=df_train_y.columns)\n",
        "# submission_df = submission_df.reset_index(names='participant_id')\n",
        "# submission_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "LP8tQSP7Eu3p",
        "outputId": "817c4b3e-052b-43ad-9871-2f887e719cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(304, 27)\n",
            "(304, 200, 200, 1)\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 724ms/step\n",
            "(304, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F\n",
              "0   Cfwaf5FX7jWK             1      0\n",
              "1   vhGrzmvA3Hjq             1      1\n",
              "2   ULliyEXjy4OV             1      0\n",
              "3   LZfeAb1xMtql             1      0\n",
              "4   EnFOUv0YK1RG             1      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93d9da13-93c1-4d42-b8ed-c5df70018d3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93d9da13-93c1-4d42-b8ed-c5df70018d3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93d9da13-93c1-4d42-b8ed-c5df70018d3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93d9da13-93c1-4d42-b8ed-c5df70018d3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdce0b96-9f50-4d76-8bfb-2601264aacf9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdce0b96-9f50-4d76-8bfb-2601264aacf9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdce0b96-9f50-4d76-8bfb-2601264aacf9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "jZOiS3G7vDqE",
        "outputId": "1f2a8fd3-2213-4726-b3f2-fcd687a68f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(304, 27)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
            "(304, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F\n",
              "0   Cfwaf5FX7jWK             1      0\n",
              "1   vhGrzmvA3Hjq             1      1\n",
              "2   ULliyEXjy4OV             1      0\n",
              "3   LZfeAb1xMtql             1      0\n",
              "4   EnFOUv0YK1RG             1      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51498683-c73b-410e-8168-e56eefc423c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51498683-c73b-410e-8168-e56eefc423c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51498683-c73b-410e-8168-e56eefc423c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51498683-c73b-410e-8168-e56eefc423c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-524987a7-9f30-4f54-bf37-8606896fefc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-524987a7-9f30-4f54-bf37-8606896fefc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-524987a7-9f30-4f54-bf37-8606896fefc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "X_test_meta = df_test_meta_imputed\n",
        "print(X_test_meta.shape)\n",
        "# test_adjacency_matrices = [create_adjacency_matrix(cm, threshold=0.45) for cm in connectome_matrices_test]\n",
        "# test_adjacency_matrices = np.array(test_adjacency_matrices)\n",
        "# print(test_adjacency_matrices.shape)\n",
        "\n",
        "test_predictions = model.predict([test_feature_matrices, test_adjacency_matrices, X_test_meta])\n",
        "test_predictions_classes = classify_with_threshold(test_predictions, best_threshold[0], best_threshold[1])\n",
        "print(test_predictions_classes.shape)\n",
        "\n",
        "prediction_df = pd.DataFrame(test_predictions, index=test_idx, columns=df_train_y.columns)\n",
        "prediction_df = prediction_df.reset_index(names='participant_id')\n",
        "prediction_df.head()\n",
        "\n",
        "# test_idx = df_test_meta_imputed.index.values\n",
        "submission_df = pd.DataFrame(test_predictions_classes, index=test_idx, columns=df_train_y.columns)\n",
        "submission_df = submission_df.reset_index(names='participant_id')\n",
        "submission_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjpwqstGI0D-"
      },
      "outputs": [],
      "source": [
        "# test_predictions = model.predict(df_test_X_scaled)\n",
        "# # test_predictions = model.predict(X_test_cnn)\n",
        "# test_predictions_classes = classify_with_threshold(test_predictions, best_threshold[0], best_threshold[1])\n",
        "# print(test_predictions_classes.shape)\n",
        "\n",
        "# # test_idx = df_test_meta_imputed.index.values\n",
        "# submission_df = pd.DataFrame(test_predictions_classes, index=test_idx, columns=df_train_y.columns)\n",
        "# submission_df = submission_df.reset_index(names='participant_id')\n",
        "# submission_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8SVW-Wko3WT4",
        "outputId": "e3f3ee1a-8ac5-48b4-af2b-6a9485d2dff2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    participant_id  ADHD_Outcome     Sex_F\n",
              "0     Cfwaf5FX7jWK      0.813823  0.244276\n",
              "1     vhGrzmvA3Hjq      0.733389  0.723882\n",
              "2     ULliyEXjy4OV      0.611162  0.334524\n",
              "3     LZfeAb1xMtql      0.835722  0.329487\n",
              "4     EnFOUv0YK1RG      0.888858  0.293106\n",
              "..             ...           ...       ...\n",
              "299   UadZfjdEg7eG      0.869883  0.332411\n",
              "300   IUEHiLmQAqCi      0.892640  0.100232\n",
              "301   cRySmCadYFRO      0.696552  0.452896\n",
              "302   E3MvDUtJadc5      0.917582  0.059078\n",
              "303   dQJXfyRazknD      0.717924  0.093130\n",
              "\n",
              "[304 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c140353-38ae-4b41-ac89-420662e9e422\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>0.813823</td>\n",
              "      <td>0.244276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>0.733389</td>\n",
              "      <td>0.723882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>0.611162</td>\n",
              "      <td>0.334524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>0.835722</td>\n",
              "      <td>0.329487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>0.888858</td>\n",
              "      <td>0.293106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>UadZfjdEg7eG</td>\n",
              "      <td>0.869883</td>\n",
              "      <td>0.332411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>IUEHiLmQAqCi</td>\n",
              "      <td>0.892640</td>\n",
              "      <td>0.100232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>cRySmCadYFRO</td>\n",
              "      <td>0.696552</td>\n",
              "      <td>0.452896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>E3MvDUtJadc5</td>\n",
              "      <td>0.917582</td>\n",
              "      <td>0.059078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>dQJXfyRazknD</td>\n",
              "      <td>0.717924</td>\n",
              "      <td>0.093130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c140353-38ae-4b41-ac89-420662e9e422')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c140353-38ae-4b41-ac89-420662e9e422 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c140353-38ae-4b41-ac89-420662e9e422');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7383a953-1f42-49bf-9480-4c67bad30a2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7383a953-1f42-49bf-9480-4c67bad30a2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7383a953-1f42-49bf-9480-4c67bad30a2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c2c1ff44-106f-47c0-9e55-5265a3df5c46\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('prediction_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c2c1ff44-106f-47c0-9e55-5265a3df5c46 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('prediction_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "prediction_df",
              "summary": "{\n  \"name\": \"prediction_df\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          0.45983952283859253,\n          0.9352633357048035,\n          0.7215989828109741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          0.7917509078979492,\n          0.13879908621311188,\n          0.3879515826702118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "prediction_df\n",
        "# submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GFIf3on2OXl5"
      },
      "outputs": [],
      "source": [
        "filename = f\"yiru_GCN_lr_1e-1_lasso-imp-new_std_accuracy_graphthre0.5_bestthre_{best_threshold[0]}_{best_threshold[1]}_20250421\"\n",
        "## training_pred_df\n",
        "prediction_df.to_csv(f'./predictions/predictions_{filename}.csv', index=False)\n",
        "submission_df.to_csv(f'./submission/submission_{filename}.csv', index=False)\n",
        "model.save(f'./models/model_{filename}.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load model saved as .keras\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('your_model_file.keras')\n"
      ],
      "metadata": {
        "id": "6ucNlPU8SRf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation and Prediction Ensembling"
      ],
      "metadata": {
        "id": "xkTpRqR-Rylq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_tuning(y_pred, y_val):\n",
        "  thresholds = np.linspace(0.02, 0.98, 49)\n",
        "  threshold_combinations = list(product(thresholds, thresholds))\n",
        "\n",
        "  def classify_with_threshold(y_pred, t1, t2):\n",
        "    y_pred_classes = np.zeros_like(y_pred, dtype=int)\n",
        "    y_pred_classes[:, 0] = (y_pred[:, 0] > t1).astype(int)\n",
        "    y_pred_classes[:, 1] = (y_pred[:, 1] > t2).astype(int)\n",
        "    return y_pred_classes\n",
        "\n",
        "  f1_scores = []\n",
        "  for t1, t2 in threshold_combinations:\n",
        "      # Convert probabilities to class labels (0 or 1)\n",
        "      y_pred_classes = classify_with_threshold(y_pred, t1, t2)\n",
        "      # Calculate weighted F1 score\n",
        "      f1, f1_adhd, f1_sex = compute_weighted_f1(y_val[:,0], y_pred_classes[:,0], y_val[:,1], y_pred_classes[:,1])\n",
        "      f1_scores.append(f1)\n",
        "\n",
        "  # Convert to numpy arrays for convenience\n",
        "  f1_scores = np.array(f1_scores)\n",
        "\n",
        "  # Find the best threshold and corresponding F1 score\n",
        "  best_index = np.argmax(f1_scores)\n",
        "  best_threshold = threshold_combinations[best_index]\n",
        "  best_f1 = f1_scores[best_index]\n",
        "\n",
        "  return best_threshold, best_f1\n"
      ],
      "metadata": {
        "id": "gIlDZSNdRUp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function to run cross validations to train the GAT model with the entire dataset: connectome_matrices, df_train_meta_imputed, df_train_y, and add prediction classification threshold tuning in each fold. save the model, predictions, thresholds in output. also add test_feature_matrices, test_adjacency_matrices, X_test_meta for test data prediction generation in each fold\n",
        "\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pickle\n",
        "from itertools import product\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Assuming these functions and classes are defined in your provided code\n",
        "# create_adjacency_matrix, create_weighted_adj_matrix, compute_weighted_f1, GAT\n",
        "\n",
        "def run_cross_validation(model, connectome_matrices, df_train_meta_imputed, df_train_y, connectome_matrices_test, df_test_meta_imputed, n_splits=5, output_dir='cv_results'):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    f1_scores = []\n",
        "    all_folds_preds = []\n",
        "    all_folds_models = []\n",
        "    all_folds_thresholds = []\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(connectome_matrices)):\n",
        "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
        "\n",
        "        X_train_mri, X_val_mri = connectome_matrices[train_index], connectome_matrices[val_index]\n",
        "        X_train_meta, X_val_meta = df_train_meta_imputed[train_index], df_train_meta_imputed[val_index]\n",
        "        y_train, y_val = df_train_y.iloc[train_index].values, df_train_y.iloc[val_index].values\n",
        "\n",
        "        train_adjacency_matrices = [create_adjacency_matrix(cm, threshold=0.45) for cm in X_train_mri]\n",
        "        val_adjacency_matrices = [create_adjacency_matrix(cm, threshold=0.45) for cm in X_val_mri]\n",
        "        test_adj_matrices_fold = [create_adjacency_matrix(cm, threshold=0.45) for cm in connectome_matrices_test] # Added for test data\n",
        "\n",
        "        train_feature_matrices = [np.eye(200, 200) for _ in X_train_mri]\n",
        "        val_feature_matrices = [np.eye(200, 200) for _ in X_val_mri]\n",
        "        test_feat_matrices_fold = [np.eye(200, 200) for _ in connectome_matrices_test] # Added for test data\n",
        "\n",
        "        X_test_meta = df_test_meta_imputed\n",
        "\n",
        "\n",
        "        optimizer = Adam(learning_rate=1e-2)\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        weights = np.where((y_train[:, 0] == 1) & (y_train[:, 1] == 1), 2, 1)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=1e-6)\n",
        "        model.fit([np.array(train_feature_matrices), np.array(train_adjacency_matrices), X_train_meta], y_train,\n",
        "                  sample_weight=weights, epochs=50, batch_size=32, validation_split=0.2, callbacks=[reduce_lr])\n",
        "\n",
        "        y_pred = model.predict([np.array(val_feature_matrices), np.array(val_adjacency_matrices), X_val_meta])\n",
        "\n",
        "        best_threshold, best_f1 = threshold_tuning(y_pred, y_val)\n",
        "        print(\"Best Threshold:\", best_threshold)\n",
        "        print(\"Best F1 Score:\", best_f1)\n",
        "\n",
        "        y_pred_classes = classify_with_threshold(y_pred, best_threshold[0], best_threshold[1])\n",
        "        f1 = compute_weighted_f1(y_val[:, 0], y_pred_classes[:, 0], y_val[:, 1], y_pred_classes[:, 1])\n",
        "        f1_scores.append(f1[0])\n",
        "        print(f\"Fold {fold + 1} Weighted F1 Score: {f1[0]}\")\n",
        "\n",
        "\n",
        "        # Test set predictions with the best threshold\n",
        "        y_pred_test = model.predict([np.array(test_feat_matrices_fold), np.array(test_adj_matrices_fold), X_test_meta])\n",
        "        y_pred_test_classes = classify_with_threshold(y_pred_test, best_threshold[0], best_threshold[1])\n",
        "\n",
        "        fold_data = {\n",
        "            'y_val': y_val,\n",
        "            'y_pred': y_pred,\n",
        "            'y_pred_classes': y_pred_classes, # Added class predictions\n",
        "            'y_pred_test': y_pred_test,       # Added test predictions\n",
        "            'y_pred_test_classes': y_pred_test_classes, # Added test class predictions\n",
        "            'threshold': best_threshold\n",
        "        }\n",
        "        fold_path = os.path.join(output_dir, f'fold_{fold + 1}.pkl')\n",
        "        with open(fold_path, 'wb') as f:\n",
        "            pickle.dump(fold_data, f)\n",
        "\n",
        "        all_folds_preds.append(fold_data)\n",
        "        all_folds_models.append(model)\n",
        "        all_folds_thresholds.append(best_threshold)\n",
        "\n",
        "    print(f\"Average Weighted F1 Score across all folds: {np.mean(f1_scores)}\")\n",
        "    return f1_scores, all_folds_models, all_folds_preds, all_folds_thresholds\n",
        "\n",
        "# Example usage (replace with your actual data)\n",
        "# Assuming model, connectome_matrices, df_train_meta_imputed, df_train_y, test_feature_matrices, test_adjacency_matrices and X_test_meta are defined\n",
        "# model = GAT(...) # Initialize your GAT model\n",
        "\n",
        "current_time_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "f1scores, models, all_folds_preds, all_folds_thresholds = run_cross_validation(model, connectome_matrices, df_train_meta_imputed, df_train_y, connectome_matrices_test, df_test_meta_imputed, output_dir=f'cv_results/{current_time_str}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EduitcuSmvn",
        "outputId": "b7a5a4d1-95b3-42d4-b3e8-1150e5a4f7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - accuracy: 0.9077 - loss: 0.4822 - val_accuracy: 0.6082 - val_loss: 1.4059 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9158 - loss: 0.4615 - val_accuracy: 0.5619 - val_loss: 1.3060 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8944 - loss: 0.4794 - val_accuracy: 0.5309 - val_loss: 1.3973 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9294 - loss: 0.4528 - val_accuracy: 0.5773 - val_loss: 1.2623 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9002 - loss: 0.4522 - val_accuracy: 0.5773 - val_loss: 1.4168 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9328 - loss: 0.4369 - val_accuracy: 0.5825 - val_loss: 1.2353 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9184 - loss: 0.4512 - val_accuracy: 0.5722 - val_loss: 1.3544 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9227 - loss: 0.4401 - val_accuracy: 0.5773 - val_loss: 1.1998 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8978 - loss: 0.4563 - val_accuracy: 0.5722 - val_loss: 1.3668 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9305 - loss: 0.4359 - val_accuracy: 0.5567 - val_loss: 1.2826 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9338 - loss: 0.4477 - val_accuracy: 0.5928 - val_loss: 1.3018 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9208 - loss: 0.4461 - val_accuracy: 0.5567 - val_loss: 1.2217 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9073 - loss: 0.4345 - val_accuracy: 0.5670 - val_loss: 1.2651 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9118 - loss: 0.4499 - val_accuracy: 0.5567 - val_loss: 1.3124 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9090 - loss: 0.4654 - val_accuracy: 0.5825 - val_loss: 1.2514 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9314 - loss: 0.4604 - val_accuracy: 0.5876 - val_loss: 1.1133 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9199 - loss: 0.4597 - val_accuracy: 0.5825 - val_loss: 1.2904 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9204 - loss: 0.4430 - val_accuracy: 0.5670 - val_loss: 1.2769 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9051 - loss: 0.4291 - val_accuracy: 0.5464 - val_loss: 1.2708 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9036 - loss: 0.4392 - val_accuracy: 0.5464 - val_loss: 1.3589 - learning_rate: 0.0100\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9218 - loss: 0.4240 - val_accuracy: 0.5670 - val_loss: 1.4414 - learning_rate: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9310 - loss: 0.4242 - val_accuracy: 0.5515 - val_loss: 1.2716 - learning_rate: 0.0100\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9081 - loss: 0.4299 - val_accuracy: 0.5515 - val_loss: 1.3203 - learning_rate: 0.0100\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9250 - loss: 0.4283 - val_accuracy: 0.5515 - val_loss: 1.4686 - learning_rate: 0.0100\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9111 - loss: 0.4273 - val_accuracy: 0.5515 - val_loss: 1.6093 - learning_rate: 0.0100\n",
            "Epoch 26/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9261 - loss: 0.4338\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9250 - loss: 0.4335 - val_accuracy: 0.5464 - val_loss: 1.4864 - learning_rate: 0.0100\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9247 - loss: 0.4153 - val_accuracy: 0.5412 - val_loss: 1.3500 - learning_rate: 1.0000e-03\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9218 - loss: 0.4169 - val_accuracy: 0.5567 - val_loss: 1.4164 - learning_rate: 1.0000e-03\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.4181 - val_accuracy: 0.5619 - val_loss: 1.3700 - learning_rate: 1.0000e-03\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9196 - loss: 0.3854 - val_accuracy: 0.5619 - val_loss: 1.4065 - learning_rate: 1.0000e-03\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9210 - loss: 0.4126 - val_accuracy: 0.5619 - val_loss: 1.3951 - learning_rate: 1.0000e-03\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9279 - loss: 0.4021 - val_accuracy: 0.5567 - val_loss: 1.4276 - learning_rate: 1.0000e-03\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9315 - loss: 0.3873 - val_accuracy: 0.5515 - val_loss: 1.3920 - learning_rate: 1.0000e-03\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9293 - loss: 0.4012 - val_accuracy: 0.5567 - val_loss: 1.4281 - learning_rate: 1.0000e-03\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9175 - loss: 0.3922 - val_accuracy: 0.5567 - val_loss: 1.4309 - learning_rate: 1.0000e-03\n",
            "Epoch 36/50\n",
            "\u001b[1m23/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9404 - loss: 0.4029\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9391 - loss: 0.4027 - val_accuracy: 0.5670 - val_loss: 1.4284 - learning_rate: 1.0000e-03\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9165 - loss: 0.3994 - val_accuracy: 0.5670 - val_loss: 1.4366 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9309 - loss: 0.3839 - val_accuracy: 0.5670 - val_loss: 1.4393 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9161 - loss: 0.3928 - val_accuracy: 0.5670 - val_loss: 1.4443 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9228 - loss: 0.3779 - val_accuracy: 0.5670 - val_loss: 1.4412 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9154 - loss: 0.4178 - val_accuracy: 0.5670 - val_loss: 1.4314 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9172 - loss: 0.4001 - val_accuracy: 0.5670 - val_loss: 1.4399 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9330 - loss: 0.4177 - val_accuracy: 0.5670 - val_loss: 1.4400 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9102 - loss: 0.3954 - val_accuracy: 0.5619 - val_loss: 1.4517 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9224 - loss: 0.4079 - val_accuracy: 0.5619 - val_loss: 1.4470 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m22/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9272 - loss: 0.4117\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9271 - loss: 0.4093 - val_accuracy: 0.5619 - val_loss: 1.4477 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9205 - loss: 0.4192 - val_accuracy: 0.5619 - val_loss: 1.4477 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9459 - loss: 0.3836 - val_accuracy: 0.5619 - val_loss: 1.4474 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9244 - loss: 0.4088 - val_accuracy: 0.5619 - val_loss: 1.4471 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9331 - loss: 0.4254 - val_accuracy: 0.5619 - val_loss: 1.4459 - learning_rate: 1.0000e-05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step\n",
            "Best Threshold: (np.float64(0.38), np.float64(0.44))\n",
            "Best F1 Score: 0.7117528764891559\n",
            "Fold 1 Weighted F1 Score: 0.7117528764891559\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "Fold 2/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - accuracy: 0.9207 - loss: 0.4700 - val_accuracy: 0.5567 - val_loss: 1.5829 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9411 - loss: 0.4699 - val_accuracy: 0.5825 - val_loss: 1.3426 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9105 - loss: 0.4722 - val_accuracy: 0.5928 - val_loss: 1.5178 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9060 - loss: 0.4711 - val_accuracy: 0.5670 - val_loss: 1.3133 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9102 - loss: 0.4554 - val_accuracy: 0.6082 - val_loss: 1.4316 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9249 - loss: 0.4381 - val_accuracy: 0.5979 - val_loss: 1.3897 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9264 - loss: 0.4224 - val_accuracy: 0.5361 - val_loss: 1.1158 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8694 - loss: 0.4447 - val_accuracy: 0.6031 - val_loss: 1.4242 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9303 - loss: 0.4324 - val_accuracy: 0.5928 - val_loss: 1.2047 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9305 - loss: 0.4195 - val_accuracy: 0.5619 - val_loss: 1.1679 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9184 - loss: 0.4438 - val_accuracy: 0.6082 - val_loss: 1.2263 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9315 - loss: 0.4313 - val_accuracy: 0.5825 - val_loss: 1.2086 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9136 - loss: 0.4068 - val_accuracy: 0.6134 - val_loss: 1.1592 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9263 - loss: 0.4259 - val_accuracy: 0.5825 - val_loss: 1.2858 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9431 - loss: 0.4396 - val_accuracy: 0.5825 - val_loss: 1.1956 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9186 - loss: 0.3954 - val_accuracy: 0.6031 - val_loss: 1.5250 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9113 - loss: 0.4282\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9138 - loss: 0.4257 - val_accuracy: 0.5825 - val_loss: 1.3945 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9243 - loss: 0.4153 - val_accuracy: 0.5773 - val_loss: 1.3083 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9302 - loss: 0.3844 - val_accuracy: 0.5773 - val_loss: 1.3245 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9410 - loss: 0.3824 - val_accuracy: 0.5825 - val_loss: 1.3268 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9465 - loss: 0.3652 - val_accuracy: 0.5825 - val_loss: 1.3237 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9206 - loss: 0.4173 - val_accuracy: 0.5773 - val_loss: 1.3614 - learning_rate: 1.0000e-03\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9379 - loss: 0.3977 - val_accuracy: 0.5825 - val_loss: 1.3328 - learning_rate: 1.0000e-03\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9245 - loss: 0.3688 - val_accuracy: 0.5722 - val_loss: 1.3207 - learning_rate: 1.0000e-03\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9376 - loss: 0.3573 - val_accuracy: 0.5773 - val_loss: 1.3063 - learning_rate: 1.0000e-03\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9301 - loss: 0.3737 - val_accuracy: 0.5773 - val_loss: 1.3173 - learning_rate: 1.0000e-03\n",
            "Epoch 27/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9118 - loss: 0.3990\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9134 - loss: 0.3957 - val_accuracy: 0.5773 - val_loss: 1.3236 - learning_rate: 1.0000e-03\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9297 - loss: 0.3736 - val_accuracy: 0.5773 - val_loss: 1.3286 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9385 - loss: 0.3444 - val_accuracy: 0.5773 - val_loss: 1.3276 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9237 - loss: 0.3686 - val_accuracy: 0.5773 - val_loss: 1.3258 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9251 - loss: 0.3944 - val_accuracy: 0.5773 - val_loss: 1.3224 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9247 - loss: 0.3781 - val_accuracy: 0.5773 - val_loss: 1.3269 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9321 - loss: 0.3896 - val_accuracy: 0.5773 - val_loss: 1.3284 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9302 - loss: 0.3869 - val_accuracy: 0.5773 - val_loss: 1.3266 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9234 - loss: 0.3573 - val_accuracy: 0.5773 - val_loss: 1.3241 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9445 - loss: 0.3669 - val_accuracy: 0.5773 - val_loss: 1.3278 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9293 - loss: 0.3992\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9294 - loss: 0.3952 - val_accuracy: 0.5773 - val_loss: 1.3228 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9230 - loss: 0.3831 - val_accuracy: 0.5773 - val_loss: 1.3229 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9291 - loss: 0.3831 - val_accuracy: 0.5773 - val_loss: 1.3234 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9219 - loss: 0.3849 - val_accuracy: 0.5773 - val_loss: 1.3240 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9281 - loss: 0.3681 - val_accuracy: 0.5773 - val_loss: 1.3240 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9210 - loss: 0.3615 - val_accuracy: 0.5773 - val_loss: 1.3243 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9289 - loss: 0.3711 - val_accuracy: 0.5773 - val_loss: 1.3245 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9280 - loss: 0.3865 - val_accuracy: 0.5773 - val_loss: 1.3247 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9160 - loss: 0.3807 - val_accuracy: 0.5773 - val_loss: 1.3251 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9290 - loss: 0.3835 - val_accuracy: 0.5773 - val_loss: 1.3256 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9193 - loss: 0.3890\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9218 - loss: 0.3865 - val_accuracy: 0.5773 - val_loss: 1.3257 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9379 - loss: 0.3809 - val_accuracy: 0.5773 - val_loss: 1.3258 - learning_rate: 1.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9272 - loss: 0.3805 - val_accuracy: 0.5773 - val_loss: 1.3257 - learning_rate: 1.0000e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9267 - loss: 0.3964 - val_accuracy: 0.5773 - val_loss: 1.3257 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Best Threshold: (np.float64(0.54), np.float64(0.36000000000000004))\n",
            "Best F1 Score: 0.767984693877551\n",
            "Fold 2 Weighted F1 Score: 0.767984693877551\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Fold 3/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.9245 - loss: 0.4890 - val_accuracy: 0.5515 - val_loss: 1.7048 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9256 - loss: 0.4637 - val_accuracy: 0.5206 - val_loss: 1.3057 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9198 - loss: 0.4464 - val_accuracy: 0.5361 - val_loss: 1.4425 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9352 - loss: 0.4550 - val_accuracy: 0.5361 - val_loss: 1.3820 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9434 - loss: 0.4385 - val_accuracy: 0.5206 - val_loss: 1.2996 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9423 - loss: 0.4394 - val_accuracy: 0.5258 - val_loss: 1.4387 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9331 - loss: 0.4343 - val_accuracy: 0.5309 - val_loss: 1.1923 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9191 - loss: 0.4547 - val_accuracy: 0.5412 - val_loss: 1.2600 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8964 - loss: 0.4561 - val_accuracy: 0.5515 - val_loss: 1.4369 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9314 - loss: 0.4764 - val_accuracy: 0.5361 - val_loss: 1.4045 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9478 - loss: 0.4424 - val_accuracy: 0.5464 - val_loss: 1.1815 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9124 - loss: 0.4384 - val_accuracy: 0.5412 - val_loss: 1.2677 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9277 - loss: 0.4610 - val_accuracy: 0.5464 - val_loss: 1.3370 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9202 - loss: 0.4490 - val_accuracy: 0.5258 - val_loss: 1.1373 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9230 - loss: 0.4413 - val_accuracy: 0.5412 - val_loss: 1.2649 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9345 - loss: 0.4426 - val_accuracy: 0.5155 - val_loss: 1.2679 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9037 - loss: 0.4292 - val_accuracy: 0.5258 - val_loss: 1.3304 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9176 - loss: 0.4555 - val_accuracy: 0.5412 - val_loss: 1.3827 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9508 - loss: 0.4046 - val_accuracy: 0.5361 - val_loss: 1.4080 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9285 - loss: 0.4232 - val_accuracy: 0.5515 - val_loss: 1.3836 - learning_rate: 0.0100\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9435 - loss: 0.4214 - val_accuracy: 0.5412 - val_loss: 1.3252 - learning_rate: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9291 - loss: 0.4355 - val_accuracy: 0.5464 - val_loss: 1.3297 - learning_rate: 0.0100\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9216 - loss: 0.4171 - val_accuracy: 0.5412 - val_loss: 1.2204 - learning_rate: 0.0100\n",
            "Epoch 24/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9223 - loss: 0.4087\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9240 - loss: 0.4110 - val_accuracy: 0.5361 - val_loss: 1.3537 - learning_rate: 0.0100\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9371 - loss: 0.4064 - val_accuracy: 0.5258 - val_loss: 1.3937 - learning_rate: 1.0000e-03\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9485 - loss: 0.3840 - val_accuracy: 0.5412 - val_loss: 1.3842 - learning_rate: 1.0000e-03\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9320 - loss: 0.4055 - val_accuracy: 0.5412 - val_loss: 1.3987 - learning_rate: 1.0000e-03\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9408 - loss: 0.3887 - val_accuracy: 0.5412 - val_loss: 1.3923 - learning_rate: 1.0000e-03\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9393 - loss: 0.4050 - val_accuracy: 0.5309 - val_loss: 1.4195 - learning_rate: 1.0000e-03\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9397 - loss: 0.3670 - val_accuracy: 0.5412 - val_loss: 1.4118 - learning_rate: 1.0000e-03\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9105 - loss: 0.3866 - val_accuracy: 0.5309 - val_loss: 1.4240 - learning_rate: 1.0000e-03\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9237 - loss: 0.3785 - val_accuracy: 0.5361 - val_loss: 1.4202 - learning_rate: 1.0000e-03\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9278 - loss: 0.4025 - val_accuracy: 0.5361 - val_loss: 1.4037 - learning_rate: 1.0000e-03\n",
            "Epoch 34/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9255 - loss: 0.3946\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9247 - loss: 0.3923 - val_accuracy: 0.5361 - val_loss: 1.3987 - learning_rate: 1.0000e-03\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9285 - loss: 0.3875 - val_accuracy: 0.5361 - val_loss: 1.3968 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9388 - loss: 0.3888 - val_accuracy: 0.5361 - val_loss: 1.4004 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9192 - loss: 0.4001 - val_accuracy: 0.5361 - val_loss: 1.3976 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9370 - loss: 0.3772 - val_accuracy: 0.5361 - val_loss: 1.4043 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9259 - loss: 0.3768 - val_accuracy: 0.5361 - val_loss: 1.4040 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9363 - loss: 0.3559 - val_accuracy: 0.5361 - val_loss: 1.4052 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9205 - loss: 0.3626 - val_accuracy: 0.5361 - val_loss: 1.4073 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9226 - loss: 0.3639 - val_accuracy: 0.5361 - val_loss: 1.4091 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9308 - loss: 0.3563 - val_accuracy: 0.5361 - val_loss: 1.4127 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9401 - loss: 0.3940\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9381 - loss: 0.3915 - val_accuracy: 0.5412 - val_loss: 1.4068 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9433 - loss: 0.3817 - val_accuracy: 0.5412 - val_loss: 1.4080 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9349 - loss: 0.3690 - val_accuracy: 0.5361 - val_loss: 1.4088 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9288 - loss: 0.3780 - val_accuracy: 0.5361 - val_loss: 1.4095 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9323 - loss: 0.3666 - val_accuracy: 0.5361 - val_loss: 1.4101 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9323 - loss: 0.3790 - val_accuracy: 0.5361 - val_loss: 1.4105 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9232 - loss: 0.3709 - val_accuracy: 0.5361 - val_loss: 1.4111 - learning_rate: 1.0000e-05\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "Best Threshold: (np.float64(0.62), np.float64(0.42000000000000004))\n",
            "Best F1 Score: 0.7624516728835273\n",
            "Fold 3 Weighted F1 Score: 0.7624516728835273\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Fold 4/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.9071 - loss: 0.4602 - val_accuracy: 0.5590 - val_loss: 1.3483 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9207 - loss: 0.4285 - val_accuracy: 0.5231 - val_loss: 1.5809 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9098 - loss: 0.4348 - val_accuracy: 0.5436 - val_loss: 1.2731 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8973 - loss: 0.3870 - val_accuracy: 0.5590 - val_loss: 1.5672 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9423 - loss: 0.3846 - val_accuracy: 0.5641 - val_loss: 1.2288 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9078 - loss: 0.3947 - val_accuracy: 0.5436 - val_loss: 1.4292 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9239 - loss: 0.3953 - val_accuracy: 0.5538 - val_loss: 1.2489 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9174 - loss: 0.3808 - val_accuracy: 0.5641 - val_loss: 1.3681 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9232 - loss: 0.3651 - val_accuracy: 0.5641 - val_loss: 1.6610 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9237 - loss: 0.3824 - val_accuracy: 0.5744 - val_loss: 1.2936 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9146 - loss: 0.3905 - val_accuracy: 0.5538 - val_loss: 1.5563 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9347 - loss: 0.3394 - val_accuracy: 0.5487 - val_loss: 1.2726 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9321 - loss: 0.3801 - val_accuracy: 0.5385 - val_loss: 1.6259 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9313 - loss: 0.3831 - val_accuracy: 0.5692 - val_loss: 1.3961 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9202 - loss: 0.3384\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9207 - loss: 0.3468 - val_accuracy: 0.5282 - val_loss: 1.5538 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9090 - loss: 0.3595 - val_accuracy: 0.5333 - val_loss: 1.4763 - learning_rate: 1.0000e-03\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9325 - loss: 0.3486 - val_accuracy: 0.5333 - val_loss: 1.4602 - learning_rate: 1.0000e-03\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9374 - loss: 0.3240 - val_accuracy: 0.5385 - val_loss: 1.4795 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9285 - loss: 0.3342 - val_accuracy: 0.5436 - val_loss: 1.4706 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9255 - loss: 0.3359 - val_accuracy: 0.5385 - val_loss: 1.5310 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9326 - loss: 0.3303 - val_accuracy: 0.5333 - val_loss: 1.5122 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9287 - loss: 0.3372 - val_accuracy: 0.5385 - val_loss: 1.5164 - learning_rate: 1.0000e-03\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9300 - loss: 0.3329 - val_accuracy: 0.5333 - val_loss: 1.5439 - learning_rate: 1.0000e-03\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9373 - loss: 0.3212 - val_accuracy: 0.5333 - val_loss: 1.5585 - learning_rate: 1.0000e-03\n",
            "Epoch 25/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9317 - loss: 0.3211\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9301 - loss: 0.3224 - val_accuracy: 0.5436 - val_loss: 1.4838 - learning_rate: 1.0000e-03\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9208 - loss: 0.3124 - val_accuracy: 0.5385 - val_loss: 1.4998 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9251 - loss: 0.3298 - val_accuracy: 0.5333 - val_loss: 1.5161 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9267 - loss: 0.3095 - val_accuracy: 0.5385 - val_loss: 1.5131 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9052 - loss: 0.3254 - val_accuracy: 0.5385 - val_loss: 1.5107 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.3386 - val_accuracy: 0.5385 - val_loss: 1.5211 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9292 - loss: 0.3242 - val_accuracy: 0.5385 - val_loss: 1.5267 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9139 - loss: 0.3519 - val_accuracy: 0.5385 - val_loss: 1.5198 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9177 - loss: 0.3322 - val_accuracy: 0.5385 - val_loss: 1.5195 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9324 - loss: 0.3335 - val_accuracy: 0.5385 - val_loss: 1.5197 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9152 - loss: 0.3282\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9159 - loss: 0.3277 - val_accuracy: 0.5385 - val_loss: 1.5232 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9224 - loss: 0.3224 - val_accuracy: 0.5385 - val_loss: 1.5239 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9349 - loss: 0.3141 - val_accuracy: 0.5385 - val_loss: 1.5240 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9138 - loss: 0.3324 - val_accuracy: 0.5385 - val_loss: 1.5239 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9146 - loss: 0.3122 - val_accuracy: 0.5385 - val_loss: 1.5248 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9433 - loss: 0.3090 - val_accuracy: 0.5385 - val_loss: 1.5260 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.3078 - val_accuracy: 0.5385 - val_loss: 1.5260 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9341 - loss: 0.3145 - val_accuracy: 0.5385 - val_loss: 1.5268 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9372 - loss: 0.3138 - val_accuracy: 0.5385 - val_loss: 1.5262 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9312 - loss: 0.3161 - val_accuracy: 0.5385 - val_loss: 1.5264 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m21/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.3078\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9294 - loss: 0.3102 - val_accuracy: 0.5385 - val_loss: 1.5271 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9200 - loss: 0.3253 - val_accuracy: 0.5385 - val_loss: 1.5271 - learning_rate: 1.0000e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9472 - loss: 0.3071 - val_accuracy: 0.5385 - val_loss: 1.5270 - learning_rate: 1.0000e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9300 - loss: 0.3092 - val_accuracy: 0.5385 - val_loss: 1.5269 - learning_rate: 1.0000e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9382 - loss: 0.3153 - val_accuracy: 0.5385 - val_loss: 1.5270 - learning_rate: 1.0000e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9218 - loss: 0.3337 - val_accuracy: 0.5385 - val_loss: 1.5268 - learning_rate: 1.0000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Best Threshold: (np.float64(0.7000000000000001), np.float64(0.46))\n",
            "Best F1 Score: 0.7706829896907217\n",
            "Fold 4 Weighted F1 Score: 0.7706829896907217\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Fold 5/5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spektral/layers/convolutional/conv.py:98: UserWarning: The adjacency matrix of dtype <dtype: 'int64'> is incompatible with the dtype of the node features <dtype: 'float32'> and has been automatically cast to <dtype: 'float32'>.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.9230 - loss: 0.4151 - val_accuracy: 0.5282 - val_loss: 1.6019 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9321 - loss: 0.3861 - val_accuracy: 0.5385 - val_loss: 1.5121 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9045 - loss: 0.4133 - val_accuracy: 0.5538 - val_loss: 1.4855 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9126 - loss: 0.3835 - val_accuracy: 0.5385 - val_loss: 1.6193 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9208 - loss: 0.3804 - val_accuracy: 0.5436 - val_loss: 1.6698 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9151 - loss: 0.3665 - val_accuracy: 0.5385 - val_loss: 1.5679 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9093 - loss: 0.3633 - val_accuracy: 0.5385 - val_loss: 1.5172 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8927 - loss: 0.3772 - val_accuracy: 0.5282 - val_loss: 1.6399 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9164 - loss: 0.3932 - val_accuracy: 0.5487 - val_loss: 1.7702 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9344 - loss: 0.3837 - val_accuracy: 0.5333 - val_loss: 1.6105 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9114 - loss: 0.3644 - val_accuracy: 0.5282 - val_loss: 1.5493 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8872 - loss: 0.3567 - val_accuracy: 0.5641 - val_loss: 1.4211 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8974 - loss: 0.3965 - val_accuracy: 0.5436 - val_loss: 1.5924 - learning_rate: 0.0100\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9181 - loss: 0.3364 - val_accuracy: 0.5538 - val_loss: 1.6455 - learning_rate: 0.0100\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8994 - loss: 0.3646 - val_accuracy: 0.5538 - val_loss: 1.5157 - learning_rate: 0.0100\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9063 - loss: 0.3225 - val_accuracy: 0.5744 - val_loss: 1.5360 - learning_rate: 0.0100\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9040 - loss: 0.3349 - val_accuracy: 0.5487 - val_loss: 1.9744 - learning_rate: 0.0100\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8975 - loss: 0.3811 - val_accuracy: 0.5538 - val_loss: 1.9098 - learning_rate: 0.0100\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9334 - loss: 0.3167 - val_accuracy: 0.5538 - val_loss: 1.8745 - learning_rate: 0.0100\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9038 - loss: 0.3208 - val_accuracy: 0.5487 - val_loss: 1.6003 - learning_rate: 0.0100\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9201 - loss: 0.3286 - val_accuracy: 0.5385 - val_loss: 1.4022 - learning_rate: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9118 - loss: 0.3380 - val_accuracy: 0.5282 - val_loss: 1.8798 - learning_rate: 0.0100\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8819 - loss: 0.3027 - val_accuracy: 0.5641 - val_loss: 1.9390 - learning_rate: 0.0100\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9172 - loss: 0.2900 - val_accuracy: 0.5538 - val_loss: 1.6729 - learning_rate: 0.0100\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9056 - loss: 0.3274 - val_accuracy: 0.5436 - val_loss: 1.8545 - learning_rate: 0.0100\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9141 - loss: 0.2847 - val_accuracy: 0.5231 - val_loss: 1.5887 - learning_rate: 0.0100\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8908 - loss: 0.2731 - val_accuracy: 0.4821 - val_loss: 1.6156 - learning_rate: 0.0100\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9008 - loss: 0.2968 - val_accuracy: 0.5179 - val_loss: 1.6235 - learning_rate: 0.0100\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8733 - loss: 0.2869 - val_accuracy: 0.5641 - val_loss: 2.2597 - learning_rate: 0.0100\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9162 - loss: 0.3162 - val_accuracy: 0.5026 - val_loss: 1.6790 - learning_rate: 0.0100\n",
            "Epoch 31/50\n",
            "\u001b[1m24/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.3116\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8949 - loss: 0.3116 - val_accuracy: 0.5333 - val_loss: 2.1009 - learning_rate: 0.0100\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9096 - loss: 0.2985 - val_accuracy: 0.5179 - val_loss: 1.7096 - learning_rate: 1.0000e-03\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9125 - loss: 0.2439 - val_accuracy: 0.5436 - val_loss: 1.7753 - learning_rate: 1.0000e-03\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9195 - loss: 0.2317 - val_accuracy: 0.5538 - val_loss: 1.8567 - learning_rate: 1.0000e-03\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9119 - loss: 0.2499 - val_accuracy: 0.5436 - val_loss: 1.8299 - learning_rate: 1.0000e-03\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9013 - loss: 0.2256 - val_accuracy: 0.5436 - val_loss: 1.8566 - learning_rate: 1.0000e-03\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9065 - loss: 0.2274 - val_accuracy: 0.5436 - val_loss: 1.8465 - learning_rate: 1.0000e-03\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9159 - loss: 0.2165 - val_accuracy: 0.5436 - val_loss: 1.8200 - learning_rate: 1.0000e-03\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9027 - loss: 0.2242 - val_accuracy: 0.5487 - val_loss: 1.8763 - learning_rate: 1.0000e-03\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9275 - loss: 0.2039 - val_accuracy: 0.5333 - val_loss: 1.8320 - learning_rate: 1.0000e-03\n",
            "Epoch 41/50\n",
            "\u001b[1m20/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9153 - loss: 0.2168\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9155 - loss: 0.2157 - val_accuracy: 0.5385 - val_loss: 1.8847 - learning_rate: 1.0000e-03\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9121 - loss: 0.2128 - val_accuracy: 0.5385 - val_loss: 1.8863 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9285 - loss: 0.2156 - val_accuracy: 0.5436 - val_loss: 1.8869 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9070 - loss: 0.2136 - val_accuracy: 0.5436 - val_loss: 1.8884 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9213 - loss: 0.1994 - val_accuracy: 0.5385 - val_loss: 1.8715 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9190 - loss: 0.2028 - val_accuracy: 0.5436 - val_loss: 1.8806 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9108 - loss: 0.2266 - val_accuracy: 0.5385 - val_loss: 1.8747 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9217 - loss: 0.2081 - val_accuracy: 0.5436 - val_loss: 1.8871 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9030 - loss: 0.2094 - val_accuracy: 0.5385 - val_loss: 1.8709 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8940 - loss: 0.2052 - val_accuracy: 0.5385 - val_loss: 1.8802 - learning_rate: 1.0000e-04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n",
            "Best Threshold: (np.float64(0.64), np.float64(0.04))\n",
            "Best F1 Score: 0.7107457497274522\n",
            "Fold 5 Weighted F1 Score: 0.7107457497274522\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Average Weighted F1 Score across all folds: 0.7447235965336816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSDlMGcuuHdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c42ff63-2227-4a34-ef85-c736296cb5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Predictions (Average): [[1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]]\n",
            "Ensemble Predictions (Majority Vote): [[1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ],
      "source": [
        "# prompt: I have all_folds_preds as my input, use different ensemble methods (average, major vote, etc) to get the final y_pred_test from all models\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def ensemble_predictions(all_folds_preds, method='average'):\n",
        "  \"\"\"\n",
        "  Combines predictions from all folds using different ensemble methods.\n",
        "\n",
        "  Args:\n",
        "    all_folds_preds: A list of dictionaries, where each dictionary contains\n",
        "                     'y_pred_test' (predicted probabilities for the test set)\n",
        "                     from a single fold.\n",
        "    method: The ensemble method to use ('average', 'majority_vote').\n",
        "\n",
        "  Returns:\n",
        "    y_pred_test: The combined prediction for the test set.\n",
        "  \"\"\"\n",
        "  num_folds = len(all_folds_preds)\n",
        "  num_samples = len(all_folds_preds[0]['y_pred_test'])\n",
        "  num_classes = all_folds_preds[0]['y_pred_test'].shape[1]\n",
        "\n",
        "  if method == 'average':\n",
        "    y_pred_test = np.zeros((num_samples, num_classes))\n",
        "    for fold_preds in all_folds_preds:\n",
        "      y_pred_test += fold_preds['y_pred_test']\n",
        "    y_pred_test /= num_folds\n",
        "  elif method == 'majority_vote':\n",
        "    # Assuming binary classification for majority vote\n",
        "    y_pred_test = np.zeros((num_samples, num_classes))\n",
        "    for fold_preds in all_folds_preds:\n",
        "        y_pred_test += fold_preds['y_pred_test_classes']\n",
        "    y_pred_test = (y_pred_test / num_folds > 0.5).astype(int)\n",
        "  else:\n",
        "    raise ValueError(\"Invalid ensemble method. Choose 'average' or 'majority_vote'.\")\n",
        "\n",
        "  return y_pred_test\n",
        "\n",
        "# Example usage:\n",
        "y_pred_test_ensemble_majority_vote = ensemble_predictions(all_folds_preds, method='majority_vote')\n",
        "\n",
        "y_pred_test_ensemble_average = ensemble_predictions(all_folds_preds, method='average')\n",
        "threshold_average = np.mean(all_folds_thresholds, axis=0)\n",
        "y_pred_test_ensemble_average = classify_with_threshold(y_pred_test_ensemble_average, threshold_average[0], threshold_average[1])\n",
        "\n",
        "print(\"Ensemble Predictions (Average):\", y_pred_test_ensemble_average)\n",
        "print(\"Ensemble Predictions (Majority Vote):\", y_pred_test_ensemble_majority_vote)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_submission(y_pred_test_class, output_file='submission.csv'):\n",
        "  assert y_pred_test_class.shape == (len(test_idx), 2)\n",
        "  assert type(y_pred_test_class[0,0]) == np.int64\n",
        "  assert type(y_pred_test_class[0,1]) == np.int64\n",
        "\n",
        "  submission_df = pd.DataFrame(y_pred_test_class, index=test_idx, columns=df_train_y.columns)\n",
        "  submission_df = submission_df.reset_index(names='participant_id')\n",
        "  print(submission_df.head())\n",
        "\n",
        "  submission_df.to_csv(output_file, index=False)\n",
        "  return submission_df\n",
        "\n",
        "submission_df_average = save_submission(\n",
        "    y_pred_test_ensemble_average,\n",
        "    output_file='./submission/submission_pred_yiru_CV_compiled_ensemble_average_GAT_lr_1e-2_lasso-imp-new_std_accuracy_sampleweight_thre0.45_20250418.csv'\n",
        ")\n",
        "\n",
        "submission_df_majority_vote = save_submission(\n",
        "    y_pred_test_ensemble_majority_vote,\n",
        "    output_file='./submission/submission_pred_yiru_CV_compiled_ensemble_majority_vote_GAT_lr_1e-2_lasso-imp-new_std_accuracy_sampleweight_thre0.45_20250418.csv'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21w6ApUxdoxR",
        "outputId": "03212d3a-0341-48f8-84c8-5373e3482d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  participant_id  ADHD_Outcome  Sex_F\n",
            "0   Cfwaf5FX7jWK             1      1\n",
            "1   vhGrzmvA3Hjq             1      1\n",
            "2   ULliyEXjy4OV             1      0\n",
            "3   LZfeAb1xMtql             1      1\n",
            "4   EnFOUv0YK1RG             1      0\n",
            "  participant_id  ADHD_Outcome  Sex_F\n",
            "0   Cfwaf5FX7jWK             1      1\n",
            "1   vhGrzmvA3Hjq             1      1\n",
            "2   ULliyEXjy4OV             1      0\n",
            "3   LZfeAb1xMtql             1      1\n",
            "4   EnFOUv0YK1RG             1      0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "FXiFcnmDQHxB",
        "6wx08ZAME_mK",
        "MzdLsh4gFENt",
        "F9S5jI5voKla",
        "aXC1lHAE6Cca",
        "GGrNRIfYygdl",
        "na_o32wSEzyS",
        "NgFjLqRKcD27",
        "Z8FVmAr4cJBj",
        "hxjW4VRQ0qRs",
        "kmKPi3TgkjEX",
        "Drizrw76p3yn",
        "ZASlzIhz1s6-",
        "xkTpRqR-Rylq"
      ],
      "authorship_tag": "ABX9TyPwTTLUjlQhrYtwFcn6MNEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}